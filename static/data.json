[
  {
    "author": "zsz",
    "index_original": 2,
    "paper_title": "Facetto: Combining Unsupervised and Supervised Learning for Hierarchical Phenotype Analysis in Multi-Channel Image Data",
    "pub_year": 2020,
    "domain": "Healthcare",
    "requirement": {
      "requirement_text": "T1: Cell Type Discovery and Calling. The task most frequently mentioned by all experts is identifying and analyzing speci\ufb01c types and states of cells based on the intensity and pattern of staining with speci\ufb01c antibodies (O1, O2, P1, P2, CB1-6). Challenges: Challenges lie in processing, displaying, and faceting the large and high-dimensional data, as well as in mutual support of manual and automated analysis. A lack of adequate tools makes this task very time-consuming at present.",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "Each image tile in CyCIF is a 16 bit grayscale image,typically comprising 4 \u00d7106 pixels (the dimensions of a scientific gradeCMOS camera). Each channel is recorded in a separate grayscale imagethat is registered to other channels and pseudocolored for visualization.Segmentation assigns an ID (cell ID) to each cell in the stitched image.",
      "data_code": {
        "tables": 1,
        "media": 1,
        "clusters_and_sets_and_lists": 1,
        "geometry": 1
      }
    },
    "solution": [
      {
        "solution_category": "Interaction",
        "solution_axial": "Filtering",
        "solution_compoent": "",
        "axial_code": ["Filtering"],
        "componenet_code": ["filtering"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 3,
    "paper_title": "Facetto: Combining Unsupervised and Supervised Learning for Hierarchical Phenotype Analysis in Multi-Channel Image Data",
    "pub_year": 2020,
    "domain": "Healthcare",
    "requirement": {
      "requirement_text": "T1: Cell Type Discovery and Calling. The task most frequently mentioned by all experts is identifying and analyzing speci\ufb01c types and states of cells based on the intensity and pattern of staining with speci\ufb01c antibodies (O1, O2, P1, P2, CB1-6). Challenges: Challenges lie in processing, displaying, and faceting the large and high-dimensional data, as well as in mutual support of manual and automated analysis. A lack of adequate tools makes this task very time-consuming at present.",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "Each image tile in CyCIF is a 16 bit grayscale image,typically comprising 4 \u00d7106 pixels (the dimensions of a scientific gradeCMOS camera). Each channel is recorded in a separate grayscale imagethat is registered to other channels and pseudocolored for visualization.Segmentation assigns an ID (cell ID) to each cell in the stitched image.",
      "data_code": {
        "tables": 1,
        "media": 1,
        "clusters_and_sets_and_lists": 1,
        "geometry": 1
      }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "Clustering&Grouping",
        "solution_compoent": "Discovercellsubtypes,propagatelearnedtypesacrossimages",
        "axial_code": ["Clustering&Grouping"],
        "componenet_code": ["clustering_and_grouping"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 4,
    "paper_title": "Facetto: Combining Unsupervised and Supervised Learning for Hierarchical Phenotype Analysis in Multi-Channel Image Data",
    "pub_year": 2020,
    "domain": "Healthcare",
    "requirement": {
      "requirement_text": "T2: Overview-Detail Exploration of Multi-Channel Image Data. A crucial task for oncologists and pathologists is rapid navigation and visualization of multi-channel images (O1, O2, P1, P2). Pathologists are accustomed to moving slides back and forth physically on a micro-scope stage and switching between high and low power views. They rely on a seamless visual experience to make a diagnosis. Challenges: Image analysis must not only support seamless pan and zoom, but also switching between groups of channels. Current tools do not scale beyond 4-5 channels and lack on-demand rendering, blending of channels, and means to emphasize (and recall) regions or individual cells of interest.",
      "requirement_code": { "describe_observation_aggregate": 1 }
    },
    "data": {
      "data_text": "Each image tile in CyCIF is a 16 bit grayscale image,typically comprising 4 \u00d7106 pixels (the dimensions of a scientific gradeCMOS camera). Each channel is recorded in a separate grayscale imagethat is registered to other channels and pseudocolored for visualization.Segmentation assigns an ID (cell ID) to each cell in the stitched image.",
      "data_code": {
        "tables": 1,
        "media": 1,
        "clusters_and_sets_and_lists": 1,
        "geometry": 1
      }
    },
    "solution": [
      {
        "solution_category": "Interaction",
        "solution_axial": "Filtering,OverviewandExplore",
        "solution_compoent": "",
        "axial_code": ["OverviewandExplore", "Filtering"],
        "componenet_code": [
          "overview_and_explore",
          "filtering",
          "overview_and_explore",
          "filtering"
        ]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 5,
    "paper_title": "Facetto: Combining Unsupervised and Supervised Learning for Hierarchical Phenotype Analysis in Multi-Channel Image Data",
    "pub_year": 2020,
    "domain": "Healthcare",
    "requirement": {
      "requirement_text": "T2: Overview-Detail Exploration of Multi-Channel Image Data. A crucial task for oncologists and pathologists is rapid navigation and visualization of multi-channel images (O1, O2, P1, P2). Pathologists are accustomed to moving slides back and forth physically on a micro-scope stage and switching between high and low power views. They rely on a seamless visual experience to make a diagnosis. Challenges: Image analysis must not only support seamless pan and zoom, but also switching between groups of channels. Current tools do not scale beyond 4-5 channels and lack on-demand rendering, blending of channels, and means to emphasize (and recall) regions or individual cells of interest.",
      "requirement_code": { "describe_observation_aggregate": 1 }
    },
    "data": {
      "data_text": "Each image tile in CyCIF is a 16 bit grayscale image,typically comprising 4 \u00d7106 pixels (the dimensions of a scientific gradeCMOS camera). Each channel is recorded in a separate grayscale imagethat is registered to other channels and pseudocolored for visualization.Segmentation assigns an ID (cell ID) to each cell in the stitched image.",
      "data_code": {
        "tables": 1,
        "media": 1,
        "clusters_and_sets_and_lists": 1,
        "geometry": 1
      }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "Clustering&Grouping",
        "solution_compoent": "Discovercellsubtypes,propagatelearnedtypesacrossimages",
        "axial_code": ["Clustering&Grouping"],
        "componenet_code": ["clustering_and_grouping"]
      },
      {
        "solution_category": "Visualization",
        "solution_axial": "Coordinate",
        "solution_compoent": "image+area",
        "axial_code": ["Coordinate"],
        "componenet_code": ["area", "image"]
      },
      {
        "solution_category": "Interaction",
        "solution_axial": "Filtering",
        "solution_compoent": "",
        "axial_code": ["Filtering"],
        "componenet_code": ["filtering"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 6,
    "paper_title": "Facetto: Combining Unsupervised and Supervised Learning for Hierarchical Phenotype Analysis in Multi-Channel Image Data",
    "pub_year": 2020,
    "domain": "Healthcare",
    "requirement": {
      "requirement_text": "T3: Data Filtering and (Sub-)Structuring. Another task frequently performed by pathologists is gating, which refers to manual \ufb01ltering of selected image channels based on the channel\u2019s intensity value range (often visualized as a frequency-intensity plot), or speci\ufb01c spatial features or regions of interest (P2, O2, CB2). Challenges: Analysis steps such as gating are often applied in an iterative manner in which the data is hierarchically faceted into subsets. These subsets can then be further analyzed, used in benchmarks, or exported for presentation or reuse with other samples. Thus, tracking the evolution and provenance of gates and gated data is important.",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "Each image tile in CyCIF is a 16 bit grayscale image,typically comprising 4 \u00d7106 pixels (the dimensions of a scientific gradeCMOS camera). Each channel is recorded in a separate grayscale imagethat is registered to other channels and pseudocolored for visualization.Segmentation assigns an ID (cell ID) to each cell in the stitched image.",
      "data_code": { "tables": 1, "media": 1, "clusters_and_sets_and_lists": 1 }
    },
    "solution": [
      {
        "solution_category": "Visualization",
        "solution_axial": "Nesting",
        "solution_compoent": "tree+circle",
        "axial_code": ["Nesting"],
        "componenet_code": ["tree", "circle"]
      },
      {
        "solution_category": "Interaction",
        "solution_axial": "Extractionoffeatures",
        "solution_compoent": "",
        "axial_code": ["Extractionoffeatures"],
        "componenet_code": ["extraction_of_features"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 7,
    "paper_title": "Facetto: Combining Unsupervised and Supervised Learning for Hierarchical Phenotype Analysis in Multi-Channel Image Data",
    "pub_year": 2020,
    "domain": "Healthcare",
    "requirement": {
      "requirement_text": "T3: Data Filtering and (Sub-)Structuring. Another task frequently performed by pathologists is gating, which refers to manual \ufb01ltering of selected image channels based on the channel\u2019s intensity value range (often visualized as a frequency-intensity plot), or speci\ufb01c spatial features or regions of interest (P2, O2, CB2). Challenges: Analysis steps such as gating are often applied in an iterative manner in which the data is hierarchically faceted into subsets. These subsets can then be further analyzed, used in benchmarks, or exported for presentation or reuse with other samples. Thus, tracking the evolution and provenance of gates and gated data is important.",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "Each image tile in CyCIF is a 16 bit grayscale image,typically comprising 4 \u00d7106 pixels (the dimensions of a scientific gradeCMOS camera). Each channel is recorded in a separate grayscale imagethat is registered to other channels and pseudocolored for visualization.Segmentation assigns an ID (cell ID) to each cell in the stitched image.",
      "data_code": {
        "tables": 1,
        "media": 1,
        "clusters_and_sets_and_lists": 1,
        "geometry": 1
      }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "Clustering&Grouping",
        "solution_compoent": "Discovercellsubtypes,propagatelearnedtypesacrossimages",
        "axial_code": ["Clustering&Grouping"],
        "componenet_code": ["clustering_and_grouping"]
      },
      {
        "solution_category": "Visualization",
        "solution_axial": "Coordinate",
        "solution_compoent": "image+area",
        "axial_code": ["Coordinate"],
        "componenet_code": ["area", "image"]
      },
      {
        "solution_category": "Interaction",
        "solution_axial": "Participation/Collaboration",
        "solution_compoent": "",
        "axial_code": ["Participation/Collaboration"],
        "componenet_code": ["participation/collaboration"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 8,
    "paper_title": "Facetto: Combining Unsupervised and Supervised Learning for Hierarchical Phenotype Analysis in Multi-Channel Image Data",
    "pub_year": 2020,
    "domain": "Healthcare",
    "requirement": {
      "requirement_text": "T3: Data Filtering and (Sub-)Structuring. Another task frequently performed by pathologists is gating, which refers to manual \ufb01ltering of selected image channels based on the channel\u2019s intensity value range (often visualized as a frequency-intensity plot), or speci\ufb01c spatial features or regions of interest (P2, O2, CB2). Challenges: Analysis steps such as gating are often applied in an iterative manner in which the data is hierarchically faceted into subsets. These subsets can then be further analyzed, used in benchmarks, or exported for presentation or reuse with other samples. Thus, tracking the evolution and provenance of gates and gated data is important.",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "Each image tile in CyCIF is a 16 bit grayscale image,typically comprising 4 \u00d7106 pixels (the dimensions of a scientific gradeCMOS camera). Each channel is recorded in a separate grayscale imagethat is registered to other channels and pseudocolored for visualization.Segmentation assigns an ID (cell ID) to each cell in the stitched image.",
      "data_code": {
        "tables": 1,
        "media": 1,
        "clusters_and_sets_and_lists": 1,
        "geometry": 1
      }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "Clustering&Grouping",
        "solution_compoent": "Discovercellsubtypes,propagatelearnedtypesacrossimages",
        "axial_code": ["Clustering&Grouping"],
        "componenet_code": ["clustering_and_grouping"]
      },
      {
        "solution_category": "Visualization",
        "solution_axial": "Coordinate",
        "solution_compoent": "image+area",
        "axial_code": ["Coordinate"],
        "componenet_code": ["area", "image"]
      },
      {
        "solution_category": "Interaction",
        "solution_axial": "Filtering",
        "solution_compoent": "",
        "axial_code": ["Filtering"],
        "componenet_code": ["filtering"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 9,
    "paper_title": "Facetto: Combining Unsupervised and Supervised Learning for Hierarchical Phenotype Analysis in Multi-Channel Image Data",
    "pub_year": 2020,
    "domain": "Healthcare",
    "requirement": {
      "requirement_text": "T3: Data Filtering and (Sub-)Structuring. Another task frequently performed by pathologists is gating, which refers to manual \ufb01ltering of selected image channels based on the channel\u2019s intensity value range (often visualized as a frequency-intensity plot), or speci\ufb01c spatial features or regions of interest (P2, O2, CB2). Challenges: Analysis steps such as gating are often applied in an iterative manner in which the data is hierarchically faceted into subsets. These subsets can then be further analyzed, used in benchmarks, or exported for presentation or reuse with other samples. Thus, tracking the evolution and provenance of gates and gated data is important.",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "Each image tile in CyCIF is a 16 bit grayscale image,typically comprising 4 \u00d7106 pixels (the dimensions of a scientific gradeCMOS camera). Each channel is recorded in a separate grayscale imagethat is registered to other channels and pseudocolored for visualization.Segmentation assigns an ID (cell ID) to each cell in the stitched image.",
      "data_code": {
        "tables": 1,
        "media": 1,
        "clusters_and_sets_and_lists": 1,
        "geometry": 1
      }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "Clustering&Grouping",
        "solution_compoent": "Discovercellsubtypes,propagatelearnedtypesacrossimages",
        "axial_code": ["Clustering&Grouping"],
        "componenet_code": ["clustering_and_grouping"]
      },
      {
        "solution_category": "Visualization",
        "solution_axial": "Stack",
        "solution_compoent": "image+parallelcoordinates",
        "axial_code": ["Stack"],
        "componenet_code": ["parallelcoordinates", "image"]
      },
      {
        "solution_category": "Interaction",
        "solution_axial": "Filtering",
        "solution_compoent": "",
        "axial_code": ["Filtering"],
        "componenet_code": ["filtering"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 10,
    "paper_title": "Facetto: Combining Unsupervised and Supervised Learning for Hierarchical Phenotype Analysis in Multi-Channel Image Data",
    "pub_year": 2020,
    "domain": "Healthcare",
    "requirement": {
      "requirement_text": "T4: Proofreading and Analyzing Results in Spatial Context. Many algorithms operate on features computed from images following segmentation; these include mean intensity value per cell and channel. Feature extraction and segmentation from tissues, in which cells of different sizes and shapes are crowded together, are challenging tasks for which software tools are still being developed. As a result, it is essential that the results of feature extraction are checked and corrected prior to downstream data processing (CB1, CB3). This requires effective means to link feature and image space (P1, O1). Challenges: Currently, such linking is only supported by HistoCat [60], and generally requires domain experts to continuously switch between tools (CB2).",
      "requirement_code": { "describe_observation_item": 1 }
    },
    "data": {
      "data_text": "Each image tile in CyCIF is a 16 bit grayscale image,typically comprising 4 \u00d7106 pixels (the dimensions of a scientific gradeCMOS camera). Each channel is recorded in a separate grayscale imagethat is registered to other channels and pseudocolored for visualization.Segmentation assigns an ID (cell ID) to each cell in the stitched image.",
      "data_code": {
        "tables": 1,
        "media": 1,
        "clusters_and_sets_and_lists": 1,
        "geometry": 1
      }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "Clustering&Grouping",
        "solution_compoent": "Discovercellsubtypes,propagatelearnedtypesacrossimages",
        "axial_code": ["Clustering&Grouping"],
        "componenet_code": ["clustering_and_grouping"]
      },
      {
        "solution_category": "Visualization",
        "solution_axial": "Coordinate",
        "solution_compoent": "image+area",
        "axial_code": ["Coordinate"],
        "componenet_code": ["area", "image"]
      },
      {
        "solution_category": "Interaction",
        "solution_axial": "Participation/Collaboration",
        "solution_compoent": "",
        "axial_code": ["Participation/Collaboration"],
        "componenet_code": ["participation/collaboration"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 11,
    "paper_title": "Facetto: Combining Unsupervised and Supervised Learning for Hierarchical Phenotype Analysis in Multi-Channel Image Data",
    "pub_year": 2020,
    "domain": "Healthcare",
    "requirement": {
      "requirement_text": "T4: Proofreading and Analyzing Results in Spatial Context. Many algorithms operate on features computed from images following segmentation; these include mean intensity value per cell and channel. Feature extraction and segmentation from tissues, in which cells of different sizes and shapes are crowded together, are challenging tasks for which software tools are still being developed. As a result, it is essential that the results of feature extraction are checked and corrected prior to downstream data processing (CB1, CB3). This requires effective means to link feature and image space (P1, O1). Challenges: Currently, such linking is only supported by HistoCat [60], and generally requires domain experts to continuously switch between tools (CB2).",
      "requirement_code": { "describe_observation_item": 1 }
    },
    "data": {
      "data_text": "Each image tile in CyCIF is a 16 bit grayscale image,typically comprising 4 \u00d7106 pixels (the dimensions of a scientific gradeCMOS camera). Each channel is recorded in a separate grayscale imagethat is registered to other channels and pseudocolored for visualization.Segmentation assigns an ID (cell ID) to each cell in the stitched image.",
      "data_code": { "tables": 1, "media": 1, "clusters_and_sets_and_lists": 1 }
    },
    "solution": [
      {
        "solution_category": "Visualization",
        "solution_axial": "Repetition",
        "solution_compoent": "table+bar",
        "axial_code": ["Repetition"],
        "componenet_code": ["table", "bar"]
      },
      {
        "solution_category": "Interaction",
        "solution_axial": "Selecting,Reconfigure,Participation/Collaboration",
        "solution_compoent": "",
        "axial_code": [
          "Participation/Collaboration",
          "Selecting",
          "Reconfigure"
        ],
        "componenet_code": [
          "participation/collaboration",
          "selecting",
          "reconfigure",
          "participation/collaboration",
          "selecting",
          "reconfigure",
          "participation/collaboration",
          "selecting",
          "reconfigure"
        ]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 12,
    "paper_title": "Facetto: Combining Unsupervised and Supervised Learning for Hierarchical Phenotype Analysis in Multi-Channel Image Data",
    "pub_year": 2020,
    "domain": "Healthcare",
    "requirement": {
      "requirement_text": "T5: Deriving Pro\ufb01les for (Sub)regions and Classes. Once a type/region is detected, it is important to identify, annotate, and extract a pro\ufb01le of typical marker distributions within an area of interest (O2, P2). The pro\ufb01le includes statistical measures and distributions of cell features and can be used to present the outcome of an analysis session, diagnosis, or as a starting point for further analysis. Challenges: The variables used to construct pro\ufb01les, and the ways in which these variables are displayed, are not standardized and can only be developed by human-machine interaction.",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "Each image tile in CyCIF is a 16 bit grayscale image,typically comprising 4 \u00d7106 pixels (the dimensions of a scientific gradeCMOS camera). Each channel is recorded in a separate grayscale imagethat is registered to other channels and pseudocolored for visualization.Segmentation assigns an ID (cell ID) to each cell in the stitched image.",
      "data_code": { "tables": 1, "media": 1, "clusters_and_sets_and_lists": 1 }
    },
    "solution": [
      {
        "solution_category": "Visualization",
        "solution_axial": "Nesting",
        "solution_compoent": "tree+circle",
        "axial_code": ["Nesting"],
        "componenet_code": ["tree", "circle"]
      },
      {
        "solution_category": "Interaction",
        "solution_axial": "Selecting,Abstract/Elaborate",
        "solution_compoent": "",
        "axial_code": ["Abstract/Elaborate", "Selecting"],
        "componenet_code": [
          "abstract/elaborate",
          "selecting",
          "abstract/elaborate",
          "selecting"
        ]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 13,
    "paper_title": "Facetto: Combining Unsupervised and Supervised Learning for Hierarchical Phenotype Analysis in Multi-Channel Image Data",
    "pub_year": 2020,
    "domain": "Healthcare",
    "requirement": {
      "requirement_text": "T5: Deriving Pro\ufb01les for (Sub)regions and Classes. Once a type/region is detected, it is important to identify, annotate, and extract a pro\ufb01le of typical marker distributions within an area of interest (O2, P2). The pro\ufb01le includes statistical measures and distributions of cell features and can be used to present the outcome of an analysis session, diagnosis, or as a starting point for further analysis. Challenges: The variables used to construct pro\ufb01les, and the ways in which these variables are displayed, are not standardized and can only be developed by human-machine interaction.",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "Each image tile in CyCIF is a 16 bit grayscale image,typically comprising 4 \u00d7106 pixels (the dimensions of a scientific gradeCMOS camera). Each channel is recorded in a separate grayscale imagethat is registered to other channels and pseudocolored for visualization.Segmentation assigns an ID (cell ID) to each cell in the stitched image.",
      "data_code": {
        "tables": 1,
        "media": 1,
        "clusters_and_sets_and_lists": 1,
        "geometry": 1
      }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "Clustering&Grouping",
        "solution_compoent": "Discovercellsubtypes,propagatelearnedtypesacrossimages",
        "axial_code": ["Clustering&Grouping"],
        "componenet_code": ["clustering_and_grouping"]
      },
      {
        "solution_category": "Visualization",
        "solution_axial": "Repetition",
        "solution_compoent": "scatter",
        "axial_code": ["Repetition"],
        "componenet_code": ["scatter"]
      },
      {
        "solution_category": "Interaction",
        "solution_axial": "OverviewandExplore",
        "solution_compoent": "",
        "axial_code": ["OverviewandExplore"],
        "componenet_code": ["overview_and_explore"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 14,
    "paper_title": "Facetto: Combining Unsupervised and Supervised Learning for Hierarchical Phenotype Analysis in Multi-Channel Image Data",
    "pub_year": 2020,
    "domain": "Healthcare",
    "requirement": {
      "requirement_text": "T5: Deriving Pro\ufb01les for (Sub)regions and Classes. Once a type/region is detected, it is important to identify, annotate, and extract a pro\ufb01le of typical marker distributions within an area of interest (O2, P2). The pro\ufb01le includes statistical measures and distributions of cell features and can be used to present the outcome of an analysis session, diagnosis, or as a starting point for further analysis. Challenges: The variables used to construct pro\ufb01les, and the ways in which these variables are displayed, are not standardized and can only be developed by human-machine interaction.",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "Each image tile in CyCIF is a 16 bit grayscale image,typically comprising 4 \u00d7106 pixels (the dimensions of a scientific gradeCMOS camera). Each channel is recorded in a separate grayscale imagethat is registered to other channels and pseudocolored for visualization.Segmentation assigns an ID (cell ID) to each cell in the stitched image.",
      "data_code": {
        "tables": 1,
        "media": 1,
        "clusters_and_sets_and_lists": 1,
        "geometry": 1
      }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "Clustering&Grouping",
        "solution_compoent": "Discovercellsubtypes,propagatelearnedtypesacrossimages",
        "axial_code": ["Clustering&Grouping"],
        "componenet_code": ["clustering_and_grouping"]
      },
      {
        "solution_category": "Visualization",
        "solution_axial": "Stack",
        "solution_compoent": "image+parallelcoordinates",
        "axial_code": ["Stack"],
        "componenet_code": ["parallelcoordinates", "image"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 15,
    "paper_title": "Facetto: Combining Unsupervised and Supervised Learning for Hierarchical Phenotype Analysis in Multi-Channel Image Data",
    "pub_year": 2020,
    "domain": "Healthcare",
    "requirement": {
      "requirement_text": "T5: Deriving Pro\ufb01les for (Sub)regions and Classes. Once a type/region is detected, it is important to identify, annotate, and extract a pro\ufb01le of typical marker distributions within an area of interest (O2, P2). The pro\ufb01le includes statistical measures and distributions of cell features and can be used to present the outcome of an analysis session, diagnosis, or as a starting point for further analysis. Challenges: The variables used to construct pro\ufb01les, and the ways in which these variables are displayed, are not standardized and can only be developed by human-machine interaction.",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "Each image tile in CyCIF is a 16 bit grayscale image,typically comprising 4 \u00d7106 pixels (the dimensions of a scientific gradeCMOS camera). Each channel is recorded in a separate grayscale imagethat is registered to other channels and pseudocolored for visualization.Segmentation assigns an ID (cell ID) to each cell in the stitched image.",
      "data_code": {
        "tables": 1,
        "media": 1,
        "clusters_and_sets_and_lists": 1,
        "geometry": 1
      }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "Clustering&Grouping",
        "solution_compoent": "Discovercellsubtypes,propagatelearnedtypesacrossimages",
        "axial_code": ["Clustering&Grouping"],
        "componenet_code": ["clustering_and_grouping"]
      },
      {
        "solution_category": "Visualization",
        "solution_axial": "Repetition",
        "solution_compoent": "scatter",
        "axial_code": ["Repetition"],
        "componenet_code": ["scatter"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 18,
    "paper_title": "EmotionCues: Emotion-Oriented Visual Summarization of Classroom Videos",
    "pub_year": 2021,
    "domain": "Emotion",
    "requirement": {
      "requirement_text": "Obtain the emotion status of all the people in a video. Given a specific video, users have a great interest in gaining a quick overview of the video content. For example, what is the overall emotion trend as the video progresses? What kind of emotion dominates the video? Compared with checking the original video back and forth, a visual overview would greatly reduce the browsing burden.",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "The video data we use are mainly collected from our collabo_x0002_rating kindergartens. Teachers in the kindergartens use differ_x0002_ent cameras to shoot videos of children in class. Each video is about 10 minutes long (1.26 G) with a resolution of 1920 _x0003_ 1080 and 30 frames per second (FPS). That is, each video consists of nearly 18,000 high-resolution frames with a wealth of details.",
      "data_code": { "temporal": 1, "media": 1, "sequential": 1 }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "Sampling,Modeling",
        "solution_compoent": "Videosampling,categoricalmodels",
        "axial_code": ["Sampling", "Modeling"],
        "componenet_code": ["sampling", "modeling", "sampling", "modeling"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 19,
    "paper_title": "EmotionCues: Emotion-Oriented Visual Summarization of Classroom Videos",
    "pub_year": 2021,
    "domain": "Emotion",
    "requirement": {
      "requirement_text": "Obtain the emotion status of all the people in a video. Given a specific video, users have a great interest in gaining a quick overview of the video content. For example, what is the overall emotion trend as the video progresses? What kind of emotion dominates the video? Compared with checking the original video back and forth, a visual overview would greatly reduce the browsing burden.",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "The video data we use are mainly collected from our collabo_x0002_rating kindergartens. Teachers in the kindergartens use differ_x0002_ent cameras to shoot videos of children in class. Each video is about 10 minutes long (1.26 G) with a resolution of 1920 _x0003_ 1080 and 30 frames per second (FPS). That is, each video consists of nearly 18,000 high-resolution frames with a wealth of details.",
      "data_code": { "temporal": 1, "media": 1, "sequential": 1 }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "Sampling,Modeling",
        "solution_compoent": "Videosampling,categoricalmodels",
        "axial_code": ["Sampling", "Modeling"],
        "componenet_code": ["sampling", "modeling", "sampling", "modeling"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 20,
    "paper_title": "EmotionCues: Emotion-Oriented Visual Summarization of Classroom Videos",
    "pub_year": 2021,
    "domain": "Emotion",
    "requirement": {
      "requirement_text": "Uncover emotion patterns of an individual in a video. After gaining an overview of the given video, users concentrate on an individual of interest. For example, most parents are concerned about their own children, and they are likely to explore individuals in a video. What is the emotion pattern of a selected person in this video? How do his/her emotions evolve over time?",
      "requirement_code": { "describe_observation_item": 1 }
    },
    "data": {
      "data_text": "The video data we use are mainly collected from our collabo_x0002_rating kindergartens. Teachers in the kindergartens use differ_x0002_ent cameras to shoot videos of children in class. Each video is about 10 minutes long (1.26 G) with a resolution of 1920 _x0003_ 1080 and 30 frames per second (FPS). That is, each video consists of nearly 18,000 high-resolution frames with a wealth of details.",
      "data_code": { "temporal": 1, "media": 1, "sequential": 1 }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "Sampling,Modeling",
        "solution_compoent": "Videosampling,categoricalmodels",
        "axial_code": ["Sampling", "Modeling"],
        "componenet_code": ["sampling", "modeling", "sampling", "modeling"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 21,
    "paper_title": "EmotionCues: Emotion-Oriented Visual Summarization of Classroom Videos",
    "pub_year": 2021,
    "domain": "Emotion",
    "requirement": {
      "requirement_text": "Uncover emotion patterns of an individual in a video. After gaining an overview of the given video, users concentrate on an individual of interest. For example, most parents are concerned about their own children, and they are likely to explore individuals in a video. What is the emotion pattern of a selected person in this video? How do his/her emotions evolve over time?",
      "requirement_code": { "describe_observation_item": 1 }
    },
    "data": {
      "data_text": "The video data we use are mainly collected from our collabo_x0002_rating kindergartens. Teachers in the kindergartens use differ_x0002_ent cameras to shoot videos of children in class. Each video is about 10 minutes long (1.26 G) with a resolution of 1920 _x0003_ 1080 and 30 frames per second (FPS). That is, each video consists of nearly 18,000 high-resolution frames with a wealth of details.",
      "data_code": { "temporal": 1, "media": 1, "sequential": 1 }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "Sampling,Modeling",
        "solution_compoent": "Videosampling,categoricalmodels",
        "axial_code": ["Sampling", "Modeling"],
        "componenet_code": ["sampling", "modeling", "sampling", "modeling"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 22,
    "paper_title": "EmotionCues: Emotion-Oriented Visual Summarization of Classroom Videos",
    "pub_year": 2021,
    "domain": "Emotion",
    "requirement": {
      "requirement_text": "Compare emotion portraits of different people. Users would like to explore a person of interest, especially to obtain his/her relative status in a video. Further comparisons between different people empower users to identify abnormal patterns. For example, teachers may worry about a special student in the class, and parents are curious about whether their children behave differently compared to others. Therefore, comparing different people\u2019s emotion patterns and measuring their similarity and difference are very valuable for users.",
      "requirement_code": { "compare_entities": 1 }
    },
    "data": {
      "data_text": "The video data we use are mainly collected from our collabo_x0002_rating kindergartens. Teachers in the kindergartens use differ_x0002_ent cameras to shoot videos of children in class. Each video is about 10 minutes long (1.26 G) with a resolution of 1920 _x0003_ 1080 and 30 frames per second (FPS). That is, each video consists of nearly 18,000 high-resolution frames with a wealth of details.",
      "data_code": { "temporal": 1, "media": 1, "sequential": 1 }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "Sampling,Modeling",
        "solution_compoent": "Videosampling,categoricalmodels",
        "axial_code": ["Sampling", "Modeling"],
        "componenet_code": ["sampling", "modeling", "sampling", "modeling"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 23,
    "paper_title": "EmotionCues: Emotion-Oriented Visual Summarization of Classroom Videos",
    "pub_year": 2021,
    "domain": "Emotion",
    "requirement": {
      "requirement_text": "Compare emotion portraits of different people. Users would like to explore a person of interest, especially to obtain his/her relative status in a video. Further comparisons between different people empower users to identify abnormal patterns. For example, teachers may worry about a special student in the class, and parents are curious about whether their children behave differently compared to others. Therefore, comparing different people\u2019s emotion patterns and measuring their similarity and difference are very valuable for users.",
      "requirement_code": { "compare_entities": 1 }
    },
    "data": {
      "data_text": "The video data we use are mainly collected from our collabo_x0002_rating kindergartens. Teachers in the kindergartens use differ_x0002_ent cameras to shoot videos of children in class. Each video is about 10 minutes long (1.26 G) with a resolution of 1920 _x0003_ 1080 and 30 frames per second (FPS). That is, each video consists of nearly 18,000 high-resolution frames with a wealth of details.",
      "data_code": { "temporal": 1, "media": 1, "sequential": 1 }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "Sampling,Modeling",
        "solution_compoent": "Videosampling,categoricalmodels",
        "axial_code": ["Sampling", "Modeling"],
        "componenet_code": ["sampling", "modeling", "sampling", "modeling"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 24,
    "paper_title": "EmotionCues: Emotion-Oriented Visual Summarization of Classroom Videos",
    "pub_year": 2021,
    "domain": "Emotion",
    "requirement": {
      "requirement_text": "Compare emotion portraits of different people. Users would like to explore a person of interest, especially to obtain his/her relative status in a video. Further comparisons between different people empower users to identify abnormal patterns. For example, teachers may worry about a special student in the class, and parents are curious about whether their children behave differently compared to others. Therefore, comparing different people\u2019s emotion patterns and measuring their similarity and difference are very valuable for users.",
      "requirement_code": { "compare_entities": 1 }
    },
    "data": {
      "data_text": "The video data we use are mainly collected from our collabo_x0002_rating kindergartens. Teachers in the kindergartens use differ_x0002_ent cameras to shoot videos of children in class. Each video is about 10 minutes long (1.26 G) with a resolution of 1920 _x0003_ 1080 and 30 frames per second (FPS). That is, each video consists of nearly 18,000 high-resolution frames with a wealth of details.",
      "data_code": { "temporal": 1, "media": 1, "sequential": 1 }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "Sampling,Modeling",
        "solution_compoent": "Videosampling,categoricalmodels",
        "axial_code": ["Sampling", "Modeling"],
        "componenet_code": ["sampling", "modeling", "sampling", "modeling"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 25,
    "paper_title": "EmotionCues: Emotion-Oriented Visual Summarization of Classroom Videos",
    "pub_year": 2021,
    "domain": "Emotion",
    "requirement": {
      "requirement_text": "Reveal model uncertainty with influencing factors. Emotion recognition algorithms are not perfect and the accuracy is influenced by multiple factors. Leveraging these factors properly can provide useful cues for inferring underlying patterns. For example, the accuracy of emotion recognition probably decreases, when the algorithm processes a child face image with a small face size in the video or occluded by others. It would also be better to allow users to investigate model accuracy and correct corresponding errors if needed.",
      "requirement_code": { "identify_main_cause_item": 1 }
    },
    "data": {
      "data_text": "The video data we use are mainly collected from our collabo_x0002_rating kindergartens. Teachers in the kindergartens use differ_x0002_ent cameras to shoot videos of children in class. Each video is about 10 minutes long (1.26 G) with a resolution of 1920 _x0003_ 1080 and 30 frames per second (FPS). That is, each video consists of nearly 18,000 high-resolution frames with a wealth of details.",
      "data_code": { "temporal": 1, "media": 1, "sequential": 1 }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "Sampling",
        "solution_compoent": "Videosampling",
        "axial_code": ["Sampling"],
        "componenet_code": ["sampling"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 26,
    "paper_title": "EmotionCues: Emotion-Oriented Visual Summarization of Classroom Videos",
    "pub_year": 2021,
    "domain": "Emotion",
    "requirement": {
      "requirement_text": "Reveal model uncertainty with influencing factors. Emotion recognition algorithms are not perfect and the accuracy is influenced by multiple factors. Leveraging these factors properly can provide useful cues for inferring underlying patterns. For example, the accuracy of emotion recognition probably decreases, when the algorithm processes a child face image with a small face size in the video or occluded by others. It would also be better to allow users to investigate model accuracy and correct corresponding errors if needed.",
      "requirement_code": { "identify_main_cause_item": 1 }
    },
    "data": {
      "data_text": "The video data we use are mainly collected from our collabo_x0002_rating kindergartens. Teachers in the kindergartens use differ_x0002_ent cameras to shoot videos of children in class. Each video is about 10 minutes long (1.26 G) with a resolution of 1920 _x0003_ 1080 and 30 frames per second (FPS). That is, each video consists of nearly 18,000 high-resolution frames with a wealth of details.",
      "data_code": { "temporal": 1, "media": 1, "sequential": 1 }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "Sampling,Modeling",
        "solution_compoent": "Videosampling,categoricalmodels",
        "axial_code": ["Sampling", "Modeling"],
        "componenet_code": ["sampling", "modeling", "sampling", "modeling"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 27,
    "paper_title": "EmotionCues: Emotion-Oriented Visual Summarization of Classroom Videos",
    "pub_year": 2021,
    "domain": "Emotion",
    "requirement": {
      "requirement_text": "Provide context for video analysis. The visual analytics system is based on complex recognition models and abstract data representation. Users also want to know the original video context, which helps them understand the analytical results and validate assumptions. For example, what kind of scenario leads to a change of emotions? Do their assumptions about these findings make sense?",
      "requirement_code": {
        "evaluate_hypothesis": 1,
        "describe_observation_item": 1
      }
    },
    "data": {
      "data_text": "The video data we use are mainly collected from our collabo_x0002_rating kindergartens. Teachers in the kindergartens use differ_x0002_ent cameras to shoot videos of children in class. Each video is about 10 minutes long (1.26 G) with a resolution of 1920 _x0003_ 1080 and 30 frames per second (FPS). That is, each video consists of nearly 18,000 high-resolution frames with a wealth of details.",
      "data_code": { "temporal": 1, "media": 1, "sequential": 1 }
    },
    "solution": [
      {
        "solution_category": "Visualization",
        "solution_axial": "Basic",
        "solution_compoent": "Video",
        "axial_code": ["Basic"],
        "componenet_code": ["Video"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 31,
    "paper_title": "Interactive Correction of Mislabeled Training Data",
    "pub_year": 2019,
    "domain": "label",
    "requirement": {
      "requirement_text": "Examining unusual distribution for identifying labelingerrors. A cleaning pipeline oftenstarts by identifying local regions with unusual patterns of data or la-bel distribution, upon which mislabeled training items can be largelyidentified and inspected. Thus, the experts wanted to quickly locatesuch suspicious regions. Moreover, in each region, the mislabeledtraining items should always be displayed with priority no matterwhich data filter or sampling strategy is applied.",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "The MNIST dataset [57] contains 10,000 training items with correct labels of the 10 digits (0...9). For our experiments, label errors are introduced into the dataset following the contamination mechanism in [54]. The Clothing dataset is a subset of the Clothing 1M dataset [52] in which images were crawled from several online shopping websites. The images are of 14 classes (T-shirt, Shirt, Knitwear, etc.) with some confusing ones (e.g. Knitwear and Sweater).",
      "data_code": { "text": 1, "clusters_and_sets_and_lists": 1, "ordinal": 1 }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "Rectification,Sampling,DimensionalityReduction",
        "solution_compoent": "correctpossiblelabelerrors,sample,incrementaltSNE",
        "axial_code": ["Rectification", "Sampling", "DimensionalityReduction"],
        "componenet_code": [
          "rectification",
          "sampling",
          "dimensionality_reduction",
          "rectification",
          "sampling",
          "dimensionality_reduction",
          "rectification",
          "sampling",
          "dimensionality_reduction"
        ]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 32,
    "paper_title": "Interactive Correction of Mislabeled Training Data",
    "pub_year": 2019,
    "domain": "label",
    "requirement": {
      "requirement_text": "Examining unusual distribution for identifying labelingerrors. A cleaning pipeline oftenstarts by identifying local regions with unusual patterns of data or la-bel distribution, upon which mislabeled training items can be largelyidentified and inspected. Thus, the experts wanted to quickly locatesuch suspicious regions. Moreover, in each region, the mislabeledtraining items should always be displayed with priority no matterwhich data filter or sampling strategy is applied.",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "The MNIST dataset [57] contains 10,000 training items with correct labels of the 10 digits (0...9). For our experiments, label errors are introduced into the dataset following the contamination mechanism in [54]. The Clothing dataset is a subset of the Clothing 1M dataset [52] in which images were crawled from several online shopping websites. The images are of 14 classes (T-shirt, Shirt, Knitwear, etc.) with some confusing ones (e.g. Knitwear and Sweater).",
      "data_code": { "text": 1, "clusters_and_sets_and_lists": 1, "ordinal": 1 }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "Rectification,Sampling,DimensionalityReduction",
        "solution_compoent": "correctpossiblelabelerrors,sample,incrementaltSNE",
        "axial_code": ["Rectification", "Sampling", "DimensionalityReduction"],
        "componenet_code": [
          "rectification",
          "sampling",
          "dimensionality_reduction",
          "rectification",
          "sampling",
          "dimensionality_reduction",
          "rectification",
          "sampling",
          "dimensionality_reduction"
        ]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 33,
    "paper_title": "Interactive Correction of Mislabeled Training Data",
    "pub_year": 2019,
    "domain": "label",
    "requirement": {
      "requirement_text": "Recommending and verifying trusted items. While manual inspection and correction is a routine for debugging mislabeled items, the experts need automated approaches to improve efficiency. Methods such as propagation of trusted items are the most discussed and recognized. However, without efficient algorithms and interactive tools, selecting and validating a set of trusted items from the cluttered visualization can still become laborious. Two requirements were identified by our collaborators based on their experience. First, automatic recommendation algorithms are desired to locate trusted items quickly. Second, flexible ways to examine and compare trusted items are required for further verification",
      "requirement_code": { "compare_entities": 1 }
    },
    "data": {
      "data_text": "The MNIST dataset [57] contains 10,000 training items with correct labels of the 10 digits (0...9). For our experiments, label errors are introduced into the dataset following the contamination mechanism in [54]. The Clothing dataset is a subset of the Clothing 1M dataset [52] in which images were crawled from several online shopping websites. The images are of 14 classes (T-shirt, Shirt, Knitwear, etc.) with some confusing ones (e.g. Knitwear and Sweater).",
      "data_code": {
        "media": 1,
        "clusters_and_sets_and_lists": 1,
        "ordinal": 1
      }
    },
    "solution": [
      {
        "solution_category": "Visualization",
        "solution_axial": "Repetition",
        "solution_compoent": "image+bar",
        "axial_code": ["Repetition"],
        "componenet_code": ["image", "bar"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 34,
    "paper_title": "Interactive Correction of Mislabeled Training Data",
    "pub_year": 2019,
    "domain": "label",
    "requirement": {
      "requirement_text": "Recommending and verifying trusted items. While manual inspection and correction is a routine for debugging mislabeled items, the experts need automated approaches to improve efficiency. Methods such as propagation of trusted items are the most discussed and recognized. However, without efficient algorithms and interactive tools, selecting and validating a set of trusted items from the cluttered visualization can still become laborious. Two requirements were identified by our collaborators based on their experience. First, automatic recommendation algorithms are desired to locate trusted items quickly. Second, flexible ways to examine and compare trusted items are required for further verification",
      "requirement_code": { "compare_entities": 1 }
    },
    "data": {
      "data_text": "The MNIST dataset [57] contains 10,000 training items with correct labels of the 10 digits (0...9). For our experiments, label errors are introduced into the dataset following the contamination mechanism in [54]. The Clothing dataset is a subset of the Clothing 1M dataset [52] in which images were crawled from several online shopping websites. The images are of 14 classes (T-shirt, Shirt, Knitwear, etc.) with some confusing ones (e.g. Knitwear and Sweater).",
      "data_code": {
        "media": 1,
        "clusters_and_sets_and_lists": 1,
        "ordinal": 1
      }
    },
    "solution": [
      {
        "solution_category": "Visualization",
        "solution_axial": "Repetition",
        "solution_compoent": "image+bar",
        "axial_code": ["Repetition"],
        "componenet_code": ["image", "bar"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 35,
    "paper_title": "Interactive Correction of Mislabeled Training Data",
    "pub_year": 2019,
    "domain": "label",
    "requirement": {
      "requirement_text": "Recommending and verifying trusted items. While manual inspection and correction is a routine for debugging mislabeled items, the experts need automated approaches to improve efficiency. Methods such as propagation of trusted items are the most discussed and recognized. However, without efficient algorithms and interactive tools, selecting and validating a set of trusted items from the cluttered visualization can still become laborious. Two requirements were identified by our collaborators based on their experience. First, automatic recommendation algorithms are desired to locate trusted items quickly. Second, flexible ways to examine and compare trusted items are required for further verification",
      "requirement_code": { "compare_entities": 1 }
    },
    "data": {
      "data_text": "The MNIST dataset [57] contains 10,000 training items with correct labels of the 10 digits (0...9). For our experiments, label errors are introduced into the dataset following the contamination mechanism in [54]. The Clothing dataset is a subset of the Clothing 1M dataset [52] in which images were crawled from several online shopping websites. The images are of 14 classes (T-shirt, Shirt, Knitwear, etc.) with some confusing ones (e.g. Knitwear and Sweater).",
      "data_code": {
        "media": 1,
        "clusters_and_sets_and_lists": 1,
        "ordinal": 1
      }
    },
    "solution": [
      {
        "solution_category": "Visualization",
        "solution_axial": "Repetition",
        "solution_compoent": "image+bar",
        "axial_code": ["Repetition"],
        "componenet_code": ["image", "bar"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 36,
    "paper_title": "Interactive Correction of Mislabeled Training Data",
    "pub_year": 2019,
    "domain": "label",
    "requirement": {
      "requirement_text": "Exploring the details. Exploring the details of training items was considered an essential step to verify the labeling correctness. Specifically, the experts would like to be able to explore the details in the context of a distribution visualization so that they can quickly compare groups of items in local regions.",
      "requirement_code": { "evaluate_hypothesis": 1, "collect_evidence": 1 }
    },
    "data": {
      "data_text": "The MNIST dataset [57] contains 10,000 training items with correct labels of the 10 digits (0...9). For our experiments, label errors are introduced into the dataset following the contamination mechanism in [54]. The Clothing dataset is a subset of the Clothing 1M dataset [52] in which images were crawled from several online shopping websites. The images are of 14 classes (T-shirt, Shirt, Knitwear, etc.) with some confusing ones (e.g. Knitwear and Sweater).",
      "data_code": { "text": 1, "clusters_and_sets_and_lists": 1, "ordinal": 1 }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "Rectification,Sampling,DimensionalityReduction",
        "solution_compoent": "correctpossiblelabelerrors,sample,incrementaltSNE",
        "axial_code": ["Rectification", "Sampling", "DimensionalityReduction"],
        "componenet_code": [
          "rectification",
          "sampling",
          "dimensionality_reduction",
          "rectification",
          "sampling",
          "dimensionality_reduction",
          "rectification",
          "sampling",
          "dimensionality_reduction"
        ]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 37,
    "paper_title": "Interactive Correction of Mislabeled Training Data",
    "pub_year": 2019,
    "domain": "label",
    "requirement": {
      "requirement_text": "Exploring the details. Exploring the details of training items was considered an essential step to verify the labeling correctness. Specifically, the experts would like to be able to explore the details in the context of a distribution visualization so that they can quickly compare groups of items in local regions.",
      "requirement_code": { "evaluate_hypothesis": 1, "collect_evidence": 1 }
    },
    "data": {
      "data_text": "The MNIST dataset [57] contains 10,000 training items with correct labels of the 10 digits (0...9). For our experiments, label errors are introduced into the dataset following the contamination mechanism in [54]. The Clothing dataset is a subset of the Clothing 1M dataset [52] in which images were crawled from several online shopping websites. The images are of 14 classes (T-shirt, Shirt, Knitwear, etc.) with some confusing ones (e.g. Knitwear and Sweater).",
      "data_code": { "text": 1, "clusters_and_sets_and_lists": 1, "ordinal": 1 }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "Rectification,Sampling,DimensionalityReduction",
        "solution_compoent": "correctpossiblelabelerrors,sample,incrementaltSNE",
        "axial_code": ["Rectification", "Sampling", "DimensionalityReduction"],
        "componenet_code": [
          "rectification",
          "sampling",
          "dimensionality_reduction",
          "rectification",
          "sampling",
          "dimensionality_reduction",
          "rectification",
          "sampling",
          "dimensionality_reduction"
        ]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 45,
    "paper_title": "t-viSNE: Interactive Assessment and Interpretation of t-SNE Projections",
    "pub_year": 2020,
    "domain": "XAI",
    "requirement": {
      "requirement_text": "Provide the means to investigate quality further, differentiating between the trustworthiness of different regions of the projection.",
      "requirement_code": { "evaluate_hypothesis": 1 }
    },
    "data": {
      "data_text": "The Pima Indian Diabetes dataset, the data set includes 768 female patients of Pima Indian heritage, aged between 21 to 81. The main task in this example is to classify the patients into positive (which have diabetes; 268 data points) or negative to diabetes (i.e., healthy; 500 data points). Every data instance contains eight dimensions: the number of times each patient/person was pregnant and their age, plasma glucose concentration level, diastolic blood pressure, skin thickness, insulin level, body mass index (BMI), and diabetes pedigree function (DPF), which is a function measuring the hereditary or genetic risk of having diabetes.",
      "data_code": { "tables": 1, "categorical": 1 }
    },
    "solution": [
      {
        "solution_category": "Interaction",
        "solution_axial": "Participation/Collaboration",
        "solution_compoent": "",
        "axial_code": ["Participation/Collaboration"],
        "componenet_code": ["participation/collaboration"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 46,
    "paper_title": "t-viSNE: Interactive Assessment and Interpretation of t-SNE Projections",
    "pub_year": 2020,
    "domain": "XAI",
    "requirement": {
      "requirement_text": "Provide the means to investigate quality further, differentiating between the trustworthiness of different regions of the projection.",
      "requirement_code": { "evaluate_hypothesis": 1 }
    },
    "data": {
      "data_text": "The Pima Indian Diabetes dataset, the data set includes 768 female patients of Pima Indian heritage, aged between 21 to 81. The main task in this example is to classify the patients into positive (which have diabetes; 268 data points) or negative to diabetes (i.e., healthy; 500 data points). Every data instance contains eight dimensions: the number of times each patient/person was pregnant and their age, plasma glucose concentration level, diastolic blood pressure, skin thickness, insulin level, body mass index (BMI), and diabetes pedigree function (DPF), which is a function measuring the hereditary or genetic risk of having diabetes.",
      "data_code": { "tables": 1, "categorical": 1 }
    },
    "solution": [
      {
        "solution_category": "Interaction",
        "solution_axial": "Participation/Collaboration",
        "solution_compoent": "",
        "axial_code": ["Participation/Collaboration"],
        "componenet_code": ["participation/collaboration"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 47,
    "paper_title": "t-viSNE: Interactive Assessment and Interpretation of t-SNE Projections",
    "pub_year": 2020,
    "domain": "XAI",
    "requirement": {
      "requirement_text": "Provide the means to investigate quality further, differentiating between the trustworthiness of different regions of the projection.",
      "requirement_code": { "evaluate_hypothesis": 1 }
    },
    "data": {
      "data_text": "The Pima Indian Diabetes dataset, the data set includes 768 female patients of Pima Indian heritage, aged between 21 to 81. The main task in this example is to classify the patients into positive (which have diabetes; 268 data points) or negative to diabetes (i.e., healthy; 500 data points). Every data instance contains eight dimensions: the number of times each patient/person was pregnant and their age, plasma glucose concentration level, diastolic blood pressure, skin thickness, insulin level, body mass index (BMI), and diabetes pedigree function (DPF), which is a function measuring the hereditary or genetic risk of having diabetes.",
      "data_code": { "tables": 1, "categorical": 1 }
    },
    "solution": [
      {
        "solution_category": "Interaction",
        "solution_axial": "Participation/Collaboration",
        "solution_compoent": "",
        "axial_code": ["Participation/Collaboration"],
        "componenet_code": ["participation/collaboration"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 48,
    "paper_title": "t-viSNE: Interactive Assessment and Interpretation of t-SNE Projections",
    "pub_year": 2020,
    "domain": "XAI",
    "requirement": {
      "requirement_text": "Allow the interpretation of different visible patterns of the projection in terms of the original data set\u2019s dimensions.",
      "requirement_code": { "describe_observation_aggregate": 1 }
    },
    "data": {
      "data_text": "The Pima Indian Diabetes dataset, the data set includes 768 female patients of Pima Indian heritage, aged between 21 to 81. The main task in this example is to classify the patients into positive (which have diabetes; 268 data points) or negative to diabetes (i.e., healthy; 500 data points). Every data instance contains eight dimensions: the number of times each patient/person was pregnant and their age, plasma glucose concentration level, diastolic blood pressure, skin thickness, insulin level, body mass index (BMI), and diabetes pedigree function (DPF), which is a function measuring the hereditary or genetic risk of having diabetes.",
      "data_code": { "tables": 1, "categorical": 1 }
    },
    "solution": [
      {
        "solution_category": "Interaction",
        "solution_axial": "Participation/Collaboration",
        "solution_compoent": "",
        "axial_code": ["Participation/Collaboration"],
        "componenet_code": ["participation/collaboration"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 49,
    "paper_title": "t-viSNE: Interactive Assessment and Interpretation of t-SNE Projections",
    "pub_year": 2020,
    "domain": "XAI",
    "requirement": {
      "requirement_text": "Allow the interpretation of different visible patterns of the projection in terms of the original data set\u2019s dimensions.",
      "requirement_code": { "describe_observation_aggregate": 1 }
    },
    "data": {
      "data_text": "The Pima Indian Diabetes dataset, the data set includes 768 female patients of Pima Indian heritage, aged between 21 to 81. The main task in this example is to classify the patients into positive (which have diabetes; 268 data points) or negative to diabetes (i.e., healthy; 500 data points). Every data instance contains eight dimensions: the number of times each patient/person was pregnant and their age, plasma glucose concentration level, diastolic blood pressure, skin thickness, insulin level, body mass index (BMI), and diabetes pedigree function (DPF), which is a function measuring the hereditary or genetic risk of having diabetes.",
      "data_code": { "tables": 1, "categorical": 1 }
    },
    "solution": [
      {
        "solution_category": "Interaction",
        "solution_axial": "Participation/Collaboration",
        "solution_compoent": "",
        "axial_code": ["Participation/Collaboration"],
        "componenet_code": ["participation/collaboration"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 50,
    "paper_title": "Geono-Cluster: Interactive Visual Cluster Analysis for Biologists",
    "pub_year": 2021,
    "domain": "Biology",
    "requirement": {
      "requirement_text": "T1: Hand-Craft, Merge, and Split Clusters. Biologists apply their domain knowledge to create customized clusters to better understand which factor(s) is causing the ascertainment bias on the dataset that are being used popularly. For example, one of the biologist stated: \u201cGiven the identified SNPs [single-nucleotide polymorphisms] that are associated with common disease and traits, it\u2019s interesting to create a cluster of SNPs.\u201d In addition, biologists apply their domain expertise to merge or split two or more clusters depending on how related they think the clusters are based on given feature(s). For example, one of the biologists mentioned: \u201cDepending on the evolutionary history of the genes, two or more clusters can be really related to each other. If ascertained they are related, we will merge them as one cluster.\u201d Another biologist reported that \u201cIn my new project, we are comparing Africans to non-Africans. In this case I merge Americans, East Asians, and Europeans as one cluster, and compare that to Africans data.\u201d",
      "requirement_code": { "identify_main_cause_item": 1 }
    },
    "data": {
      "data_text": "The GWAS Catalog dataset, this dataset includes detailed information regarding the identified single-nucleotide polymorphisms (SNPs) associated with common diseases and traits (e.g., position on the genome, risk allele frequencies, p-value, effect sizes, etc.). SNP is a region on the gene where more than one allele (A, C, G, T) is observed and each row on the dataset is a SNP.",
      "data_code": { "tables": 1, "categorical": 1 }
    },
    "solution": [
      {
        "solution_category": "Interaction",
        "solution_axial": "Filtering",
        "solution_compoent": "",
        "axial_code": ["Filtering"],
        "componenet_code": ["filtering"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 51,
    "paper_title": "Geono-Cluster: Interactive Visual Cluster Analysis for Biologists",
    "pub_year": 2021,
    "domain": "Biology",
    "requirement": {
      "requirement_text": "T2: Divide Each Cluster to Sub-Clusters. Biologists often investigate sub-clusters within a specific cluster to: 1) understand which other factors can affect the cluster, 2) compare two clusters based on the member data items in each, and 3) see trends and patterns in the sub-clusters, with respect to chosen features, We noticed that the biologists found existing solutions challenging because they had to write lines of scripts to compute and visualize sub-clusters in a given cluster. Furthermore, the existing methods prohibit rapid iteration and visualization of results, which inevitably prolongs the exploratory clustering process to understand their data better.",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "The GWAS Catalog dataset, this dataset includes detailed information regarding the identified single-nucleotide polymorphisms (SNPs) associated with common diseases and traits (e.g., position on the genome, risk allele frequencies, p-value, effect sizes, etc.). SNP is a region on the gene where more than one allele (A, C, G, T) is observed and each row on the dataset is a SNP.",
      "data_code": { "tables": 1, "text": 1, "categorical": 1 }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "DimensionalityReduction,Clustering&Grouping",
        "solution_compoent": "",
        "axial_code": ["Clustering&Grouping", "DimensionalityReduction"],
        "componenet_code": [
          "clustering_and_grouping",
          "dimensionality_reduction",
          "clustering_and_grouping",
          "dimensionality_reduction"
        ]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 52,
    "paper_title": "Geono-Cluster: Interactive Visual Cluster Analysis for Biologists",
    "pub_year": 2021,
    "domain": "Biology",
    "requirement": {
      "requirement_text": "T2: Divide Each Cluster to Sub-Clusters. Biologists often investigate sub-clusters within a specific cluster to: 1) understand which other factors can affect the cluster, 2) compare two clusters based on the member data items in each, and 3) see trends and patterns in the sub-clusters, with respect to chosen features, We noticed that the biologists found existing solutions challenging because they had to write lines of scripts to compute and visualize sub-clusters in a given cluster. Furthermore, the existing methods prohibit rapid iteration and visualization of results, which inevitably prolongs the exploratory clustering process to understand their data better.",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "The GWAS Catalog dataset, this dataset includes detailed information regarding the identified single-nucleotide polymorphisms (SNPs) associated with common diseases and traits (e.g., position on the genome, risk allele frequencies, p-value, effect sizes, etc.). SNP is a region on the gene where more than one allele (A, C, G, T) is observed and each row on the dataset is a SNP.",
      "data_code": { "tables": 1, "categorical": 1 }
    },
    "solution": [
      {
        "solution_category": "Interaction",
        "solution_axial": "Participation/Collaboration",
        "solution_compoent": "",
        "axial_code": ["Participation/Collaboration"],
        "componenet_code": ["participation/collaboration"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 53,
    "paper_title": "Geono-Cluster: Interactive Visual Cluster Analysis for Biologists",
    "pub_year": 2021,
    "domain": "Biology",
    "requirement": {
      "requirement_text": "T3: Adjust Feature Contributions. Biologists need to easily see by how much different attributes/features contribute to computing a cluster. Moreover, they often need to adjust the importance of different features used for computing a cluster. Biologists currently have to programmatically adjust the importance of features, execute the code, and visualize the outcome. They often repeat this process multiple times until they achieve a satisfactory result. They need interactive methods to view and refine feature contributions.",
      "requirement_code": { "identify_main_cause_item": 1 }
    },
    "data": {
      "data_text": "The GWAS Catalog dataset, this dataset includes detailed information regarding the identified single-nucleotide polymorphisms (SNPs) associated with common diseases and traits (e.g., position on the genome, risk allele frequencies, p-value, effect sizes, etc.). SNP is a region on the gene where more than one allele (A, C, G, T) is observed and each row on the dataset is a SNP.",
      "data_code": { "tables": 1, "categorical": 1 }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "DimensionalityReduction,Clustering&Grouping",
        "solution_compoent": "",
        "axial_code": ["Clustering&Grouping", "DimensionalityReduction"],
        "componenet_code": [
          "clustering_and_grouping",
          "dimensionality_reduction",
          "clustering_and_grouping",
          "dimensionality_reduction"
        ]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 54,
    "paper_title": "Geono-Cluster: Interactive Visual Cluster Analysis for Biologists",
    "pub_year": 2021,
    "domain": "Biology",
    "requirement": {
      "requirement_text": "T3: Adjust Feature Contributions. Biologists need to easily see by how much different attributes/features contribute to computing a cluster. Moreover, they often need to adjust the importance of different features used for computing a cluster. Biologists currently have to programmatically adjust the importance of features, execute the code, and visualize the outcome. They often repeat this process multiple times until they achieve a satisfactory result. They need interactive methods to view and refine feature contributions.",
      "requirement_code": { "identify_main_cause_item": 1 }
    },
    "data": {
      "data_text": "The GWAS Catalog dataset, this dataset includes detailed information regarding the identified single-nucleotide polymorphisms (SNPs) associated with common diseases and traits (e.g., position on the genome, risk allele frequencies, p-value, effect sizes, etc.). SNP is a region on the gene where more than one allele (A, C, G, T) is observed and each row on the dataset is a SNP.",
      "data_code": { "tables": 1, "categorical": 1 }
    },
    "solution": [
      {
        "solution_category": "Interaction",
        "solution_axial": "Participation/Collaboration",
        "solution_compoent": "",
        "axial_code": ["Participation/Collaboration"],
        "componenet_code": ["participation/collaboration"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 55,
    "paper_title": "Geono-Cluster: Interactive Visual Cluster Analysis for Biologists",
    "pub_year": 2021,
    "domain": "Biology",
    "requirement": {
      "requirement_text": "T3: Adjust Feature Contributions. Biologists need to easily see by how much different attributes/features contribute to computing a cluster. Moreover, they often need to adjust the importance of different features used for computing a cluster. Biologists currently have to programmatically adjust the importance of features, execute the code, and visualize the outcome. They often repeat this process multiple times until they achieve a satisfactory result. They need interactive methods to view and refine feature contributions.",
      "requirement_code": { "identify_main_cause_item": 1 }
    },
    "data": {
      "data_text": "The GWAS Catalog dataset, this dataset includes detailed information regarding the identified single-nucleotide polymorphisms (SNPs) associated with common diseases and traits (e.g., position on the genome, risk allele frequencies, p-value, effect sizes, etc.). SNP is a region on the gene where more than one allele (A, C, G, T) is observed and each row on the dataset is a SNP.",
      "data_code": { "tables": 1, "categorical": 1 }
    },
    "solution": [
      {
        "solution_category": "Interaction",
        "solution_axial": "Selecting.Filtering",
        "solution_compoent": "",
        "axial_code": ["Selecting", "Filtering"],
        "componenet_code": ["selecting", "filtering", "selecting", "filtering"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 57,
    "paper_title": "Geono-Cluster: Interactive Visual Cluster Analysis for Biologists",
    "pub_year": 2021,
    "domain": "Biology",
    "requirement": {
      "requirement_text": "Enable User Interaction to Drive Recommendations. As analysts explore their data, their interests will evolve. Our initial observations and interviews also showed that biologists need to explore various clustering models rapidly during their data analysis process. One potential approach to support such a rapid data analysis is to recommend potential cluster models that biologists should consider during their data analysis process. Furthermore, the clustering recommendations should be adapted for biologists\u2019 analytic goals. The recommendation engine should steer multiple clustering models based on biologist-specified expected visual outcomes. In addition, biologists can also directly adjust feature contributions to update the clustering results. In aggregate, these interactions create demonstrations which serve as the primary units by which biologists communicate their expected changes to the system.",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "The GWAS Catalog dataset, this dataset includes detailed information regarding the identified single-nucleotide polymorphisms (SNPs) associated with common diseases and traits (e.g., position on the genome, risk allele frequencies, p-value, effect sizes, etc.). SNP is a region on the gene where more than one allele (A, C, G, T) is observed and each row on the dataset is a SNP.",
      "data_code": { "tables": 1, "categorical": 1 }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "DimensionalityReduction,Clustering&Grouping",
        "solution_compoent": "",
        "axial_code": ["Clustering&Grouping", "DimensionalityReduction"],
        "componenet_code": [
          "clustering_and_grouping",
          "dimensionality_reduction",
          "clustering_and_grouping",
          "dimensionality_reduction"
        ]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 58,
    "paper_title": "Geono-Cluster: Interactive Visual Cluster Analysis for Biologists",
    "pub_year": 2021,
    "domain": "Biology",
    "requirement": {
      "requirement_text": "Enable User Interaction to Drive Recommendations. As analysts explore their data, their interests will evolve. Our initial observations and interviews also showed that biologists need to explore various clustering models rapidly during their data analysis process. One potential approach to support such a rapid data analysis is to recommend potential cluster models that biologists should consider during their data analysis process. Furthermore, the clustering recommendations should be adapted for biologists\u2019 analytic goals. The recommendation engine should steer multiple clustering models based on biologist-specified expected visual outcomes. In addition, biologists can also directly adjust feature contributions to update the clustering results. In aggregate, these interactions create demonstrations which serve as the primary units by which biologists communicate their expected changes to the system.",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "The GWAS Catalog dataset, this dataset includes detailed information regarding the identified single-nucleotide polymorphisms (SNPs) associated with common diseases and traits (e.g., position on the genome, risk allele frequencies, p-value, effect sizes, etc.). SNP is a region on the gene where more than one allele (A, C, G, T) is observed and each row on the dataset is a SNP.",
      "data_code": { "tables": 1, "categorical": 1 }
    },
    "solution": [
      {
        "solution_category": "Interaction",
        "solution_axial": "Participation/Collaboration",
        "solution_compoent": "",
        "axial_code": ["Participation/Collaboration"],
        "componenet_code": ["participation/collaboration"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 59,
    "paper_title": "Geono-Cluster: Interactive Visual Cluster Analysis for Biologists",
    "pub_year": 2021,
    "domain": "Biology",
    "requirement": {
      "requirement_text": "Enable User Interaction to Drive Recommendations. As analysts explore their data, their interests will evolve. Our initial observations and interviews also showed that biologists need to explore various clustering models rapidly during their data analysis process. One potential approach to support such a rapid data analysis is to recommend potential cluster models that biologists should consider during their data analysis process. Furthermore, the clustering recommendations should be adapted for biologists\u2019 analytic goals. The recommendation engine should steer multiple clustering models based on biologist-specified expected visual outcomes. In addition, biologists can also directly adjust feature contributions to update the clustering results. In aggregate, these interactions create demonstrations which serve as the primary units by which biologists communicate their expected changes to the system.",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "The GWAS Catalog dataset, this dataset includes detailed information regarding the identified single-nucleotide polymorphisms (SNPs) associated with common diseases and traits (e.g., position on the genome, risk allele frequencies, p-value, effect sizes, etc.). SNP is a region on the gene where more than one allele (A, C, G, T) is observed and each row on the dataset is a SNP.",
      "data_code": { "tables": 1, "text": 1, "categorical": 1 }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "DimensionalityReduction,Clustering&Grouping",
        "solution_compoent": "",
        "axial_code": ["Clustering&Grouping", "DimensionalityReduction"],
        "componenet_code": [
          "clustering_and_grouping",
          "dimensionality_reduction",
          "clustering_and_grouping",
          "dimensionality_reduction"
        ]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 60,
    "paper_title": "Geono-Cluster: Interactive Visual Cluster Analysis for Biologists",
    "pub_year": 2021,
    "domain": "Biology",
    "requirement": {
      "requirement_text": "Enhance Interpretability of Recommendations. Biologists reported their interest in seeing more details about different clustering results while skimming through different recommendations. However, not all biologists might be familiar with technical terms used to describe a cluster such as silhouette value. Therefore, recommended clustering results should be presented in a transparent manner so that biologists can extract the most important and understandable information (e.g., contributing features) used for clustering results. One powerful approach to enhance transparency of the recommended clustering options is to use natural language to explain them. This way biologists can learn about the recommended clustering outcomes without having to know about more technical terms describing each clustering outcome.",
      "requirement_code": { "describe_observation_aggregate": 1 }
    },
    "data": {
      "data_text": "The GWAS Catalog dataset, this dataset includes detailed information regarding the identified single-nucleotide polymorphisms (SNPs) associated with common diseases and traits (e.g., position on the genome, risk allele frequencies, p-value, effect sizes, etc.). SNP is a region on the gene where more than one allele (A, C, G, T) is observed and each row on the dataset is a SNP.",
      "data_code": { "tables": 1, "text": 1, "categorical": 1 }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "DimensionalityReduction,Clustering&Grouping",
        "solution_compoent": "",
        "axial_code": ["Clustering&Grouping", "DimensionalityReduction"],
        "componenet_code": [
          "clustering_and_grouping",
          "dimensionality_reduction",
          "clustering_and_grouping",
          "dimensionality_reduction"
        ]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 62,
    "paper_title": "A Probability Density-Based Visual Analytics Approach to Forecast Bias Calibration",
    "pub_year": 2022,
    "domain": "Weather forecast",
    "requirement": {
      "requirement_text": "R.1 Extract Bias Patterns. As indicated in the previous section, bias patterns are a kind of statistical abstraction of the historical data in a certain spatiotemporal interval. However, methods that aim to extract the potential bias patterns from the reanalysis data are limited.",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "The data used in the cases comprise two types of datasets, namely, the forecast and observation data. The forecast data are produced by the Global Ensemble Forecast System (GEFS) global ensemble from the National Centers for Environmental Prediction in the United States. The dataset consists of 11 ensemble members at different convection parameters. Each member has approximately 8000 grids. The ensemble runs and generates forecast atmospheric para-meters daily from 1985, covering an area of [25:0436N, 53:1299N][66:094W, 125:625W] (latitude-longitude) with are solution of 0.5. The data have approximately 150 million forecast records (forecast average value of four output parameters during a 10-year period). Additional details of the GEFS forecast dataset can be found in [5]. The observation data are produced by the climatology-calibrated precipitation analysis (CCPA), which records the observed precipitation in the same area throughout the US every six hours from 2002 with a resolution of 0.125. These data are considered the ground-truth state of the actual weather state. The size of the data used is approximately 30 million observation records(observed precipitation at each interpolated grid point during a 10-years period). ",
      "data_code": {
        "fields": 1,
        "temporal": 1,
        "sequential": 1,
        "geometry": 1
      }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "AlgorithmCalculation,Clustering&Grouping",
        "solution_compoent": "kerneldensityestimation",
        "axial_code": ["Clustering&Grouping", "AlgorithmCalculation"],
        "componenet_code": [
          "clustering_and_grouping",
          "algorithmic_calculation",
          "clustering_and_grouping",
          "algorithmic_calculation"
        ]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 63,
    "paper_title": "A Probability Density-Based Visual Analytics Approach to Forecast Bias Calibration",
    "pub_year": 2022,
    "domain": "Weather forecast",
    "requirement": {
      "requirement_text": "R.2 Visualize the Spatiotemporal Distribution of Similar Bias Patterns. E.2 hoped to have a visualization that can well demonstrate the bias patterns in the spatial and temporal dimensions for an overview, which can help him immediately identify the basic properties and distribution of the bias patterns present in the data.",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "The data used in the cases comprise two types of datasets, namely, the forecast and observation data. The forecast data are produced by the Global Ensemble Forecast System (GEFS) global ensemble from the National Centers for Environmental Prediction in the United States. The dataset consists of 11 ensemble members at different convection parameters. Each member has approximately 8000 grids. The ensemble runs and generates forecast atmospheric para-meters daily from 1985, covering an area of [25:0436N, 53:1299N][66:094W, 125:625W] (latitude-longitude) with are solution of 0.5. The data have approximately 150 million forecast records (forecast average value of four output parameters during a 10-year period). Additional details of the GEFS forecast dataset can be found in [5]. The observation data are produced by the climatology-calibrated precipitation analysis (CCPA), which records the observed precipitation in the same area throughout the US every six hours from 2002 with a resolution of 0.125. These data are considered the ground-truth state of the actual weather state. The size of the data used is approximately 30 million observation records(observed precipitation at each interpolated grid point during a 10-years period). ",
      "data_code": {
        "fields": 1,
        "temporal": 1,
        "sequential": 1,
        "geometry": 1
      }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "AlgorithmCalculation,Clustering&Grouping",
        "solution_compoent": "kerneldensityestimation",
        "axial_code": ["Clustering&Grouping", "AlgorithmCalculation"],
        "componenet_code": [
          "clustering_and_grouping",
          "algorithmic_calculation",
          "clustering_and_grouping",
          "algorithmic_calculation"
        ]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 64,
    "paper_title": "A Probability Density-Based Visual Analytics Approach to Forecast Bias Calibration",
    "pub_year": 2022,
    "domain": "Weather forecast",
    "requirement": {
      "requirement_text": "R.2 Visualize the Spatiotemporal Distribution of Similar Bias Patterns. E.2 hoped to have a visualization that can well demonstrate the bias patterns in the spatial and temporal dimensions for an overview, which can help him immediately identify the basic properties and distribution of the bias patterns present in the data.",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "The data used in the cases comprise two types of datasets, namely, the forecast and observation data. The forecast data are produced by the Global Ensemble Forecast System (GEFS) global ensemble from the National Centers for Environmental Prediction in the United States. The dataset consists of 11 ensemble members at different convection parameters. Each member has approximately 8000 grids. The ensemble runs and generates forecast atmospheric para-meters daily from 1985, covering an area of [25:0436N, 53:1299N][66:094W, 125:625W] (latitude-longitude) with are solution of 0.5. The data have approximately 150 million forecast records (forecast average value of four output parameters during a 10-year period). Additional details of the GEFS forecast dataset can be found in [5]. The observation data are produced by the climatology-calibrated precipitation analysis (CCPA), which records the observed precipitation in the same area throughout the US every six hours from 2002 with a resolution of 0.125. These data are considered the ground-truth state of the actual weather state. The size of the data used is approximately 30 million observation records(observed precipitation at each interpolated grid point during a 10-years period). ",
      "data_code": {
        "fields": 1,
        "temporal": 1,
        "sequential": 1,
        "geometry": 1
      }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "AlgorithmCalculation,Clustering&Grouping",
        "solution_compoent": "kerneldensityestimation",
        "axial_code": ["Clustering&Grouping", "AlgorithmCalculation"],
        "componenet_code": [
          "clustering_and_grouping",
          "algorithmic_calculation",
          "clustering_and_grouping",
          "algorithmic_calculation"
        ]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 65,
    "paper_title": "A Probability Density-Based Visual Analytics Approach to Forecast Bias Calibration",
    "pub_year": 2022,
    "domain": "Weather forecast",
    "requirement": {
      "requirement_text": "R.2 Visualize the Spatiotemporal Distribution of Similar Bias Patterns. E.2 hoped to have a visualization that can well demonstrate the bias patterns in the spatial and temporal dimensions for an overview, which can help him immediately identify the basic properties and distribution of the bias patterns present in the data.",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "The data used in the cases comprise two types of datasets, namely, the forecast and observation data. The forecast data are produced by the Global Ensemble Forecast System (GEFS) global ensemble from the National Centers for Environmental Prediction in the United States. The dataset consists of 11 ensemble members at different convection parameters. Each member has approximately 8000 grids. The ensemble runs and generates forecast atmospheric para-meters daily from 1985, covering an area of [25:0436N, 53:1299N][66:094W, 125:625W] (latitude-longitude) with are solution of 0.5. The data have approximately 150 million forecast records (forecast average value of four output parameters during a 10-year period). Additional details of the GEFS forecast dataset can be found in [5]. The observation data are produced by the climatology-calibrated precipitation analysis (CCPA), which records the observed precipitation in the same area throughout the US every six hours from 2002 with a resolution of 0.125. These data are considered the ground-truth state of the actual weather state. The size of the data used is approximately 30 million observation records(observed precipitation at each interpolated grid point during a 10-years period). ",
      "data_code": { "fields": 1, "geometry": 1 }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "AlgorithmCalculation,Clustering&Grouping",
        "solution_compoent": "kerneldensityestimation",
        "axial_code": ["Clustering&Grouping", "AlgorithmCalculation"],
        "componenet_code": [
          "clustering_and_grouping",
          "algorithmic_calculation",
          "clustering_and_grouping",
          "algorithmic_calculation"
        ]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 66,
    "paper_title": "A Probability Density-Based Visual Analytics Approach to Forecast Bias Calibration",
    "pub_year": 2022,
    "domain": "Weather forecast",
    "requirement": {
      "requirement_text": "R.2 Visualize the Spatiotemporal Distribution of Similar Bias Patterns. E.2 hoped to have a visualization that can well demonstrate the bias patterns in the spatial and temporal dimensions for an overview, which can help him immediately identify the basic properties and distribution of the bias patterns present in the data.",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "The data used in the cases comprise two types of datasets, namely, the forecast and observation data. The forecast data are produced by the Global Ensemble Forecast System (GEFS) global ensemble from the National Centers for Environmental Prediction in the United States. The dataset consists of 11 ensemble members at different convection parameters. Each member has approximately 8000 grids. The ensemble runs and generates forecast atmospheric para-meters daily from 1985, covering an area of [25:0436N, 53:1299N][66:094W, 125:625W] (latitude-longitude) with are solution of 0.5. The data have approximately 150 million forecast records (forecast average value of four output parameters during a 10-year period). Additional details of the GEFS forecast dataset can be found in [5]. The observation data are produced by the climatology-calibrated precipitation analysis (CCPA), which records the observed precipitation in the same area throughout the US every six hours from 2002 with a resolution of 0.125. These data are considered the ground-truth state of the actual weather state. The size of the data used is approximately 30 million observation records(observed precipitation at each interpolated grid point during a 10-years period). ",
      "data_code": { "fields": 1, "geometry": 1 }
    },
    "solution": [
      {
        "solution_category": "Interaction",
        "solution_axial": "Filtering",
        "solution_compoent": "",
        "axial_code": ["Filtering"],
        "componenet_code": ["filtering"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 67,
    "paper_title": "A Probability Density-Based Visual Analytics Approach to Forecast Bias Calibration",
    "pub_year": 2022,
    "domain": "Weather forecast",
    "requirement": {
      "requirement_text": "R.3 Reveal the Differences and Correlations Among Different Spatiotemporal Bias Patterns. E.2 commented that the current bias analysis methods only focus on a single location, i.e., calibrating precipitation at a single station instead of analyzing its correlation among its neighbors. Understanding the stability and uniqueness of the bias patterns can help explore and make informed decisions. Thus, E.2 wanted to observe the difference and correlations among different spatiotemporal bias patterns.",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "The data used in the cases comprise two types of datasets, namely, the forecast and observation data. The forecast data are produced by the Global Ensemble Forecast System (GEFS) global ensemble from the National Centers for Environmental Prediction in the United States. The dataset consists of 11 ensemble members at different convection parameters. Each member has approximately 8000 grids. The ensemble runs and generates forecast atmospheric para-meters daily from 1985, covering an area of [25:0436N, 53:1299N][66:094W, 125:625W] (latitude-longitude) with are solution of 0.5. The data have approximately 150 million forecast records (forecast average value of four output parameters during a 10-year period). Additional details of the GEFS forecast dataset can be found in [5]. The observation data are produced by the climatology-calibrated precipitation analysis (CCPA), which records the observed precipitation in the same area throughout the US every six hours from 2002 with a resolution of 0.125. These data are considered the ground-truth state of the actual weather state. The size of the data used is approximately 30 million observation records(observed precipitation at each interpolated grid point during a 10-years period). ",
      "data_code": {
        "fields": 1,
        "temporal": 1,
        "sequential": 1,
        "geometry": 1
      }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "AlgorithmCalculation,Clustering&Grouping",
        "solution_compoent": "kerneldensityestimation",
        "axial_code": ["Clustering&Grouping", "AlgorithmCalculation"],
        "componenet_code": [
          "clustering_and_grouping",
          "algorithmic_calculation",
          "clustering_and_grouping",
          "algorithmic_calculation"
        ]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 68,
    "paper_title": "A Probability Density-Based Visual Analytics Approach to Forecast Bias Calibration",
    "pub_year": 2022,
    "domain": "Weather forecast",
    "requirement": {
      "requirement_text": "R.3 Reveal the Differences and Correlations Among Different Spatiotemporal Bias Patterns. E.2 commented that the current bias analysis methods only focus on a single location, i.e., calibrating precipitation at a single station instead of analyzing its correlation among its neighbors. Understanding the stability and uniqueness of the bias patterns can help explore and make informed decisions. Thus, E.2 wanted to observe the difference and correlations among different spatiotemporal bias patterns.",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "The data used in the cases comprise two types of datasets, namely, the forecast and observation data. The forecast data are produced by the Global Ensemble Forecast System (GEFS) global ensemble from the National Centers for Environmental Prediction in the United States. The dataset consists of 11 ensemble members at different convection parameters. Each member has approximately 8000 grids. The ensemble runs and generates forecast atmospheric para-meters daily from 1985, covering an area of [25:0436N, 53:1299N][66:094W, 125:625W] (latitude-longitude) with are solution of 0.5. The data have approximately 150 million forecast records (forecast average value of four output parameters during a 10-year period). Additional details of the GEFS forecast dataset can be found in [5]. The observation data are produced by the climatology-calibrated precipitation analysis (CCPA), which records the observed precipitation in the same area throughout the US every six hours from 2002 with a resolution of 0.125. These data are considered the ground-truth state of the actual weather state. The size of the data used is approximately 30 million observation records(observed precipitation at each interpolated grid point during a 10-years period). ",
      "data_code": { "fields": 1, "geometry": 1 }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "AlgorithmCalculation,Clustering&Grouping",
        "solution_compoent": "kerneldensityestimation",
        "axial_code": ["Clustering&Grouping", "AlgorithmCalculation"],
        "componenet_code": [
          "clustering_and_grouping",
          "algorithmic_calculation",
          "clustering_and_grouping",
          "algorithmic_calculation"
        ]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 69,
    "paper_title": "A Probability Density-Based Visual Analytics Approach to Forecast Bias Calibration",
    "pub_year": 2022,
    "domain": "Weather forecast",
    "requirement": {
      "requirement_text": "R.4 Select Bias Patterns of Interest. E.1 needed to \ufb01lter out the bias patterns of interest from the data overview rapidly for a detailed analysis. Thus, a visual interactive mechanism and visual cues should be provided to assist him in selecting the bias patterns of interest.",
      "requirement_code": { "collect_evidence": 1 }
    },
    "data": {
      "data_text": "The data used in the cases comprise two types of datasets, namely, the forecast and observation data. The forecast data are produced by the Global Ensemble Forecast System (GEFS) global ensemble from the National Centers for Environmental Prediction in the United States. The dataset consists of 11 ensemble members at different convection parameters. Each member has approximately 8000 grids. The ensemble runs and generates forecast atmospheric para-meters daily from 1985, covering an area of [25:0436N, 53:1299N][66:094W, 125:625W] (latitude-longitude) with are solution of 0.5. The data have approximately 150 million forecast records (forecast average value of four output parameters during a 10-year period). Additional details of the GEFS forecast dataset can be found in [5]. The observation data are produced by the climatology-calibrated precipitation analysis (CCPA), which records the observed precipitation in the same area throughout the US every six hours from 2002 with a resolution of 0.125. These data are considered the ground-truth state of the actual weather state. The size of the data used is approximately 30 million observation records(observed precipitation at each interpolated grid point during a 10-years period). ",
      "data_code": {
        "fields": 1,
        "temporal": 1,
        "sequential": 1,
        "geometry": 1
      }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "AlgorithmCalculation,Clustering&Grouping",
        "solution_compoent": "kerneldensityestimation",
        "axial_code": ["Clustering&Grouping", "AlgorithmCalculation"],
        "componenet_code": [
          "clustering_and_grouping",
          "algorithmic_calculation",
          "clustering_and_grouping",
          "algorithmic_calculation"
        ]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 70,
    "paper_title": "A Probability Density-Based Visual Analytics Approach to Forecast Bias Calibration",
    "pub_year": 2022,
    "domain": "Weather forecast",
    "requirement": {
      "requirement_text": "R.5 Facilitate Parameter Comparison. To understand the similarities and differences among bias patterns, comparing the atmospheric parameters when generating the corresponding bias patterns is essential to understand the underlying causes of the bias patterns and to further support making informed decisions.",
      "requirement_code": { "explain_differences": 1 }
    },
    "data": {
      "data_text": "The data used in the cases comprise two types of datasets, namely, the forecast and observation data. The forecast data are produced by the Global Ensemble Forecast System (GEFS) global ensemble from the National Centers for Environmental Prediction in the United States. The dataset consists of 11 ensemble members at different convection parameters. Each member has approximately 8000 grids. The ensemble runs and generates forecast atmospheric para-meters daily from 1985, covering an area of [25:0436N, 53:1299N][66:094W, 125:625W] (latitude-longitude) with are solution of 0.5. The data have approximately 150 million forecast records (forecast average value of four output parameters during a 10-year period). Additional details of the GEFS forecast dataset can be found in [5]. The observation data are produced by the climatology-calibrated precipitation analysis (CCPA), which records the observed precipitation in the same area throughout the US every six hours from 2002 with a resolution of 0.125. These data are considered the ground-truth state of the actual weather state. The size of the data used is approximately 30 million observation records(observed precipitation at each interpolated grid point during a 10-years period). ",
      "data_code": {
        "fields": 1,
        "temporal": 1,
        "sequential": 1,
        "geometry": 1
      }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "AlgorithmCalculation,Clustering&Grouping",
        "solution_compoent": "kerneldensityestimation",
        "axial_code": ["Clustering&Grouping", "AlgorithmCalculation"],
        "componenet_code": [
          "clustering_and_grouping",
          "algorithmic_calculation",
          "clustering_and_grouping",
          "algorithmic_calculation"
        ]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 71,
    "paper_title": "A Probability Density-Based Visual Analytics Approach to Forecast Bias Calibration",
    "pub_year": 2022,
    "domain": "Weather forecast",
    "requirement": {
      "requirement_text": "R.5 Facilitate Parameter Comparison. To understand the similarities and differences among bias patterns, comparing the atmospheric parameters when generating the corresponding bias patterns is essential to understand the underlying causes of the bias patterns and to further support making informed decisions.",
      "requirement_code": { "explain_differences": 1 }
    },
    "data": {
      "data_text": "The data used in the cases comprise two types of datasets, namely, the forecast and observation data. The forecast data are produced by the Global Ensemble Forecast System (GEFS) global ensemble from the National Centers for Environmental Prediction in the United States. The dataset consists of 11 ensemble members at different convection parameters. Each member has approximately 8000 grids. The ensemble runs and generates forecast atmospheric para-meters daily from 1985, covering an area of [25:0436N, 53:1299N][66:094W, 125:625W] (latitude-longitude) with are solution of 0.5. The data have approximately 150 million forecast records (forecast average value of four output parameters during a 10-year period). Additional details of the GEFS forecast dataset can be found in [5]. The observation data are produced by the climatology-calibrated precipitation analysis (CCPA), which records the observed precipitation in the same area throughout the US every six hours from 2002 with a resolution of 0.125. These data are considered the ground-truth state of the actual weather state. The size of the data used is approximately 30 million observation records(observed precipitation at each interpolated grid point during a 10-years period). ",
      "data_code": {
        "fields": 1,
        "temporal": 1,
        "sequential": 1,
        "geometry": 1
      }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "AlgorithmCalculation,Clustering&Grouping",
        "solution_compoent": "kerneldensityestimation",
        "axial_code": ["Clustering&Grouping", "AlgorithmCalculation"],
        "componenet_code": [
          "clustering_and_grouping",
          "algorithmic_calculation",
          "clustering_and_grouping",
          "algorithmic_calculation"
        ]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 72,
    "paper_title": "A Probability Density-Based Visual Analytics Approach to Forecast Bias Calibration",
    "pub_year": 2022,
    "domain": "Weather forecast",
    "requirement": {
      "requirement_text": "R.6 Support Detailed Calibrations. According to E.1, the accuracy of weather forecasts largely depends on the subjective judgment of the forecaster in terms of his/her quali\ufb01cation, status, and working conditions, thereby increasing the unreliability of the calibrated results. Therefore, an interactive calibration mechanism is desired to support the combination of domain experts\u2019 experience and bias patterns extracted from historical data; in this manner, the accuracy of forecast calibration is improved.",
      "requirement_code": { "collect_evidence": 1 }
    },
    "data": {
      "data_text": "The data used in the cases comprise two types of datasets, namely, the forecast and observation data. The forecast data are produced by the Global Ensemble Forecast System (GEFS) global ensemble from the National Centers for Environmental Prediction in the United States. The dataset consists of 11 ensemble members at different convection parameters. Each member has approximately 8000 grids. The ensemble runs and generates forecast atmospheric para-meters daily from 1985, covering an area of [25:0436N, 53:1299N][66:094W, 125:625W] (latitude-longitude) with are solution of 0.5. The data have approximately 150 million forecast records (forecast average value of four output parameters during a 10-year period). Additional details of the GEFS forecast dataset can be found in [5]. The observation data are produced by the climatology-calibrated precipitation analysis (CCPA), which records the observed precipitation in the same area throughout the US every six hours from 2002 with a resolution of 0.125. These data are considered the ground-truth state of the actual weather state. The size of the data used is approximately 30 million observation records(observed precipitation at each interpolated grid point during a 10-years period). ",
      "data_code": {
        "fields": 1,
        "temporal": 1,
        "sequential": 1,
        "geometry": 1
      }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "AlgorithmCalculation,Clustering&Grouping",
        "solution_compoent": "kerneldensityestimation",
        "axial_code": ["Clustering&Grouping", "AlgorithmCalculation"],
        "componenet_code": [
          "clustering_and_grouping",
          "algorithmic_calculation",
          "clustering_and_grouping",
          "algorithmic_calculation"
        ]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 73,
    "paper_title": "Auditing the Sensitivity of Graph-based Ranking with Visual Analytics",
    "pub_year": 2021,
    "domain": "Graph mining",
    "requirement": {
      "requirement_text": "D1 Visualize the Instance-level Sensitivity. The system should visualize ranking and auditing results for all instances (T1). The view for summarizing the instance-level sensitivity should include the sensitivity index (T1.1) for all nodes with respect to the node attributes (T1.3).",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "A Facebook social circle, Political blogs, and a Reddit interaction network, The political blog dataset [24]. The dataset includes a topic citation graph between liberal and conservative blogs prior to the 2004 U.S. Presidential Election.",
      "data_code": { "network_and_trees": 1 }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "Excluding",
        "solution_compoent": "",
        "axial_code": ["Excluding"],
        "componenet_code": ["excluding"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 74,
    "paper_title": "Auditing the Sensitivity of Graph-based Ranking with Visual Analytics",
    "pub_year": 2021,
    "domain": "Graph mining",
    "requirement": {
      "requirement_text": "D2 Visualize the Effect of Perturbation. The system should be able to guide analysts to explore the perturbation effect of certain node\u2019s removal and support interactions such as sorting, searching and \ufb01ltering to inspect the auditing results and corresponding perturbation effects (T2, T3). This view should include:D2.1 In\ufb02uence Overview, which summarizes the perturbation\u2019s in\ufb02uence, the degree of ranking changes, and the proportion of nodes whose rankings are increased/decreased, etc. (T1.2, T2.1, T3).",
      "requirement_code": { "describe_observation_aggregate": 1 }
    },
    "data": {
      "data_text": "A Facebook social circle, Political blogs, and a Reddit interaction network, The political blog dataset [24]. The dataset includes a topic citation graph between liberal and conservative blogs prior to the 2004 U.S. Presidential Election.",
      "data_code": { "network_and_trees": 1 }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "Excluding,AlgorithmCalculation",
        "solution_compoent": "",
        "axial_code": ["Excluding", "AlgorithmCalculation"],
        "componenet_code": [
          "excluding",
          "algorithmic_calculation",
          "excluding",
          "algorithmic_calculation"
        ]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 75,
    "paper_title": "Auditing the Sensitivity of Graph-based Ranking with Visual Analytics",
    "pub_year": 2021,
    "domain": "Graph mining",
    "requirement": {
      "requirement_text": "D2 Visualize the Effect of Perturbation. The system should be able to guide analysts to explore the perturbation effect of certain node\u2019s removal and support interactions such as sorting, searching and \ufb01ltering to inspect the auditing results and corresponding perturbation effects (T2, T3). This view should include: D2.2 Distribution View, which shows how the ranking position changes caused by the perturbation are distributed for each instance and the ranking distribution for each group of nodes. (T2.2, T1.3)",
      "requirement_code": { "describe_observation_aggregate": 1 }
    },
    "data": {
      "data_text": "A Facebook social circle, Political blogs, and a Reddit interaction network, The political blog dataset [24]. The dataset includes a topic citation graph between liberal and conservative blogs prior to the 2004 U.S. Presidential Election.",
      "data_code": { "network_and_trees": 1 }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "Excluding",
        "solution_compoent": "",
        "axial_code": ["Excluding"],
        "componenet_code": ["excluding"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 76,
    "paper_title": "Auditing the Sensitivity of Graph-based Ranking with Visual Analytics",
    "pub_year": 2021,
    "domain": "Graph mining",
    "requirement": {
      "requirement_text": "D2 Visualize the Effect of Perturbation. The system should be able to guide analysts to explore the perturbation effect of certain node\u2019s removal and support interactions such as sorting, searching and \ufb01ltering to inspect the auditing results and corresponding perturbation effects (T2, T3). This view should include: D2.2 Distribution View, which shows how the ranking position changes caused by the perturbation are distributed for each instance and the ranking distribution for each group of nodes. (T2.2, T1.3)",
      "requirement_code": { "describe_observation_aggregate": 1 }
    },
    "data": {
      "data_text": "A Facebook social circle, Political blogs, and a Reddit interaction network, The political blog dataset [24]. The dataset includes a topic citation graph between liberal and conservative blogs prior to the 2004 U.S. Presidential Election.",
      "data_code": { "network_and_trees": 1 }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "Excluding",
        "solution_compoent": "",
        "axial_code": ["Excluding"],
        "componenet_code": ["excluding"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 77,
    "paper_title": "Auditing the Sensitivity of Graph-based Ranking with Visual Analytics",
    "pub_year": 2021,
    "domain": "Graph mining",
    "requirement": {
      "requirement_text": "D2 Visualize the Effect of Perturbation. The system should be able to guide analysts to explore the perturbation effect of certain node\u2019s removal and support interactions such as sorting, searching and \ufb01ltering to inspect the auditing results and corresponding perturbation effects (T2, T3). This view should include: D2.3 Ranking Change Detail View, which lists the in\ufb02uenced nodes for this perturbation. The view should support basic query operations, e.g., sorting, \ufb01ltering and searching, etc.(T2.1, T3)",
      "requirement_code": { "describe_observation_item": 1 }
    },
    "data": {
      "data_text": "A Facebook social circle, Political blogs, and a Reddit interaction network, The political blog dataset [24]. The dataset includes a topic citation graph between liberal and conservative blogs prior to the 2004 U.S. Presidential Election.",
      "data_code": { "network_and_trees": 1 }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "Excluding",
        "solution_compoent": "",
        "axial_code": ["Excluding"],
        "componenet_code": ["excluding"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 78,
    "paper_title": "Auditing the Sensitivity of Graph-based Ranking with Visual Analytics",
    "pub_year": 2021,
    "domain": "Graph mining",
    "requirement": {
      "requirement_text": "D2 Visualize the Effect of Perturbation. The system should be able to guide analysts to explore the perturbation effect of certain node\u2019s removal and support interactions such as sorting, searching and \ufb01ltering to inspect the auditing results and corresponding perturbation effects (T2, T3). This view should include: D2.4 Local In\ufb02uence Graph View, which illustrates the relationship between the ranking changes of nodes and the topological changes caused by the perturbation. (T2.3, T3)",
      "requirement_code": { "compare_entities": 1 }
    },
    "data": {
      "data_text": "A Facebook social circle, Political blogs, and a Reddit interaction network, The political blog dataset [24]. The dataset includes a topic citation graph between liberal and conservative blogs prior to the 2004 U.S. Presidential Election.",
      "data_code": { "network_and_trees": 1 }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "Excluding",
        "solution_compoent": "",
        "axial_code": ["Excluding"],
        "componenet_code": ["excluding"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 81,
    "paper_title": "TaxThemis: Interactive Mining and Exploration of Suspicious Tax Evasion Groups",
    "pub_year": 2021,
    "domain": "Tax evasion",
    "requirement": {
      "requirement_text": "R1 Enable interactive con\ufb01gurations for suspicious RPTTE groups detection. The automated algorithms signi\ufb01cantly improve the ef\ufb01ciency of the tax inspection procedure when they can successfully identify the most relevant suspicious RPTTE groups. As mentioned by E2, different users may want to explore RPTTE groups that satisfy speci\ufb01c conditions and would like to con\ufb01gure different parameters to extend or narrow down the scope of suspicious groups by \ufb01ltering taxpayers not tightly connected to the related party transactions. For example, different users may have an interest in detecting tax evasion groups from different periods, and exploring tax evasion groups with a speci\ufb01c relevance or complexity",
      "requirement_code": { "collect_evidence": 1 }
    },
    "data": {
      "data_text": "We provide a brief introduction to the three types of tax-related data used for tax evasion detection and anal_x0002_ysis. Taxpayer and Investor Profiles: A taxpayer is a person or organi_x0002_zation (such as a company) who needs to pay taxes to the government. An investor is a person or organization that buys shares in taxpayers and holds voting rights. Our collaborator offered us the profile infor_x0002_mation of each taxpayer and the corresponding investors. The taxpayer profile describes the business nature of taxpayers, such as industry, major merchandise, ownership type, and so on. The corresponding investor information includes investor entity type, investment amount, and share ratio. There are over 4 million taxpayers and 0.9 million investors in the entire dataset provided by our collaborator. This infor_x0002_mation helps us understand the topology of investment relationships of all taxpayers. Invoice Information: The invoice information is collected to record the details of each transaction between taxpayers. We obtained 14 million Value-Added-Tax (VAT) invoices in Shaanxi Province and the time range of the invoices is from Jan 1, 2014 to Dec 31, 2015. Each invoice record consists of five attributes: date, seller, buyer, VAT tax amount, and the transaction amount. The buyer and seller in an invoice record are two taxpayers, of whom, at least one of them, are registered in Shaanxi Province. The invoices explain the trading rela_x0002_tionships among the taxpayers and show the cash flow of the taxpayers regarding transactions. Audit Records: Audit records refer to the results after a tax admin_x0002_istration officer conducts an official examination on a taxpayer\u2019s finan_x0002_cial account. Our collaborators offered us historical audit records to help analyze each case and develop our system. Each auditing record consists of audit date, violation type, case description, action taken, and tax payable. Together with the taxpayer profile, we can trace the tax evasion history of taxpayers.",
      "data_code": {
        "tables": 1,
        "text": 1,
        "categorical": 1,
        "sequential": 1,
        "network_and_trees": 1,
        "temporal": 1
      }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "AlgorithmCalculation",
        "solution_compoent": "",
        "axial_code": ["AlgorithmCalculation"],
        "componenet_code": ["algorithmic_calculation"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 82,
    "paper_title": "TaxThemis: Interactive Mining and Exploration of Suspicious Tax Evasion Groups",
    "pub_year": 2021,
    "domain": "Tax evasion",
    "requirement": {
      "requirement_text": "R1 Enable interactive con\ufb01gurations for suspicious RPTTE groups detection. The automated algorithms signi\ufb01cantly improve the ef\ufb01ciency of the tax inspection procedure when they can successfully identify the most relevant suspicious RPTTE groups. As mentioned by E2, different users may want to explore RPTTE groups that satisfy speci\ufb01c conditions and would like to con\ufb01gure different parameters to extend or narrow down the scope of suspicious groups by \ufb01ltering taxpayers not tightly connected to the related party transactions. For example, different users may have an interest in detecting tax evasion groups from different periods, and exploring tax evasion groups with a speci\ufb01c relevance or complexity",
      "requirement_code": { "collect_evidence": 1 }
    },
    "data": {
      "data_text": "We provide a brief introduction to the three types of tax-related data used for tax evasion detection and anal_x0002_ysis. Taxpayer and Investor Profiles: A taxpayer is a person or organi_x0002_zation (such as a company) who needs to pay taxes to the government. An investor is a person or organization that buys shares in taxpayers and holds voting rights. Our collaborator offered us the profile infor_x0002_mation of each taxpayer and the corresponding investors. The taxpayer profile describes the business nature of taxpayers, such as industry, major merchandise, ownership type, and so on. The corresponding investor information includes investor entity type, investment amount, and share ratio. There are over 4 million taxpayers and 0.9 million investors in the entire dataset provided by our collaborator. This infor_x0002_mation helps us understand the topology of investment relationships of all taxpayers. Invoice Information: The invoice information is collected to record the details of each transaction between taxpayers. We obtained 14 million Value-Added-Tax (VAT) invoices in Shaanxi Province and the time range of the invoices is from Jan 1, 2014 to Dec 31, 2015. Each invoice record consists of five attributes: date, seller, buyer, VAT tax amount, and the transaction amount. The buyer and seller in an invoice record are two taxpayers, of whom, at least one of them, are registered in Shaanxi Province. The invoices explain the trading rela_x0002_tionships among the taxpayers and show the cash flow of the taxpayers regarding transactions. Audit Records: Audit records refer to the results after a tax admin_x0002_istration officer conducts an official examination on a taxpayer\u2019s finan_x0002_cial account. Our collaborators offered us historical audit records to help analyze each case and develop our system. Each auditing record consists of audit date, violation type, case description, action taken, and tax payable. Together with the taxpayer profile, we can trace the tax evasion history of taxpayers.",
      "data_code": {
        "tables": 1,
        "text": 1,
        "categorical": 1,
        "sequential": 1,
        "network_and_trees": 1,
        "temporal": 1
      }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "AlgorithmCalculation",
        "solution_compoent": "",
        "axial_code": ["AlgorithmCalculation"],
        "componenet_code": ["algorithmic_calculation"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 83,
    "paper_title": "TaxThemis: Interactive Mining and Exploration of Suspicious Tax Evasion Groups",
    "pub_year": 2021,
    "domain": "Tax evasion",
    "requirement": {
      "requirement_text": "R1 Enable interactive con\ufb01gurations for suspicious RPTTE groups detection. The automated algorithms signi\ufb01cantly improve the ef\ufb01ciency of the tax inspection procedure when they can successfully identify the most relevant suspicious RPTTE groups. As mentioned by E2, different users may want to explore RPTTE groups that satisfy speci\ufb01c conditions and would like to con\ufb01gure different parameters to extend or narrow down the scope of suspicious groups by \ufb01ltering taxpayers not tightly connected to the related party transactions. For example, different users may have an interest in detecting tax evasion groups from different periods, and exploring tax evasion groups with a speci\ufb01c relevance or complexity",
      "requirement_code": { "collect_evidence": 1 }
    },
    "data": {
      "data_text": "We provide a brief introduction to the three types of tax-related data used for tax evasion detection and anal_x0002_ysis. Taxpayer and Investor Profiles: A taxpayer is a person or organi_x0002_zation (such as a company) who needs to pay taxes to the government. An investor is a person or organization that buys shares in taxpayers and holds voting rights. Our collaborator offered us the profile infor_x0002_mation of each taxpayer and the corresponding investors. The taxpayer profile describes the business nature of taxpayers, such as industry, major merchandise, ownership type, and so on. The corresponding investor information includes investor entity type, investment amount, and share ratio. There are over 4 million taxpayers and 0.9 million investors in the entire dataset provided by our collaborator. This infor_x0002_mation helps us understand the topology of investment relationships of all taxpayers. Invoice Information: The invoice information is collected to record the details of each transaction between taxpayers. We obtained 14 million Value-Added-Tax (VAT) invoices in Shaanxi Province and the time range of the invoices is from Jan 1, 2014 to Dec 31, 2015. Each invoice record consists of five attributes: date, seller, buyer, VAT tax amount, and the transaction amount. The buyer and seller in an invoice record are two taxpayers, of whom, at least one of them, are registered in Shaanxi Province. The invoices explain the trading rela_x0002_tionships among the taxpayers and show the cash flow of the taxpayers regarding transactions. Audit Records: Audit records refer to the results after a tax admin_x0002_istration officer conducts an official examination on a taxpayer\u2019s finan_x0002_cial account. Our collaborators offered us historical audit records to help analyze each case and develop our system. Each auditing record consists of audit date, violation type, case description, action taken, and tax payable. Together with the taxpayer profile, we can trace the tax evasion history of taxpayers.",
      "data_code": {
        "tables": 1,
        "text": 1,
        "categorical": 1,
        "sequential": 1,
        "network_and_trees": 1,
        "temporal": 1
      }
    },
    "solution": [
      {
        "solution_category": "Interaction",
        "solution_axial": "Participation/Collaboration",
        "solution_compoent": "",
        "axial_code": ["Participation/Collaboration"],
        "componenet_code": ["participation/collaboration"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 84,
    "paper_title": "TaxThemis: Interactive Mining and Exploration of Suspicious Tax Evasion Groups",
    "pub_year": 2021,
    "domain": "Tax evasion",
    "requirement": {
      "requirement_text": "R1 Enable interactive con\ufb01gurations for suspicious RPTTE groups detection. The automated algorithms signi\ufb01cantly improve the ef\ufb01ciency of the tax inspection procedure when they can successfully identify the most relevant suspicious RPTTE groups. As mentioned by E2, different users may want to explore RPTTE groups that satisfy speci\ufb01c conditions and would like to con\ufb01gure different parameters to extend or narrow down the scope of suspicious groups by \ufb01ltering taxpayers not tightly connected to the related party transactions. For example, different users may have an interest in detecting tax evasion groups from different periods, and exploring tax evasion groups with a speci\ufb01c relevance or complexity",
      "requirement_code": { "collect_evidence": 1 }
    },
    "data": {
      "data_text": "We provide a brief introduction to the three types of tax-related data used for tax evasion detection and anal_x0002_ysis. Taxpayer and Investor Profiles: A taxpayer is a person or organi_x0002_zation (such as a company) who needs to pay taxes to the government. An investor is a person or organization that buys shares in taxpayers and holds voting rights. Our collaborator offered us the profile infor_x0002_mation of each taxpayer and the corresponding investors. The taxpayer profile describes the business nature of taxpayers, such as industry, major merchandise, ownership type, and so on. The corresponding investor information includes investor entity type, investment amount, and share ratio. There are over 4 million taxpayers and 0.9 million investors in the entire dataset provided by our collaborator. This infor_x0002_mation helps us understand the topology of investment relationships of all taxpayers. Invoice Information: The invoice information is collected to record the details of each transaction between taxpayers. We obtained 14 million Value-Added-Tax (VAT) invoices in Shaanxi Province and the time range of the invoices is from Jan 1, 2014 to Dec 31, 2015. Each invoice record consists of five attributes: date, seller, buyer, VAT tax amount, and the transaction amount. The buyer and seller in an invoice record are two taxpayers, of whom, at least one of them, are registered in Shaanxi Province. The invoices explain the trading rela_x0002_tionships among the taxpayers and show the cash flow of the taxpayers regarding transactions. Audit Records: Audit records refer to the results after a tax admin_x0002_istration officer conducts an official examination on a taxpayer\u2019s finan_x0002_cial account. Our collaborators offered us historical audit records to help analyze each case and develop our system. Each auditing record consists of audit date, violation type, case description, action taken, and tax payable. Together with the taxpayer profile, we can trace the tax evasion history of taxpayers.",
      "data_code": {
        "tables": 1,
        "text": 1,
        "categorical": 1,
        "sequential": 1,
        "network_and_trees": 1,
        "temporal": 1
      }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "AlgorithmCalculation",
        "solution_compoent": "",
        "axial_code": ["AlgorithmCalculation"],
        "componenet_code": ["algorithmic_calculation"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 85,
    "paper_title": "TaxThemis: Interactive Mining and Exploration of Suspicious Tax Evasion Groups",
    "pub_year": 2021,
    "domain": "Tax evasion",
    "requirement": {
      "requirement_text": "R2 Rank suspicious tax evasion groups with multiple criteria. Given the vast number of suspicious groups, it is critical to help users quickly locate groups with the highest risk level. The system should support the sorting of the groups based on multiple criteria which re\ufb02ects the suspicion in different dimensions. For example, according to E1\u2019s audit experience, one of the major suspicion criteria is the existence of historical tax evasion records because those groups are likely to commit tax evasion again.",
      "requirement_code": { "compare_entities": 1 }
    },
    "data": {
      "data_text": "We provide a brief introduction to the three types of tax-related data used for tax evasion detection and anal_x0002_ysis. Taxpayer and Investor Profiles: A taxpayer is a person or organi_x0002_zation (such as a company) who needs to pay taxes to the government. An investor is a person or organization that buys shares in taxpayers and holds voting rights. Our collaborator offered us the profile infor_x0002_mation of each taxpayer and the corresponding investors. The taxpayer profile describes the business nature of taxpayers, such as industry, major merchandise, ownership type, and so on. The corresponding investor information includes investor entity type, investment amount, and share ratio. There are over 4 million taxpayers and 0.9 million investors in the entire dataset provided by our collaborator. This infor_x0002_mation helps us understand the topology of investment relationships of all taxpayers. Invoice Information: The invoice information is collected to record the details of each transaction between taxpayers. We obtained 14 million Value-Added-Tax (VAT) invoices in Shaanxi Province and the time range of the invoices is from Jan 1, 2014 to Dec 31, 2015. Each invoice record consists of five attributes: date, seller, buyer, VAT tax amount, and the transaction amount. The buyer and seller in an invoice record are two taxpayers, of whom, at least one of them, are registered in Shaanxi Province. The invoices explain the trading rela_x0002_tionships among the taxpayers and show the cash flow of the taxpayers regarding transactions. Audit Records: Audit records refer to the results after a tax admin_x0002_istration officer conducts an official examination on a taxpayer\u2019s finan_x0002_cial account. Our collaborators offered us historical audit records to help analyze each case and develop our system. Each auditing record consists of audit date, violation type, case description, action taken, and tax payable. Together with the taxpayer profile, we can trace the tax evasion history of taxpayers.",
      "data_code": {
        "tables": 1,
        "text": 1,
        "categorical": 1,
        "sequential": 1,
        "network_and_trees": 1,
        "temporal": 1
      }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "AlgorithmCalculation",
        "solution_compoent": "",
        "axial_code": ["AlgorithmCalculation"],
        "componenet_code": ["algorithmic_calculation"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 86,
    "paper_title": "TaxThemis: Interactive Mining and Exploration of Suspicious Tax Evasion Groups",
    "pub_year": 2021,
    "domain": "Tax evasion",
    "requirement": {
      "requirement_text": "R2 Rank suspicious tax evasion groups with multiple criteria. Given the vast number of suspicious groups, it is critical to help users quickly locate groups with the highest risk level. The system should support the sorting of the groups based on multiple criteria which re\ufb02ects the suspicion in different dimensions. For example, according to E1\u2019s audit experience, one of the major suspicion criteria is the existence of historical tax evasion records because those groups are likely to commit tax evasion again.",
      "requirement_code": { "compare_entities": 1 }
    },
    "data": {
      "data_text": "We provide a brief introduction to the three types of tax-related data used for tax evasion detection and anal_x0002_ysis. Taxpayer and Investor Profiles: A taxpayer is a person or organi_x0002_zation (such as a company) who needs to pay taxes to the government. An investor is a person or organization that buys shares in taxpayers and holds voting rights. Our collaborator offered us the profile infor_x0002_mation of each taxpayer and the corresponding investors. The taxpayer profile describes the business nature of taxpayers, such as industry, major merchandise, ownership type, and so on. The corresponding investor information includes investor entity type, investment amount, and share ratio. There are over 4 million taxpayers and 0.9 million investors in the entire dataset provided by our collaborator. This infor_x0002_mation helps us understand the topology of investment relationships of all taxpayers. Invoice Information: The invoice information is collected to record the details of each transaction between taxpayers. We obtained 14 million Value-Added-Tax (VAT) invoices in Shaanxi Province and the time range of the invoices is from Jan 1, 2014 to Dec 31, 2015. Each invoice record consists of five attributes: date, seller, buyer, VAT tax amount, and the transaction amount. The buyer and seller in an invoice record are two taxpayers, of whom, at least one of them, are registered in Shaanxi Province. The invoices explain the trading rela_x0002_tionships among the taxpayers and show the cash flow of the taxpayers regarding transactions. Audit Records: Audit records refer to the results after a tax admin_x0002_istration officer conducts an official examination on a taxpayer\u2019s finan_x0002_cial account. Our collaborators offered us historical audit records to help analyze each case and develop our system. Each auditing record consists of audit date, violation type, case description, action taken, and tax payable. Together with the taxpayer profile, we can trace the tax evasion history of taxpayers.",
      "data_code": {
        "tables": 1,
        "text": 1,
        "categorical": 1,
        "sequential": 1,
        "network_and_trees": 1,
        "temporal": 1
      }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "AlgorithmCalculation",
        "solution_compoent": "",
        "axial_code": ["AlgorithmCalculation"],
        "componenet_code": ["algorithmic_calculation"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 87,
    "paper_title": "TaxThemis: Interactive Mining and Exploration of Suspicious Tax Evasion Groups",
    "pub_year": 2021,
    "domain": "Tax evasion",
    "requirement": {
      "requirement_text": "R3 Support the interactive exploration of the common bene\ufb01cial owners of taxpayers who conduct the related party transactions and their attributes. As at least one common bene\ufb01cial owner will bene\ufb01t from RPTTE behaviors, exploring the investment and trading relationships helps users to understand how the tax evasion scheme works among taxpayers. In addition, the attributes of taxpayers such as historical tax evasion records provide the tax administration of\ufb01cers a context for suspicion and risk evaluation. Therefore, the experts require that all taxpayer with a common bene\ufb01cial owner should also be clearly visualized, facilitating the deep exploration and inspection of any highly suspicious related party transactions.",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "We provide a brief introduction to the three types of tax-related data used for tax evasion detection and anal_x0002_ysis. Taxpayer and Investor Profiles: A taxpayer is a person or organi_x0002_zation (such as a company) who needs to pay taxes to the government. An investor is a person or organization that buys shares in taxpayers and holds voting rights. Our collaborator offered us the profile infor_x0002_mation of each taxpayer and the corresponding investors. The taxpayer profile describes the business nature of taxpayers, such as industry, major merchandise, ownership type, and so on. The corresponding investor information includes investor entity type, investment amount, and share ratio. There are over 4 million taxpayers and 0.9 million investors in the entire dataset provided by our collaborator. This infor_x0002_mation helps us understand the topology of investment relationships of all taxpayers. Invoice Information: The invoice information is collected to record the details of each transaction between taxpayers. We obtained 14 million Value-Added-Tax (VAT) invoices in Shaanxi Province and the time range of the invoices is from Jan 1, 2014 to Dec 31, 2015. Each invoice record consists of five attributes: date, seller, buyer, VAT tax amount, and the transaction amount. The buyer and seller in an invoice record are two taxpayers, of whom, at least one of them, are registered in Shaanxi Province. The invoices explain the trading rela_x0002_tionships among the taxpayers and show the cash flow of the taxpayers regarding transactions. Audit Records: Audit records refer to the results after a tax admin_x0002_istration officer conducts an official examination on a taxpayer\u2019s finan_x0002_cial account. Our collaborators offered us historical audit records to help analyze each case and develop our system. Each auditing record consists of audit date, violation type, case description, action taken, and tax payable. Together with the taxpayer profile, we can trace the tax evasion history of taxpayers.",
      "data_code": {
        "tables": 1,
        "text": 1,
        "categorical": 1,
        "sequential": 1,
        "network_and_trees": 1,
        "temporal": 1
      }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "AlgorithmCalculation",
        "solution_compoent": "",
        "axial_code": ["AlgorithmCalculation"],
        "componenet_code": ["algorithmic_calculation"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 88,
    "paper_title": "TaxThemis: Interactive Mining and Exploration of Suspicious Tax Evasion Groups",
    "pub_year": 2021,
    "domain": "Tax evasion",
    "requirement": {
      "requirement_text": "R4 Provide convenient pro\ufb01t analysis of taxpayers that conducted related party transactions. To facilitate the tax inspection process, the users need to know how the taxpayers redistribute their pro\ufb01ts through RPTTE behaviors. It is also important to present the related party transaction as evidence for users to quickly make audit decisions. Both E1 and E2 agree that the evaluation of suspicious related party transactions is challenging because tax evaders try their best to disguise their transactions as legal ones. However, the intent of such transactions must be re\ufb02ected in reported pro\ufb01ts, which leads to a lower tax burden. Therefore, pro\ufb01t analysis can act as the critical context to help users in decision-making. The visualization should display the pro\ufb01t status of the taxpayers, as the analysis of pro\ufb01t variations can reveal whether the related party transaction behaviors affect the overall tax burden.",
      "requirement_code": { "describe_observation_aggregate": 1 }
    },
    "data": {
      "data_text": "We provide a brief introduction to the three types of tax-related data used for tax evasion detection and anal_x0002_ysis. Taxpayer and Investor Profiles: A taxpayer is a person or organi_x0002_zation (such as a company) who needs to pay taxes to the government. An investor is a person or organization that buys shares in taxpayers and holds voting rights. Our collaborator offered us the profile infor_x0002_mation of each taxpayer and the corresponding investors. The taxpayer profile describes the business nature of taxpayers, such as industry, major merchandise, ownership type, and so on. The corresponding investor information includes investor entity type, investment amount, and share ratio. There are over 4 million taxpayers and 0.9 million investors in the entire dataset provided by our collaborator. This infor_x0002_mation helps us understand the topology of investment relationships of all taxpayers. Invoice Information: The invoice information is collected to record the details of each transaction between taxpayers. We obtained 14 million Value-Added-Tax (VAT) invoices in Shaanxi Province and the time range of the invoices is from Jan 1, 2014 to Dec 31, 2015. Each invoice record consists of five attributes: date, seller, buyer, VAT tax amount, and the transaction amount. The buyer and seller in an invoice record are two taxpayers, of whom, at least one of them, are registered in Shaanxi Province. The invoices explain the trading rela_x0002_tionships among the taxpayers and show the cash flow of the taxpayers regarding transactions. Audit Records: Audit records refer to the results after a tax admin_x0002_istration officer conducts an official examination on a taxpayer\u2019s finan_x0002_cial account. Our collaborators offered us historical audit records to help analyze each case and develop our system. Each auditing record consists of audit date, violation type, case description, action taken, and tax payable. Together with the taxpayer profile, we can trace the tax evasion history of taxpayers.",
      "data_code": {
        "tables": 1,
        "text": 1,
        "categorical": 1,
        "sequential": 1,
        "network_and_trees": 1,
        "temporal": 1
      }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "AlgorithmCalculation",
        "solution_compoent": "",
        "axial_code": ["AlgorithmCalculation"],
        "componenet_code": ["algorithmic_calculation"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 89,
    "paper_title": "Githru: Visual Analytics for Understanding Software Development History Through Git Metadata Analysis",
    "pub_year": 2021,
    "domain": "git",
    "requirement": {
      "requirement_text": "R1: Provide an overview. The system should present an overview of development history where (a) the commits are grouped according to speci\ufb01c criteria to avoid examining each commit individually; (b) the visualization of a group encodes its size and topological position compared to others; and (c) the summary of the selected group(s) is presented interactively (T1).",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "an in-house repository dataset, the public GitHub repository realm-java",
      "data_code": { "network_and_trees": 1, "sequential": 1, "temporal": 1 }
    },
    "solution": [
      {
        "solution_category": "Visualization",
        "solution_axial": "Nesting",
        "solution_compoent": "network+vector",
        "axial_code": ["Nesting"],
        "componenet_code": ["network", "vector"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 90,
    "paper_title": "Githru: Visual Analytics for Understanding Software Development History Through Git Metadata Analysis",
    "pub_year": 2021,
    "domain": "git",
    "requirement": {
      "requirement_text": "R1: Provide an overview. The system should present an overview of development history where (a) the commits are grouped according to speci\ufb01c criteria to avoid examining each commit individually; (b) the visualization of a group encodes its size and topological position compared to others; and (c) the summary of the selected group(s) is presented interactively (T1).",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "an in-house repository dataset, the public GitHub repository realm-java",
      "data_code": { "network_and_trees": 1, "sequential": 1, "temporal": 1 }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "Clustering&Grouping",
        "solution_compoent": "",
        "axial_code": ["Clustering&Grouping"],
        "componenet_code": ["clustering_and_grouping"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 91,
    "paper_title": "Githru: Visual Analytics for Understanding Software Development History Through Git Metadata Analysis",
    "pub_year": 2021,
    "domain": "git",
    "requirement": {
      "requirement_text": "R1: Provide an overview. The system should present an overview of development history where (a) the commits are grouped according to speci\ufb01c criteria to avoid examining each commit individually; (b) the visualization of a group encodes its size and topological position compared to others; and (c) the summary of the selected group(s) is presented interactively (T1).",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "an in-house repository dataset, the public GitHub repository realm-java",
      "data_code": { "network_and_trees": 1, "sequential": 1, "temporal": 1 }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "Clustering&Grouping",
        "solution_compoent": "Clusterneighboringcommitsinstemstopreservetemporalsequence,topology.SAWmodelforsimilarity.",
        "axial_code": ["Clustering&Grouping"],
        "componenet_code": ["clustering_and_grouping"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 92,
    "paper_title": "Githru: Visual Analytics for Understanding Software Development History Through Git Metadata Analysis",
    "pub_year": 2021,
    "domain": "git",
    "requirement": {
      "requirement_text": "R1: Provide an overview. The system should present an overview of development history where (a) the commits are grouped according to speci\ufb01c criteria to avoid examining each commit individually; (b) the visualization of a group encodes its size and topological position compared to others; and (c) the summary of the selected group(s) is presented interactively (T1).",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "an in-house repository dataset, the public GitHub repository realm-java",
      "data_code": { "network_and_trees": 1, "sequential": 1, "temporal": 1 }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "Clustering&Grouping",
        "solution_compoent": "Clusternon-neighborcommits,simplifystructureoptionally.",
        "axial_code": ["Clustering&Grouping"],
        "componenet_code": ["clustering_and_grouping"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 93,
    "paper_title": "Githru: Visual Analytics for Understanding Software Development History Through Git Metadata Analysis",
    "pub_year": 2021,
    "domain": "git",
    "requirement": {
      "requirement_text": "R1: Provide an overview. The system should present an overview of development history where (a) the commits are grouped according to speci\ufb01c criteria to avoid examining each commit individually; (b) the visualization of a group encodes its size and topological position compared to others; and (c) the summary of the selected group(s) is presented interactively (T1).",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "an in-house repository dataset, the public GitHub repository realm-java",
      "data_code": { "network_and_trees": 1, "sequential": 1, "temporal": 1 }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "Clustering&Grouping",
        "solution_compoent": "",
        "axial_code": ["Clustering&Grouping"],
        "componenet_code": ["clustering_and_grouping"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 94,
    "paper_title": "Githru: Visual Analytics for Understanding Software Development History Through Git Metadata Analysis",
    "pub_year": 2021,
    "domain": "git",
    "requirement": {
      "requirement_text": "R1: Provide an overview. The system should present an overview of development history where (a) the commits are grouped according to speci\ufb01c criteria to avoid examining each commit individually; (b) the visualization of a group encodes its size and topological position compared to others; and (c) the summary of the selected group(s) is presented interactively (T1).",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "an in-house repository dataset, the public GitHub repository realm-java",
      "data_code": { "network_and_trees": 1, "sequential": 1, "temporal": 1 }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "Clustering&Grouping",
        "solution_compoent": "",
        "axial_code": ["Clustering&Grouping"],
        "componenet_code": ["clustering_and_grouping"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 95,
    "paper_title": "Githru: Visual Analytics for Understanding Software Development History Through Git Metadata Analysis",
    "pub_year": 2021,
    "domain": "git",
    "requirement": {
      "requirement_text": "R1: Provide an overview. The system should present an overview of development history where (a) the commits are grouped according to speci\ufb01c criteria to avoid examining each commit individually; (b) the visualization of a group encodes its size and topological position compared to others; and (c) the summary of the selected group(s) is presented interactively (T1).",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "an in-house repository dataset, the public GitHub repository realm-java",
      "data_code": { "network_and_trees": 1, "sequential": 1, "temporal": 1 }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "Clustering&Grouping",
        "solution_compoent": "",
        "axial_code": ["Clustering&Grouping"],
        "componenet_code": ["clustering_and_grouping"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 96,
    "paper_title": "Githru: Visual Analytics for Understanding Software Development History Through Git Metadata Analysis",
    "pub_year": 2021,
    "domain": "git",
    "requirement": {
      "requirement_text": "R1: Provide an overview. The system should present an overview of development history where (a) the commits are grouped according to speci\ufb01c criteria to avoid examining each commit individually; (b) the visualization of a group encodes its size and topological position compared to others; and (c) the summary of the selected group(s) is presented interactively (T1).",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "an in-house repository dataset, the public GitHub repository realm-java",
      "data_code": { "network_and_trees": 1, "sequential": 1, "temporal": 1 }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "Clustering&Grouping",
        "solution_compoent": "",
        "axial_code": ["Clustering&Grouping"],
        "componenet_code": ["clustering_and_grouping"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 97,
    "paper_title": "Githru: Visual Analytics for Understanding Software Development History Through Git Metadata Analysis",
    "pub_year": 2021,
    "domain": "git",
    "requirement": {
      "requirement_text": "R2: Visualize a graph while preserving topology. The graph representing the abstracted data should be visualized in an interpretable form. The graph should contain abstracted topological data that include (a) the temporal sequence of each node (i.e., commit) and (b) branch information and merge relation; and (c) the graph should be navigable with minimal interactions (T2).",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "an in-house repository dataset, the public GitHub repository realm-java",
      "data_code": { "network_and_trees": 1, "sequential": 1, "temporal": 1 }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "Clustering&Grouping",
        "solution_compoent": "",
        "axial_code": ["Clustering&Grouping"],
        "componenet_code": ["clustering_and_grouping"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 98,
    "paper_title": "Githru: Visual Analytics for Understanding Software Development History Through Git Metadata Analysis",
    "pub_year": 2021,
    "domain": "git",
    "requirement": {
      "requirement_text": "R2: Visualize a graph while preserving topology. The graph representing the abstracted data should be visualized in an interpretable form. The graph should contain abstracted topological data that include (a) the temporal sequence of each node (i.e., commit) and (b) branch information and merge relation; and (c) the graph should be navigable with minimal interactions (T2).",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "an in-house repository dataset, the public GitHub repository realm-java",
      "data_code": { "network_and_trees": 1, "sequential": 1, "temporal": 1 }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "Clustering&Grouping",
        "solution_compoent": "",
        "axial_code": ["Clustering&Grouping"],
        "componenet_code": ["clustering_and_grouping"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 99,
    "paper_title": "Githru: Visual Analytics for Understanding Software Development History Through Git Metadata Analysis",
    "pub_year": 2021,
    "domain": "git",
    "requirement": {
      "requirement_text": "R2: Visualize a graph while preserving topology. The graph representing the abstracted data should be visualized in an interpretable form. The graph should contain abstracted topological data that include (a) the temporal sequence of each node (i.e., commit) and (b) branch information and merge relation; and (c) the graph should be navigable with minimal interactions (T2).",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "an in-house repository dataset, the public GitHub repository realm-java",
      "data_code": { "network_and_trees": 1, "sequential": 1, "temporal": 1 }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "Clustering&Grouping",
        "solution_compoent": "",
        "axial_code": ["Clustering&Grouping"],
        "componenet_code": ["clustering_and_grouping"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 100,
    "paper_title": "Githru: Visual Analytics for Understanding Software Development History Through Git Metadata Analysis",
    "pub_year": 2021,
    "domain": "git",
    "requirement": {
      "requirement_text": "R2: Visualize a graph while preserving topology. The graph representing the abstracted data should be visualized in an interpretable form. The graph should contain abstracted topological data that include (a) the temporal sequence of each node (i.e., commit) and (b) branch information and merge relation; and (c) the graph should be navigable with minimal interactions (T2).",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "an in-house repository dataset, the public GitHub repository realm-java",
      "data_code": { "network_and_trees": 1, "sequential": 1, "temporal": 1 }
    },
    "solution": [
      {
        "solution_category": "Interaction",
        "solution_axial": "Participation/Collaboration",
        "solution_compoent": "",
        "axial_code": ["Participation/Collaboration"],
        "componenet_code": ["participation/collaboration"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 101,
    "paper_title": "Githru: Visual Analytics for Understanding Software Development History Through Git Metadata Analysis",
    "pub_year": 2021,
    "domain": "git",
    "requirement": {
      "requirement_text": "R3: Support \ufb01ltering by and searching for details. Depending on the user query, which can be a keyword or a temporal range, the corresponding commits should be (a) \ufb01ltered in or out and (b) searched and highlighted to reduce the exploration scope. Moreover, users should be able to (c) browse the details of each commit (T3).",
      "requirement_code": { "collect_evidence": 1 }
    },
    "data": {
      "data_text": "an in-house repository dataset, the public GitHub repository realm-java",
      "data_code": { "network_and_trees": 1, "sequential": 1, "temporal": 1 }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "Clustering&Grouping",
        "solution_compoent": "",
        "axial_code": ["Clustering&Grouping"],
        "componenet_code": ["clustering_and_grouping"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 102,
    "paper_title": "Githru: Visual Analytics for Understanding Software Development History Through Git Metadata Analysis",
    "pub_year": 2021,
    "domain": "git",
    "requirement": {
      "requirement_text": "R3: Support \ufb01ltering by and searching for details. Depending on the user query, which can be a keyword or a temporal range, the corresponding commits should be (a) \ufb01ltered in or out and (b) searched and highlighted to reduce the exploration scope. Moreover, users should be able to (c) browse the details of each commit (T3).",
      "requirement_code": { "collect_evidence": 1 }
    },
    "data": {
      "data_text": "an in-house repository dataset, the public GitHub repository realm-java",
      "data_code": { "network_and_trees": 1, "sequential": 1, "temporal": 1 }
    },
    "solution": [
      {
        "solution_category": "Interaction",
        "solution_axial": "Participation/Collaboration",
        "solution_compoent": "",
        "axial_code": ["Participation/Collaboration"],
        "componenet_code": ["participation/collaboration"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 103,
    "paper_title": "Githru: Visual Analytics for Understanding Software Development History Through Git Metadata Analysis",
    "pub_year": 2021,
    "domain": "git",
    "requirement": {
      "requirement_text": "R3: Support \ufb01ltering by and searching for details. Depending on the user query, which can be a keyword or a temporal range, the corresponding commits should be (a) \ufb01ltered in or out and (b) searched and highlighted to reduce the exploration scope. Moreover, users should be able to (c) browse the details of each commit (T3).",
      "requirement_code": { "collect_evidence": 1 }
    },
    "data": {
      "data_text": "an in-house repository dataset, the public GitHub repository realm-java",
      "data_code": { "network_and_trees": 1, "sequential": 1, "temporal": 1 }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "Clustering&Grouping",
        "solution_compoent": "",
        "axial_code": ["Clustering&Grouping"],
        "componenet_code": ["clustering_and_grouping"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 104,
    "paper_title": "Githru: Visual Analytics for Understanding Software Development History Through Git Metadata Analysis",
    "pub_year": 2021,
    "domain": "git",
    "requirement": {
      "requirement_text": "R3: Support \ufb01ltering by and searching for details. Depending on the user query, which can be a keyword or a temporal range, the corresponding commits should be (a) \ufb01ltered in or out and (b) searched and highlighted to reduce the exploration scope. Moreover, users should be able to (c) browse the details of each commit (T3).",
      "requirement_code": { "collect_evidence": 1 }
    },
    "data": {
      "data_text": "an in-house repository dataset, the public GitHub repository realm-java",
      "data_code": { "network_and_trees": 1, "sequential": 1, "temporal": 1 }
    },
    "solution": [
      {
        "solution_category": "Interaction",
        "solution_axial": "Selecting",
        "solution_compoent": "",
        "axial_code": ["Selecting"],
        "componenet_code": ["selecting"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 105,
    "paper_title": "Githru: Visual Analytics for Understanding Software Development History Through Git Metadata Analysis",
    "pub_year": 2021,
    "domain": "git",
    "requirement": {
      "requirement_text": "R3: Support \ufb01ltering by and searching for details. Depending on the user query, which can be a keyword or a temporal range, the corresponding commits should be (a) \ufb01ltered in or out and (b) searched and highlighted to reduce the exploration scope. Moreover, users should be able to (c) browse the details of each commit (T3).",
      "requirement_code": { "collect_evidence": 1 }
    },
    "data": {
      "data_text": "an in-house repository dataset, the public GitHub repository realm-java",
      "data_code": { "network_and_trees": 1, "sequential": 1, "temporal": 1 }
    },
    "solution": [
      {
        "solution_category": "Interaction",
        "solution_axial": "Filtering",
        "solution_compoent": "",
        "axial_code": ["Filtering"],
        "componenet_code": ["filtering"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 106,
    "paper_title": "Githru: Visual Analytics for Understanding Software Development History Through Git Metadata Analysis",
    "pub_year": 2021,
    "domain": "git",
    "requirement": {
      "requirement_text": "R3: Support \ufb01ltering by and searching for details. Depending on the user query, which can be a keyword or a temporal range, the corresponding commits should be (a) \ufb01ltered in or out and (b) searched and highlighted to reduce the exploration scope. Moreover, users should be able to (c) browse the details of each commit (T3).",
      "requirement_code": { "collect_evidence": 1 }
    },
    "data": {
      "data_text": "an in-house repository dataset, the public GitHub repository realm-java",
      "data_code": {
        "sequential": 1,
        "network_and_trees": 1,
        "text": 1,
        "temporal": 1
      }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "Clustering&Grouping",
        "solution_compoent": "",
        "axial_code": ["Clustering&Grouping"],
        "componenet_code": ["clustering_and_grouping"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 107,
    "paper_title": "Githru: Visual Analytics for Understanding Software Development History Through Git Metadata Analysis",
    "pub_year": 2021,
    "domain": "git",
    "requirement": {
      "requirement_text": "R4: Support comparison. The system should facilitate comparisons (a) based on the number of commits and LOC. The magnitude can be compared according to (b) overall trends, or (c) within/between user-selections. (d) In particular, the information in the changed \ufb01les should be compared while being organized according to the directory that contains the structure of the source code (T3).",
      "requirement_code": { "compare_entities": 1 }
    },
    "data": {
      "data_text": "an in-house repository dataset, the public GitHub repository realm-java",
      "data_code": { "network_and_trees": 1, "sequential": 1, "temporal": 1 }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "Clustering&Grouping",
        "solution_compoent": "",
        "axial_code": ["Clustering&Grouping"],
        "componenet_code": ["clustering_and_grouping"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 108,
    "paper_title": "Githru: Visual Analytics for Understanding Software Development History Through Git Metadata Analysis",
    "pub_year": 2021,
    "domain": "git",
    "requirement": {
      "requirement_text": "R4: Support comparison. The system should facilitate comparisons (a) based on the number of commits and LOC. The magnitude can be compared according to (b) overall trends, or (c) within/between user-selections. (d) In particular, the information in the changed \ufb01les should be compared while being organized according to the directory that contains the structure of the source code (T3).",
      "requirement_code": { "compare_entities": 1 }
    },
    "data": {
      "data_text": "an in-house repository dataset, the public GitHub repository realm-java",
      "data_code": {
        "sequential": 1,
        "network_and_trees": 1,
        "text": 1,
        "temporal": 1
      }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "Clustering&Grouping",
        "solution_compoent": "",
        "axial_code": ["Clustering&Grouping"],
        "componenet_code": ["clustering_and_grouping"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 109,
    "paper_title": "Githru: Visual Analytics for Understanding Software Development History Through Git Metadata Analysis",
    "pub_year": 2021,
    "domain": "git",
    "requirement": {
      "requirement_text": "R4: Support comparison. The system should facilitate comparisons (a) based on the number of commits and LOC. The magnitude can be compared according to (b) overall trends, or (c) within/between user-selections. (d) In particular, the information in the changed \ufb01les should be compared while being organized according to the directory that contains the structure of the source code (T3).",
      "requirement_code": { "compare_entities": 1 }
    },
    "data": {
      "data_text": "an in-house repository dataset, the public GitHub repository realm-java",
      "data_code": {
        "sequential": 1,
        "network_and_trees": 1,
        "text": 1,
        "temporal": 1
      }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "Clustering&Grouping",
        "solution_compoent": "",
        "axial_code": ["Clustering&Grouping"],
        "componenet_code": ["clustering_and_grouping"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 110,
    "paper_title": "SafetyLens: Visual Data Analysis of Functional Safety of Vehicles",
    "pub_year": 2021,
    "domain": "Functional Safety",
    "requirement": {
      "requirement_text": "DG1: FACILITATE E XPLORATION OF A P ROJECT User tasks such as \u201cFind missing links\u201d, \u201cLookup and analyze a node\u2019s end-to-end traceability\u201d are network exploration tasks. Hence, we modeled Functional Safety data as a network and derived this design goal to support tasks like fetching node details on hover, \ufb01nding adjacent nodes, and \ufb01nding paths from one node to another based on the taxonomies by Lee et al. [34] and Pretorius et al. [40].",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "Each Project constitutes an instance of a Functional Safety dataset. This can be modeled as a network with nodes and links. Each node represents a functional safety Element with seven attributes: {ID, Name, Type, ASIL, Severity, Exposure, Controllability}. A link between two nodes represents the Relation between two Elements and has three attributes: {Source, Target, Relation}",
      "data_code": { "network_and_trees": 1, "ordinal": 1 }
    },
    "solution": [
      {
        "solution_category": "Visualization",
        "solution_axial": "Stack",
        "solution_compoent": "scatter+table",
        "axial_code": ["Stack"],
        "componenet_code": ["scatter", "table"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 114,
    "paper_title": "SafetyLens: Visual Data Analysis of Functional Safety of Vehicles",
    "pub_year": 2021,
    "domain": "Functional Safety",
    "requirement": {
      "requirement_text": "DG3: D ISCOVER PATTERNS AND A NOMALIES The domain experts we spoke to make use of existing commercial and open source tools. These tools support basic exploration and comparison of Functional Safety projects but may fall short when the scale and complexity of data increases. Thus, SafetyLens should support discovering interesting patterns within and across projects.",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "Each Project constitutes an instance of a Functional Safety dataset. This can be modeled as a network with nodes and links. Each node represents a functional safety Element with seven attributes: {ID, Name, Type, ASIL, Severity, Exposure, Controllability}. A link between two nodes represents the Relation between two Elements and has three attributes: {Source, Target, Relation}",
      "data_code": { "network_and_trees": 1, "ordinal": 1 }
    },
    "solution": [
      {
        "solution_category": "Visualization",
        "solution_axial": "Repetition",
        "solution_compoent": "heatmap",
        "axial_code": ["Repetition"],
        "componenet_code": ["heatmap"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 115,
    "paper_title": "SafetyLens: Visual Data Analysis of Functional Safety of Vehicles",
    "pub_year": 2021,
    "domain": "Functional Safety",
    "requirement": {
      "requirement_text": "DG3: D ISCOVER PATTERNS AND A NOMALIES The domain experts we spoke to make use of existing commercial and open source tools. These tools support basic exploration and comparison of Functional Safety projects but may fall short when the scale and complexity of data increases. Thus, SafetyLens should support discovering interesting patterns within and across projects.",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "Each Project constitutes an instance of a Functional Safety dataset. This can be modeled as a network with nodes and links. Each node represents a functional safety Element with seven attributes: {ID, Name, Type, ASIL, Severity, Exposure, Controllability}. A link between two nodes represents the Relation between two Elements and has three attributes: {Source, Target, Relation}",
      "data_code": { "network_and_trees": 1, "ordinal": 1 }
    },
    "solution": [
      {
        "solution_category": "Visualization",
        "solution_axial": "Repetition",
        "solution_compoent": "scatter",
        "axial_code": ["Repetition"],
        "componenet_code": ["scatter"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 116,
    "paper_title": "SafetyLens: Visual Data Analysis of Functional Safety of Vehicles",
    "pub_year": 2021,
    "domain": "Functional Safety",
    "requirement": {
      "requirement_text": "DG4: FACILITATE T RACEABILITY AND D ECOMPOSITION OF ASIL S An important task for domain experts is to trace the ASIL from one node to another (e.g., {MB \u2192 HzE \u2192 SG \u2192 FSR \u2192 TSR}). Since ASILs determine the extent of safety mechanisms for elements, any discrepancy such as an element assigned an ASIL=A instead of ASIL=D is an important concern. To diagnose the problem, users should be able to decompose the ASIL into its Severity (S), Exposure (E), and Controllability (C). Thus, it is an important design goal for SafetyLens to unify tasks allowing users to ef\ufb01ciently detect, diagnose, and \ufb01x ASIL assignment issues",
      "requirement_code": { "identify_main_cause_item": 1 }
    },
    "data": {
      "data_text": "Each Project constitutes an instance of a Functional Safety dataset. This can be modeled as a network with nodes and links. Each node represents a functional safety Element with seven attributes: {ID, Name, Type, ASIL, Severity, Exposure, Controllability}. A link between two nodes represents the Relation between two Elements and has three attributes: {Source, Target, Relation}",
      "data_code": { "network_and_trees": 1, "ordinal": 1 }
    },
    "solution": [
      {
        "solution_category": "Visualization",
        "solution_axial": "Stack",
        "solution_compoent": "scatter+table+heatmap",
        "axial_code": ["Stack"],
        "componenet_code": ["scatter", "heatmap", "table"]
      },
      {
        "solution_category": "Interaction",
        "solution_axial": "Selecting,",
        "solution_compoent": "",
        "axial_code": ["", "Selecting"],
        "componenet_code": ["selecting", "selecting"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 118,
    "paper_title": "SafetyLens: Visual Data Analysis of Functional Safety of Vehicles",
    "pub_year": 2021,
    "domain": "Functional Safety",
    "requirement": {
      "requirement_text": "DG6: P ROVIDE A S UMMARY OF K EY M ETRICS The user tasks suggested that key metrics should be readily available (e.g., total number of nodes, total number of nodes with ASIL=D, etc).",
      "requirement_code": { "describe_observation_aggregate": 1 }
    },
    "data": {
      "data_text": "Each Project constitutes an instance of a Functional Safety dataset. This can be modeled as a network with nodes and links. Each node represents a functional safety Element with seven attributes: {ID, Name, Type, ASIL, Severity, Exposure, Controllability}. A link between two nodes represents the Relation between two Elements and has three attributes: {Source, Target, Relation}",
      "data_code": { "network_and_trees": 1, "ordinal": 1 }
    },
    "solution": [
      {
        "solution_category": "Visualization",
        "solution_axial": "Repetition",
        "solution_compoent": "heatmap",
        "axial_code": ["Repetition"],
        "componenet_code": ["heatmap"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 120,
    "paper_title": "Towards Better Bus Networks: A Visual Analytics Approach",
    "pub_year": 2021,
    "domain": "Bus route planning",
    "requirement": {
      "requirement_text": "P1: Obtain the spatial overview of the bus network and its performance. The experts requested to see a map-based overview of the bus network similar to other GIS software [20, 53]. Such an overview should help users to rapidly orient themselves in the spatial context and grasp the spatial distribution of routes. The overview should also include the visualization of the network performance to guide users in performing a drill-down analysis on the potentially ineffective routes.",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "The proposed system is based on three types of data, namely, bus stop, route, and trip data, collected from bus networks. Bus stop data comprise the bus stops in a city. Each stop is defined by its ID, name, and coordinates. Bus route data comprise the bus routes, where each of them is identified by its ID and a stop sequence. Bus trip data contain a series of bus fare card records, where each of them comprises a card ID, a tap-on timestamp, and the route and stops where the fare card was tapped on and off. However, the tap-off timestamps are not present in the dataset because of sensor errors. This timestamp was inferred either by using the tap-on timestamps at the destination stops if such transfer records exist, or based on driving time along the bus route at 20 km/h plus 2 min spent at every stop, as suggested by our domain experts.",
      "data_code": { "tables": 1, "categorical": 1, "geometry": 1 }
    },
    "solution": [
      {
        "solution_category": "Visualization",
        "solution_axial": "Nesting",
        "solution_compoent": "map+radar+area",
        "axial_code": ["Nesting"],
        "componenet_code": ["area", "radar", "map"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 121,
    "paper_title": "Towards Better Bus Networks: A Visual Analytics Approach",
    "pub_year": 2021,
    "domain": "Bus route planning",
    "requirement": {
      "requirement_text": "P1: Obtain the spatial overview of the bus network and its performance. The experts requested to see a map-based overview of the bus network similar to other GIS software [20, 53]. Such an overview should help users to rapidly orient themselves in the spatial context and grasp the spatial distribution of routes. The overview should also include the visualization of the network performance to guide users in performing a drill-down analysis on the potentially ineffective routes.",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "The proposed system is based on three types of data, namely, bus stop, route, and trip data, collected from bus networks. Bus stop data comprise the bus stops in a city. Each stop is defined by its ID, name, and coordinates. Bus route data comprise the bus routes, where each of them is identified by its ID and a stop sequence. Bus trip data contain a series of bus fare card records, where each of them comprises a card ID, a tap-on timestamp, and the route and stops where the fare card was tapped on and off. However, the tap-off timestamps are not present in the dataset because of sensor errors. This timestamp was inferred either by using the tap-on timestamps at the destination stops if such transfer records exist, or based on driving time along the bus route at 20 km/h plus 2 min spent at every stop, as suggested by our domain experts.",
      "data_code": { "tables": 1, "categorical": 1, "geometry": 1 }
    },
    "solution": [
      {
        "solution_category": "Visualization",
        "solution_axial": "Stack",
        "solution_compoent": "table+area",
        "axial_code": ["Stack"],
        "componenet_code": ["area", "table"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 122,
    "paper_title": "Towards Better Bus Networks: A Visual Analytics Approach",
    "pub_year": 2021,
    "domain": "Bus route planning",
    "requirement": {
      "requirement_text": "P1: Obtain the spatial overview of the bus network and its performance. The experts requested to see a map-based overview of the bus network similar to other GIS software [20, 53]. Such an overview should help users to rapidly orient themselves in the spatial context and grasp the spatial distribution of routes. The overview should also include the visualization of the network performance to guide users in performing a drill-down analysis on the potentially ineffective routes.",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "The proposed system is based on three types of data, namely, bus stop, route, and trip data, collected from bus networks. Bus stop data comprise the bus stops in a city. Each stop is defined by its ID, name, and coordinates. Bus route data comprise the bus routes, where each of them is identified by its ID and a stop sequence. Bus trip data contain a series of bus fare card records, where each of them comprises a card ID, a tap-on timestamp, and the route and stops where the fare card was tapped on and off. However, the tap-off timestamps are not present in the dataset because of sensor errors. This timestamp was inferred either by using the tap-on timestamps at the destination stops if such transfer records exist, or based on driving time along the bus route at 20 km/h plus 2 min spent at every stop, as suggested by our domain experts.",
      "data_code": { "tables": 1, "categorical": 1, "geometry": 1 }
    },
    "solution": [
      {
        "solution_category": "Visualization",
        "solution_axial": "Nesting",
        "solution_compoent": "map+radar+area",
        "axial_code": ["Nesting"],
        "componenet_code": ["area", "radar", "map"]
      },
      {
        "solution_category": "Interaction",
        "solution_axial": "OverviewandExplore",
        "solution_compoent": "",
        "axial_code": ["OverviewandExplore"],
        "componenet_code": ["overview_and_explore"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 123,
    "paper_title": "Towards Better Bus Networks: A Visual Analytics Approach",
    "pub_year": 2021,
    "domain": "Bus route planning",
    "requirement": {
      "requirement_text": "P1: Obtain the spatial overview of the bus network and its performance. The experts requested to see a map-based overview of the bus network similar to other GIS software [20, 53]. Such an overview should help users to rapidly orient themselves in the spatial context and grasp the spatial distribution of routes. The overview should also include the visualization of the network performance to guide users in performing a drill-down analysis on the potentially ineffective routes.",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "The proposed system is based on three types of data, namely, bus stop, route, and trip data, collected from bus networks. Bus stop data comprise the bus stops in a city. Each stop is defined by its ID, name, and coordinates. Bus route data comprise the bus routes, where each of them is identified by its ID and a stop sequence. Bus trip data contain a series of bus fare card records, where each of them comprises a card ID, a tap-on timestamp, and the route and stops where the fare card was tapped on and off. However, the tap-off timestamps are not present in the dataset because of sensor errors. This timestamp was inferred either by using the tap-on timestamps at the destination stops if such transfer records exist, or based on driving time along the bus route at 20 km/h plus 2 min spent at every stop, as suggested by our domain experts.",
      "data_code": { "tables": 1, "categorical": 1, "geometry": 1 }
    },
    "solution": [
      {
        "solution_category": "Visualization",
        "solution_axial": "Stack",
        "solution_compoent": "table+area",
        "axial_code": ["Stack"],
        "componenet_code": ["area", "table"]
      },
      {
        "solution_category": "Interaction",
        "solution_axial": "Reconfigure",
        "solution_compoent": "",
        "axial_code": ["Reconfigure"],
        "componenet_code": ["reconfigure"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 124,
    "paper_title": "Towards Better Bus Networks: A Visual Analytics Approach",
    "pub_year": 2021,
    "domain": "Bus route planning",
    "requirement": {
      "requirement_text": "P2: Analyze the passenger \ufb02ows of bus routes to \ufb01nd weaknesses. The movement of passengers through the bus network provides key insights for the experts to evaluate the performance of the routes. For example, some parts of a route might be non-functional if few passengers were getting on or off in these parts. Therefore, intuitive visualization of passenger \ufb02ows is highly demanded to facilitate the identi\ufb01cation of de\ufb01cient routes. Moreover, such a visualization should also enable the experts to analyze the transfers among multiple bus routes, which may reveal patterns to improve route design.",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "The proposed system is based on three types of data, namely, bus stop, route, and trip data, collected from bus networks. Bus stop data comprise the bus stops in a city. Each stop is defined by its ID, name, and coordinates. Bus route data comprise the bus routes, where each of them is identified by its ID and a stop sequence. Bus trip data contain a series of bus fare card records, where each of them comprises a card ID, a tap-on timestamp, and the route and stops where the fare card was tapped on and off. However, the tap-off timestamps are not present in the dataset because of sensor errors. This timestamp was inferred either by using the tap-on timestamps at the destination stops if such transfer records exist, or based on driving time along the bus route at 20 km/h plus 2 min spent at every stop, as suggested by our domain experts.",
      "data_code": { "tables": 1, "categorical": 1, "geometry": 1 }
    },
    "solution": [
      {
        "solution_category": "Visualization",
        "solution_axial": "Nesting",
        "solution_compoent": "map+radar+area",
        "axial_code": ["Nesting"],
        "componenet_code": ["area", "radar", "map"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 125,
    "paper_title": "Towards Better Bus Networks: A Visual Analytics Approach",
    "pub_year": 2021,
    "domain": "Bus route planning",
    "requirement": {
      "requirement_text": "P2: Analyze the passenger \ufb02ows of bus routes to \ufb01nd weaknesses. The movement of passengers through the bus network provides key insights for the experts to evaluate the performance of the routes. For example, some parts of a route might be non-functional if few passengers were getting on or off in these parts. Therefore, intuitive visualization of passenger \ufb02ows is highly demanded to facilitate the identi\ufb01cation of de\ufb01cient routes. Moreover, such a visualization should also enable the experts to analyze the transfers among multiple bus routes, which may reveal patterns to improve route design.",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "The proposed system is based on three types of data, namely, bus stop, route, and trip data, collected from bus networks. Bus stop data comprise the bus stops in a city. Each stop is defined by its ID, name, and coordinates. Bus route data comprise the bus routes, where each of them is identified by its ID and a stop sequence. Bus trip data contain a series of bus fare card records, where each of them comprises a card ID, a tap-on timestamp, and the route and stops where the fare card was tapped on and off. However, the tap-off timestamps are not present in the dataset because of sensor errors. This timestamp was inferred either by using the tap-on timestamps at the destination stops if such transfer records exist, or based on driving time along the bus route at 20 km/h plus 2 min spent at every stop, as suggested by our domain experts.",
      "data_code": { "tables": 1, "categorical": 1, "geometry": 1 }
    },
    "solution": [
      {
        "solution_category": "Visualization",
        "solution_axial": "Coordinate",
        "solution_compoent": "matrix+bar",
        "axial_code": ["Coordinate"],
        "componenet_code": ["matrix", "bar"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 126,
    "paper_title": "Towards Better Bus Networks: A Visual Analytics Approach",
    "pub_year": 2021,
    "domain": "Bus route planning",
    "requirement": {
      "requirement_text": "P2: Analyze the passenger \ufb02ows of bus routes to \ufb01nd weaknesses. The movement of passengers through the bus network provides key insights for the experts to evaluate the performance of the routes. For example, some parts of a route might be non-functional if few passengers were getting on or off in these parts. Therefore, intuitive visualization of passenger \ufb02ows is highly demanded to facilitate the identi\ufb01cation of de\ufb01cient routes. Moreover, such a visualization should also enable the experts to analyze the transfers among multiple bus routes, which may reveal patterns to improve route design.",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "The proposed system is based on three types of data, namely, bus stop, route, and trip data, collected from bus networks. Bus stop data comprise the bus stops in a city. Each stop is defined by its ID, name, and coordinates. Bus route data comprise the bus routes, where each of them is identified by its ID and a stop sequence. Bus trip data contain a series of bus fare card records, where each of them comprises a card ID, a tap-on timestamp, and the route and stops where the fare card was tapped on and off. However, the tap-off timestamps are not present in the dataset because of sensor errors. This timestamp was inferred either by using the tap-on timestamps at the destination stops if such transfer records exist, or based on driving time along the bus route at 20 km/h plus 2 min spent at every stop, as suggested by our domain experts.",
      "data_code": { "tables": 1, "categorical": 1, "geometry": 1 }
    },
    "solution": [
      {
        "solution_category": "Visualization",
        "solution_axial": "Nesting",
        "solution_compoent": "map+radar+area",
        "axial_code": ["Nesting"],
        "componenet_code": ["area", "radar", "map"]
      },
      {
        "solution_category": "Interaction",
        "solution_axial": "OverviewandExplore",
        "solution_compoent": "",
        "axial_code": ["OverviewandExplore"],
        "componenet_code": ["overview_and_explore"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 127,
    "paper_title": "Towards Better Bus Networks: A Visual Analytics Approach",
    "pub_year": 2021,
    "domain": "Bus route planning",
    "requirement": {
      "requirement_text": "P2: Analyze the passenger \ufb02ows of bus routes to \ufb01nd weaknesses. The movement of passengers through the bus network provides key insights for the experts to evaluate the performance of the routes. For example, some parts of a route might be non-functional if few passengers were getting on or off in these parts. Therefore, intuitive visualization of passenger \ufb02ows is highly demanded to facilitate the identi\ufb01cation of de\ufb01cient routes. Moreover, such a visualization should also enable the experts to analyze the transfers among multiple bus routes, which may reveal patterns to improve route design.",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "The proposed system is based on three types of data, namely, bus stop, route, and trip data, collected from bus networks. Bus stop data comprise the bus stops in a city. Each stop is defined by its ID, name, and coordinates. Bus route data comprise the bus routes, where each of them is identified by its ID and a stop sequence. Bus trip data contain a series of bus fare card records, where each of them comprises a card ID, a tap-on timestamp, and the route and stops where the fare card was tapped on and off. However, the tap-off timestamps are not present in the dataset because of sensor errors. This timestamp was inferred either by using the tap-on timestamps at the destination stops if such transfer records exist, or based on driving time along the bus route at 20 km/h plus 2 min spent at every stop, as suggested by our domain experts.",
      "data_code": {
        "tables": 1,
        "categorical": 1,
        "geometry": 1,
        "sequential": 1,
        "temporal": 1
      }
    },
    "solution": [
      {
        "solution_category": "Visualization",
        "solution_axial": "Coordinate",
        "solution_compoent": "matrix+bar",
        "axial_code": ["Coordinate"],
        "componenet_code": ["matrix", "bar"]
      },
      {
        "solution_category": "Interaction",
        "solution_axial": "Filtering",
        "solution_compoent": "",
        "axial_code": ["Filtering"],
        "componenet_code": ["filtering"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 128,
    "paper_title": "Towards Better Bus Networks: A Visual Analytics Approach",
    "pub_year": 2021,
    "domain": "Bus route planning",
    "requirement": {
      "requirement_text": "M1: Generate a set of alternative routes based on the constraints. The experts prefer to interact with the model and generate the Paretooptimal routes as the potential replacements of the selected ineffective route. To minimize the disruption caused by route changes, the experts may preserve several primary stops from the original route. Moreover, certain constraints, such as the construction cost and maximum route length, may be imposed on route generation. An easy-to-use interface is required for translating these constraints into the complex parameters required by the model.",
      "requirement_code": { "evaluate_hypothesis": 1 }
    },
    "data": {
      "data_text": "The proposed system is based on three types of data, namely, bus stop, route, and trip data, collected from bus networks. Bus stop data comprise the bus stops in a city. Each stop is defined by its ID, name, and coordinates. Bus route data comprise the bus routes, where each of them is identified by its ID and a stop sequence. Bus trip data contain a series of bus fare card records, where each of them comprises a card ID, a tap-on timestamp, and the route and stops where the fare card was tapped on and off. However, the tap-off timestamps are not present in the dataset because of sensor errors. This timestamp was inferred either by using the tap-on timestamps at the destination stops if such transfer records exist, or based on driving time along the bus route at 20 km/h plus 2 min spent at every stop, as suggested by our domain experts.",
      "data_code": {
        "tables": 1,
        "categorical": 1,
        "geometry": 1,
        "sequential": 1,
        "temporal": 1
      }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "Modeling",
        "solution_compoent": "",
        "axial_code": ["Modeling"],
        "componenet_code": ["modeling"]
      },
      {
        "solution_category": "Visualization",
        "solution_axial": "Stack",
        "solution_compoent": "map+area",
        "axial_code": ["Stack"],
        "componenet_code": ["area", "map"]
      },
      {
        "solution_category": "Interaction",
        "solution_axial": "Participation/Collaboration",
        "solution_compoent": "",
        "axial_code": ["Participation/Collaboration"],
        "componenet_code": ["participation/collaboration"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 129,
    "paper_title": "Towards Better Bus Networks: A Visual Analytics Approach",
    "pub_year": 2021,
    "domain": "Bus route planning",
    "requirement": {
      "requirement_text": "M2: Inspect the quality of the generated routes in real time. Considering that the model is progressive and does not stop automatically, the experts need to know when the results are suf\ufb01ciently good to stop the route generation process. Hence, tailored visualizations are required to depict the current status of the generation process in real-time and provide the early quality preview of the alternative routes as the process continues. Moreover, such visualizations should allow some undesired routes to be removed from the search space to interactively guide and accelerate the search process.",
      "requirement_code": { "compare_entities": 1 }
    },
    "data": {
      "data_text": "The proposed system is based on three types of data, namely, bus stop, route, and trip data, collected from bus networks. Bus stop data comprise the bus stops in a city. Each stop is defined by its ID, name, and coordinates. Bus route data comprise the bus routes, where each of them is identified by its ID and a stop sequence. Bus trip data contain a series of bus fare card records, where each of them comprises a card ID, a tap-on timestamp, and the route and stops where the fare card was tapped on and off. However, the tap-off timestamps are not present in the dataset because of sensor errors. This timestamp was inferred either by using the tap-on timestamps at the destination stops if such transfer records exist, or based on driving time along the bus route at 20 km/h plus 2 min spent at every stop, as suggested by our domain experts.",
      "data_code": {
        "tables": 1,
        "categorical": 1,
        "geometry": 1,
        "sequential": 1,
        "temporal": 1
      }
    },
    "solution": [
      {
        "solution_category": "Visualization",
        "solution_axial": "Stack",
        "solution_compoent": "map+area",
        "axial_code": ["Stack"],
        "componenet_code": ["area", "map"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 130,
    "paper_title": "Towards Better Bus Networks: A Visual Analytics Approach",
    "pub_year": 2021,
    "domain": "Bus route planning",
    "requirement": {
      "requirement_text": "L1: Compare the generated routes based on topologies. To help the experts identify the most promising ones from the generated routes, the proposed system must reveal the topological similarities and differences among these routes. The experts may want to know: What stops do these two routes share? Which pair of consecutive stops is the most frequently selected? How much does a route deviate from another one by taking a detour? Integrating topological information can help experts estimate the performance of these routes and eliminate the undesired ones that share similar characteristics",
      "requirement_code": { "compare_entities": 1 }
    },
    "data": {
      "data_text": "The proposed system is based on three types of data, namely, bus stop, route, and trip data, collected from bus networks. Bus stop data comprise the bus stops in a city. Each stop is defined by its ID, name, and coordinates. Bus route data comprise the bus routes, where each of them is identified by its ID and a stop sequence. Bus trip data contain a series of bus fare card records, where each of them comprises a card ID, a tap-on timestamp, and the route and stops where the fare card was tapped on and off. However, the tap-off timestamps are not present in the dataset because of sensor errors. This timestamp was inferred either by using the tap-on timestamps at the destination stops if such transfer records exist, or based on driving time along the bus route at 20 km/h plus 2 min spent at every stop, as suggested by our domain experts.",
      "data_code": { "tables": 1, "categorical": 1, "geometry": 1 }
    },
    "solution": [
      {
        "solution_category": "Visualization",
        "solution_axial": "Coordinate",
        "solution_compoent": "matrix+bar",
        "axial_code": ["Coordinate"],
        "componenet_code": ["matrix", "bar"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 131,
    "paper_title": "Towards Better Bus Networks: A Visual Analytics Approach",
    "pub_year": 2021,
    "domain": "Bus route planning",
    "requirement": {
      "requirement_text": "L2: Compare the generated routes based on multiple criteria. The most promising alternative route should also be determined in terms of the performance criteria. However, experts may treat each criterion differently under different circumstances. For example, the distances between the stops in a suburban bus route will be considerably longer than those between the stops in a city bus route. To facilitate a judicious decision-making process, the system should enable the experts to inspect the criteria of the generated routes and identify the most optimal one ef\ufb01ciently with tailored ranking models.",
      "requirement_code": { "explain_differences": 1 }
    },
    "data": {
      "data_text": "The proposed system is based on three types of data, namely, bus stop, route, and trip data, collected from bus networks. Bus stop data comprise the bus stops in a city. Each stop is defined by its ID, name, and coordinates. Bus route data comprise the bus routes, where each of them is identified by its ID and a stop sequence. Bus trip data contain a series of bus fare card records, where each of them comprises a card ID, a tap-on timestamp, and the route and stops where the fare card was tapped on and off. However, the tap-off timestamps are not present in the dataset because of sensor errors. This timestamp was inferred either by using the tap-on timestamps at the destination stops if such transfer records exist, or based on driving time along the bus route at 20 km/h plus 2 min spent at every stop, as suggested by our domain experts.",
      "data_code": { "tables": 1, "categorical": 1, "geometry": 1 }
    },
    "solution": [
      {
        "solution_category": "Visualization",
        "solution_axial": "Stack",
        "solution_compoent": "table+area",
        "axial_code": ["Stack"],
        "componenet_code": ["area", "table"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 132,
    "paper_title": "ChemVA: Interactive Visual Analysis of Chemical Compound Similarity in Virtual Screening",
    "pub_year": 2021,
    "domain": "cheminformatics",
    "requirement": {
      "requirement_text": "R1: Overview and detailed analysis of a molecular ensemble in the low-dimensional space. For large datasets, scatter plots, which are commonly used to represent the DR output, may suffer from occlusion problems for large datasets. Therefore, the tool should provide visual support for the analysis of data on different levels of abstraction, from the overall distribution of the compounds within the 2D space to the detailed view of individual compounds for a selected region of interest.",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "The first dataset was composed by merging ligands binding to the Serotonin 1a receptor1 and Dopamine D2 receptor2, whereas the second dataset comprised ligands to the P-glycoprotein 13. We assigned a categorical label to each compound according to its experimentally measured IC50 bioac_x0002_tivity value towards the target(s) under study. Compounds showing IC50 values below 10 nM were labeled as Active; compounds between 10 and 1000 nM were labeled as Moderately Active, and those over 1000 nM were labeled as Inactive. The serotonin-dopamine dataset comprises 118 compounds, whereas the P-glycoprotein dataset contains 893 compounds.",
      "data_code": {
        "tables": 1,
        "ordinal": 1,
        "clusters_and_sets_and_lists": 1
      }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "DimensionalityReduction",
        "solution_compoent": "",
        "axial_code": ["DimensionalityReduction"],
        "componenet_code": ["dimensionality_reduction"]
      },
      {
        "solution_category": "Visualization",
        "solution_axial": "Repetition",
        "solution_compoent": "hexagonarea+scatter",
        "axial_code": ["Repetition"],
        "componenet_code": ["scatter", "hexagonarea"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 133,
    "paper_title": "ChemVA: Interactive Visual Analysis of Chemical Compound Similarity in Virtual Screening",
    "pub_year": 2021,
    "domain": "cheminformatics",
    "requirement": {
      "requirement_text": "R2: Visual inspection of multiple projections. A set of compounds can be expressed by different vector-based molecular representations, each yielding a different DR projection. The tool should enable the user to intuitively combine information encoded in the individual projections to allow studying at once the similarity between compounds based on different molecular representations. More speci\ufb01cally, this includes exploring similarities and differences between chemical compounds, expressed by the different projections. Additionally, the visual representations and interactions should help the domain experts evaluate the suitability of the selected DR model.",
      "requirement_code": { "compare_entities": 1 }
    },
    "data": {
      "data_text": "The first dataset was composed by merging ligands binding to the Serotonin 1a receptor1 and Dopamine D2 receptor2, whereas the second dataset comprised ligands to the P-glycoprotein 13. We assigned a categorical label to each compound according to its experimentally measured IC50 bioac_x0002_tivity value towards the target(s) under study. Compounds showing IC50 values below 10 nM were labeled as Active; compounds between 10 and 1000 nM were labeled as Moderately Active, and those over 1000 nM were labeled as Inactive. The serotonin-dopamine dataset comprises 118 compounds, whereas the P-glycoprotein dataset contains 893 compounds.",
      "data_code": {
        "tables": 1,
        "ordinal": 1,
        "clusters_and_sets_and_lists": 1
      }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "DimensionalityReduction",
        "solution_compoent": "",
        "axial_code": ["DimensionalityReduction"],
        "componenet_code": ["dimensionality_reduction"]
      },
      {
        "solution_category": "Visualization",
        "solution_axial": "Coordinate",
        "solution_compoent": "hexagonarea",
        "axial_code": ["Coordinate"],
        "componenet_code": ["hexagonarea"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 134,
    "paper_title": "ChemVA: Interactive Visual Analysis of Chemical Compound Similarity in Virtual Screening",
    "pub_year": 2021,
    "domain": "cheminformatics",
    "requirement": {
      "requirement_text": "R3: Evaluation of the trustworthiness of projections. Users need proper visual support for assessing the trustworthiness of a lowdimensional projection based on the distortion with regard to pairwise distances between compounds in the original space. When such trustworthiness can be compared on different DR projections, users can focus the exploration on a subset of molecular representations.",
      "requirement_code": { "collect_evidence": 1 }
    },
    "data": {
      "data_text": "The first dataset was composed by merging ligands binding to the Serotonin 1a receptor1 and Dopamine D2 receptor2, whereas the second dataset comprised ligands to the P-glycoprotein 13. We assigned a categorical label to each compound according to its experimentally measured IC50 bioac_x0002_tivity value towards the target(s) under study. Compounds showing IC50 values below 10 nM were labeled as Active; compounds between 10 and 1000 nM were labeled as Moderately Active, and those over 1000 nM were labeled as Inactive. The serotonin-dopamine dataset comprises 118 compounds, whereas the P-glycoprotein dataset contains 893 compounds.",
      "data_code": {
        "tables": 1,
        "ordinal": 1,
        "clusters_and_sets_and_lists": 1
      }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "DimensionalityReduction",
        "solution_compoent": "",
        "axial_code": ["DimensionalityReduction"],
        "componenet_code": ["dimensionality_reduction"]
      },
      {
        "solution_category": "Visualization",
        "solution_axial": "Repetition",
        "solution_compoent": "hexagonarea",
        "axial_code": ["Repetition"],
        "componenet_code": ["hexagonarea"]
      },
      {
        "solution_category": "Interaction",
        "solution_axial": "Filtering",
        "solution_compoent": "",
        "axial_code": ["Filtering"],
        "componenet_code": ["filtering"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 135,
    "paper_title": "ChemVA: Interactive Visual Analysis of Chemical Compound Similarity in Virtual Screening",
    "pub_year": 2021,
    "domain": "cheminformatics",
    "requirement": {
      "requirement_text": "R3: Evaluation of the trustworthiness of projections. Users need proper visual support for assessing the trustworthiness of a lowdimensional projection based on the distortion with regard to pairwise distances between compounds in the original space. When such trustworthiness can be compared on different DR projections, users can focus the exploration on a subset of molecular representations.",
      "requirement_code": { "collect_evidence": 1 }
    },
    "data": {
      "data_text": "The first dataset was composed by merging ligands binding to the Serotonin 1a receptor1 and Dopamine D2 receptor2, whereas the second dataset comprised ligands to the P-glycoprotein 13. We assigned a categorical label to each compound according to its experimentally measured IC50 bioac_x0002_tivity value towards the target(s) under study. Compounds showing IC50 values below 10 nM were labeled as Active; compounds between 10 and 1000 nM were labeled as Moderately Active, and those over 1000 nM were labeled as Inactive. The serotonin-dopamine dataset comprises 118 compounds, whereas the P-glycoprotein dataset contains 893 compounds.",
      "data_code": {
        "tables": 1,
        "ordinal": 1,
        "clusters_and_sets_and_lists": 1
      }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "AlgorithmCalculation",
        "solution_compoent": "",
        "axial_code": ["AlgorithmCalculation"],
        "componenet_code": ["algorithmic_calculation"]
      },
      {
        "solution_category": "Visualization",
        "solution_axial": "Nesting",
        "solution_compoent": "hexagonarea+scatter",
        "axial_code": ["Nesting"],
        "componenet_code": ["scatter", "hexagonarea"]
      },
      {
        "solution_category": "Interaction",
        "solution_axial": "Filtering",
        "solution_compoent": "",
        "axial_code": ["Filtering"],
        "componenet_code": ["filtering"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 136,
    "paper_title": "ChemVA: Interactive Visual Analysis of Chemical Compound Similarity in Virtual Screening",
    "pub_year": 2021,
    "domain": "cheminformatics",
    "requirement": {
      "requirement_text": "R3: Evaluation of the trustworthiness of projections. Users need proper visual support for assessing the trustworthiness of a lowdimensional projection based on the distortion with regard to pairwise distances between compounds in the original space. When such trustworthiness can be compared on different DR projections, users can focus the exploration on a subset of molecular representations.",
      "requirement_code": { "collect_evidence": 1 }
    },
    "data": {
      "data_text": "The first dataset was composed by merging ligands binding to the Serotonin 1a receptor1 and Dopamine D2 receptor2, whereas the second dataset comprised ligands to the P-glycoprotein 13. We assigned a categorical label to each compound according to its experimentally measured IC50 bioac_x0002_tivity value towards the target(s) under study. Compounds showing IC50 values below 10 nM were labeled as Active; compounds between 10 and 1000 nM were labeled as Moderately Active, and those over 1000 nM were labeled as Inactive. The serotonin-dopamine dataset comprises 118 compounds, whereas the P-glycoprotein dataset contains 893 compounds.",
      "data_code": {
        "tables": 1,
        "ordinal": 1,
        "clusters_and_sets_and_lists": 1
      }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "DimensionalityReduction",
        "solution_compoent": "",
        "axial_code": ["DimensionalityReduction"],
        "componenet_code": ["dimensionality_reduction"]
      },
      {
        "solution_category": "Visualization",
        "solution_axial": "Coordinate",
        "solution_compoent": "hexagonarea",
        "axial_code": ["Coordinate"],
        "componenet_code": ["hexagonarea"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 137,
    "paper_title": "ChemVA: Interactive Visual Analysis of Chemical Compound Similarity in Virtual Screening",
    "pub_year": 2021,
    "domain": "cheminformatics",
    "requirement": {
      "requirement_text": "R4: Comparison of compounds according to features related to drug-likeness. Chemical compounds have many features and descriptors related to drug-likeness that can complement other molecular representations in the task of virtual screening. Therefore, it is desirable to provide users with an option to visualize these additional features along with the projections.",
      "requirement_code": { "compare_entities": 1 }
    },
    "data": {
      "data_text": "The first dataset was composed by merging ligands binding to the Serotonin 1a receptor1 and Dopamine D2 receptor2, whereas the second dataset comprised ligands to the P-glycoprotein 13. We assigned a categorical label to each compound according to its experimentally measured IC50 bioac_x0002_tivity value towards the target(s) under study. Compounds showing IC50 values below 10 nM were labeled as Active; compounds between 10 and 1000 nM were labeled as Moderately Active, and those over 1000 nM were labeled as Inactive. The serotonin-dopamine dataset comprises 118 compounds, whereas the P-glycoprotein dataset contains 893 compounds.",
      "data_code": {
        "tables": 1,
        "ordinal": 1,
        "clusters_and_sets_and_lists": 1
      }
    },
    "solution": [
      {
        "solution_category": "Visualization",
        "solution_axial": "Stack",
        "solution_compoent": "bar+box",
        "axial_code": ["Stack"],
        "componenet_code": ["box", "bar"]
      },
      {
        "solution_category": "Interaction",
        "solution_axial": "Filtering",
        "solution_compoent": "",
        "axial_code": ["Filtering"],
        "componenet_code": ["filtering"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 138,
    "paper_title": "ChemVA: Interactive Visual Analysis of Chemical Compound Similarity in Virtual Screening",
    "pub_year": 2021,
    "domain": "cheminformatics",
    "requirement": {
      "requirement_text": "R5: Comprehensible viewing of 3D structural similarity. The tool should support the inspection of individual compounds in terms of their 3D geometry, as well as the visual comparison of common 3D substructures in a selected set of compounds. For multiple compounds, such a view should convey the information about similarities and differences in their 3D structure.",
      "requirement_code": {
        "describe_observation_item": 1,
        "compare_entities": 1
      }
    },
    "data": {
      "data_text": "The first dataset was composed by merging ligands binding to the Serotonin 1a receptor1 and Dopamine D2 receptor2, whereas the second dataset comprised ligands to the P-glycoprotein 13. We assigned a categorical label to each compound according to its experimentally measured IC50 bioac_x0002_tivity value towards the target(s) under study. Compounds showing IC50 values below 10 nM were labeled as Active; compounds between 10 and 1000 nM were labeled as Moderately Active, and those over 1000 nM were labeled as Inactive. The serotonin-dopamine dataset comprises 118 compounds, whereas the P-glycoprotein dataset contains 893 compounds.",
      "data_code": {
        "tables": 1,
        "ordinal": 1,
        "clusters_and_sets_and_lists": 1
      }
    },
    "solution": [
      {
        "solution_category": "Visualization",
        "solution_axial": "Co-axis",
        "solution_compoent": "3Dstructure",
        "axial_code": ["Co-axis"],
        "componenet_code": ["3Dstructure"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 139,
    "paper_title": "ChemVA: Interactive Visual Analysis of Chemical Compound Similarity in Virtual Screening",
    "pub_year": 2021,
    "domain": "cheminformatics",
    "requirement": {
      "requirement_text": "R6: Possibility to add new compounds and comparison with the existing data. The tool should support the process of exploration of different features and bioactivity for newly added compounds. The new compound should be projected using the DR model and integrated into the remaining views, so that the user can compare its features to those of the compounds in the existing dataset.",
      "requirement_code": { "compare_entities": 1 }
    },
    "data": {
      "data_text": "The first dataset was composed by merging ligands binding to the Serotonin 1a receptor1 and Dopamine D2 receptor2, whereas the second dataset comprised ligands to the P-glycoprotein 13. We assigned a categorical label to each compound according to its experimentally measured IC50 bioac_x0002_tivity value towards the target(s) under study. Compounds showing IC50 values below 10 nM were labeled as Active; compounds between 10 and 1000 nM were labeled as Moderately Active, and those over 1000 nM were labeled as Inactive. The serotonin-dopamine dataset comprises 118 compounds, whereas the P-glycoprotein dataset contains 893 compounds.",
      "data_code": {
        "tables": 1,
        "ordinal": 1,
        "clusters_and_sets_and_lists": 1
      }
    },
    "solution": [
      {
        "solution_category": "Interaction",
        "solution_axial": "Participation/Collaboration",
        "solution_compoent": "",
        "axial_code": ["Participation/Collaboration"],
        "componenet_code": ["participation/collaboration"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 156,
    "paper_title": "CcNav: Understanding Compiler Optimizations in Binary Code",
    "pub_year": 2021,
    "domain": "compilation",
    "requirement": {
      "requirement_text": "T1.1 Match source code with binary cod",
      "requirement_code": { "describe_observation_item": 1 }
    },
    "data": {
      "data_text": "The input data for CcNavis a compiled executable and its source code, the former of which can be disassembled into disassembly code. Both source and disassembly code are text data. There may be multiple source files associated with a single executable file.",
      "data_code": { "text": 1 }
    },
    "solution": [
      {
        "solution_category": "Visualization",
        "solution_axial": "Repetition",
        "solution_compoent": "table+text",
        "axial_code": ["Repetition"],
        "componenet_code": ["text", "table"]
      },
      {
        "solution_category": "Interaction",
        "solution_axial": "Participation/Collaboration",
        "solution_compoent": "",
        "axial_code": ["Participation/Collaboration"],
        "componenet_code": ["participation/collaboration"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 157,
    "paper_title": "CcNav: Understanding Compiler Optimizations in Binary Code",
    "pub_year": 2021,
    "domain": "compilation",
    "requirement": {
      "requirement_text": "T1.1 Match source code with binary cod",
      "requirement_code": { "describe_observation_item": 1 }
    },
    "data": {
      "data_text": "The input data for CcNavis a compiled executable and its source code, the former of which can be disassembled into disassembly code. Both source and disassembly code are text data. There may be multiple source files associated with a single executable file.",
      "data_code": { "text": 1 }
    },
    "solution": [
      {
        "solution_category": "Interaction",
        "solution_axial": "Filtering",
        "solution_compoent": "",
        "axial_code": ["Filtering"],
        "componenet_code": ["filtering"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 158,
    "paper_title": "CcNav: Understanding Compiler Optimizations in Binary Code",
    "pub_year": 2021,
    "domain": "compilation",
    "requirement": {
      "requirement_text": "T1.1 Match source code with binary cod",
      "requirement_code": { "describe_observation_item": 1 }
    },
    "data": {
      "data_text": "The input data for CcNavis a compiled executable and its source code, the former of which can be disassembled into disassembly code. Both source and disassembly code are text data. There may be multiple source files associated with a single executable file.",
      "data_code": { "text": 1 }
    },
    "solution": [
      {
        "solution_category": "Visualization",
        "solution_axial": "Repetition",
        "solution_compoent": "table+text",
        "axial_code": ["Repetition"],
        "componenet_code": ["text", "table"]
      },
      {
        "solution_category": "Interaction",
        "solution_axial": "Selecting",
        "solution_compoent": "",
        "axial_code": ["Selecting"],
        "componenet_code": ["selecting"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 159,
    "paper_title": "CcNav: Understanding Compiler Optimizations in Binary Code",
    "pub_year": 2021,
    "domain": "compilation",
    "requirement": {
      "requirement_text": "T1.1 Match source code with binary cod",
      "requirement_code": { "describe_observation_item": 1 }
    },
    "data": {
      "data_text": "The input data for CcNavis a compiled executable and its source code, the former of which can be disassembled into disassembly code. Both source and disassembly code are text data. There may be multiple source files associated with a single executable file.",
      "data_code": { "text": 1 }
    },
    "solution": [
      {
        "solution_category": "Interaction",
        "solution_axial": "Filtering",
        "solution_compoent": "",
        "axial_code": ["Filtering"],
        "componenet_code": ["filtering"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 160,
    "paper_title": "CcNav: Understanding Compiler Optimizations in Binary Code",
    "pub_year": 2021,
    "domain": "compilation",
    "requirement": {
      "requirement_text": "T1.2 Identify/Relate structures with code",
      "requirement_code": { "describe_observation_item": 1 }
    },
    "data": {
      "data_text": "The input data for CcNavis a compiled executable and its source code, the former of which can be disassembled into disassembly code. Both source and disassembly code are text data. There may be multiple source files associated with a single executable file.",
      "data_code": { "text": 1 }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "Excluding",
        "solution_compoent": "",
        "axial_code": ["Excluding"],
        "componenet_code": ["excluding"]
      },
      {
        "solution_category": "Visualization",
        "solution_axial": "Repetition",
        "solution_compoent": "table+text",
        "axial_code": ["Repetition"],
        "componenet_code": ["text", "table"]
      },
      {
        "solution_category": "Interaction",
        "solution_axial": "Selecting",
        "solution_compoent": "",
        "axial_code": ["Selecting"],
        "componenet_code": ["selecting"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 161,
    "paper_title": "CcNav: Understanding Compiler Optimizations in Binary Code",
    "pub_year": 2021,
    "domain": "compilation",
    "requirement": {
      "requirement_text": "T1.2 Identify/Relate structures with code",
      "requirement_code": { "describe_observation_item": 1 }
    },
    "data": {
      "data_text": "The input data for CcNavis a compiled executable and its source code, the former of which can be disassembled into disassembly code. Both source and disassembly code are text data. There may be multiple source files associated with a single executable file.",
      "data_code": { "text": 1 }
    },
    "solution": [
      {
        "solution_category": "Visualization",
        "solution_axial": "Nesting",
        "solution_compoent": "network+contour+text",
        "axial_code": ["Nesting"],
        "componenet_code": ["text", "network", "contour"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 162,
    "paper_title": "CcNav: Understanding Compiler Optimizations in Binary Code",
    "pub_year": 2021,
    "domain": "compilation",
    "requirement": {
      "requirement_text": "T1.2 Identify/Relate structures with code",
      "requirement_code": { "describe_observation_item": 1 }
    },
    "data": {
      "data_text": "The input data for CcNavis a compiled executable and its source code, the former of which can be disassembled into disassembly code. Both source and disassembly code are text data. There may be multiple source files associated with a single executable file.",
      "data_code": { "text": 1 }
    },
    "solution": [
      {
        "solution_category": "Interaction",
        "solution_axial": "Filtering",
        "solution_compoent": "",
        "axial_code": ["Filtering"],
        "componenet_code": ["filtering"]
      },
      {
        "solution_category": "Visualization",
        "solution_axial": "Repetition",
        "solution_compoent": "text",
        "axial_code": ["Repetition"],
        "componenet_code": ["text"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 163,
    "paper_title": "CcNav: Understanding Compiler Optimizations in Binary Code",
    "pub_year": 2021,
    "domain": "compilation",
    "requirement": {
      "requirement_text": "T1.2 Identify/Relate structures with code",
      "requirement_code": { "describe_observation_item": 1 }
    },
    "data": {
      "data_text": "The input data for CcNavis a compiled executable and its source code, the former of which can be disassembled into disassembly code. Both source and disassembly code are text data. There may be multiple source files associated with a single executable file.",
      "data_code": { "text": 1 }
    },
    "solution": [
      {
        "solution_category": "Visualization",
        "solution_axial": "Nesting",
        "solution_compoent": "tree+text",
        "axial_code": ["Nesting"],
        "componenet_code": ["text", "tree"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 164,
    "paper_title": "CcNav: Understanding Compiler Optimizations in Binary Code",
    "pub_year": 2021,
    "domain": "compilation",
    "requirement": {
      "requirement_text": "T1.2 Identify/Relate structures with code",
      "requirement_code": { "describe_observation_item": 1 }
    },
    "data": {
      "data_text": "The input data for CcNavis a compiled executable and its source code, the former of which can be disassembled into disassembly code. Both source and disassembly code are text data. There may be multiple source files associated with a single executable file.",
      "data_code": { "text": 1 }
    },
    "solution": [
      {
        "solution_category": "Interaction",
        "solution_axial": "Filtering",
        "solution_compoent": "",
        "axial_code": ["Filtering"],
        "componenet_code": ["filtering"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 165,
    "paper_title": "CcNav: Understanding Compiler Optimizations in Binary Code",
    "pub_year": 2021,
    "domain": "compilation",
    "requirement": {
      "requirement_text": "T1.2 Identify/Relate structures with code",
      "requirement_code": { "describe_observation_item": 1 }
    },
    "data": {
      "data_text": "The input data for CcNavis a compiled executable and its source code, the former of which can be disassembled into disassembly code. Both source and disassembly code are text data. There may be multiple source files associated with a single executable file.",
      "data_code": { "text": 1 }
    },
    "solution": [
      {
        "solution_category": "Visualization",
        "solution_axial": "Nesting",
        "solution_compoent": "network+text",
        "axial_code": ["Nesting"],
        "componenet_code": ["text", "network"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 166,
    "paper_title": "CcNav: Understanding Compiler Optimizations in Binary Code",
    "pub_year": 2021,
    "domain": "compilation",
    "requirement": {
      "requirement_text": "T1.3 Annotate relations",
      "requirement_code": { "describe_observation_item": 1 }
    },
    "data": {
      "data_text": "The input data for CcNavis a compiled executable and its source code, the former of which can be disassembled into disassembly code. Both source and disassembly code are text data. There may be multiple source files associated with a single executable file.",
      "data_code": { "text": 1 }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "Excluding",
        "solution_compoent": "",
        "axial_code": ["Excluding"],
        "componenet_code": ["excluding"]
      },
      {
        "solution_category": "Visualization",
        "solution_axial": "Repetition",
        "solution_compoent": "table+text",
        "axial_code": ["Repetition"],
        "componenet_code": ["text", "table"]
      },
      {
        "solution_category": "Interaction",
        "solution_axial": "Selecting",
        "solution_compoent": "",
        "axial_code": ["Selecting"],
        "componenet_code": ["selecting"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 167,
    "paper_title": "CcNav: Understanding Compiler Optimizations in Binary Code",
    "pub_year": 2021,
    "domain": "compilation",
    "requirement": {
      "requirement_text": "T1.3 Annotate relations",
      "requirement_code": { "describe_observation_item": 1 }
    },
    "data": {
      "data_text": "The input data for CcNavis a compiled executable and its source code, the former of which can be disassembled into disassembly code. Both source and disassembly code are text data. There may be multiple source files associated with a single executable file.",
      "data_code": { "text": 1 }
    },
    "solution": [
      {
        "solution_category": "Interaction",
        "solution_axial": "Participation/Collaboration",
        "solution_compoent": "",
        "axial_code": ["Participation/Collaboration"],
        "componenet_code": ["participation/collaboration"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 168,
    "paper_title": "CcNav: Understanding Compiler Optimizations in Binary Code",
    "pub_year": 2021,
    "domain": "compilation",
    "requirement": {
      "requirement_text": "T1.4 Trace variable",
      "requirement_code": { "describe_observation_item": 1 }
    },
    "data": {
      "data_text": "The input data for CcNavis a compiled executable and its source code, the former of which can be disassembled into disassembly code. Both source and disassembly code are text data. There may be multiple source files associated with a single executable file.",
      "data_code": { "text": 1 }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "Excluding",
        "solution_compoent": "",
        "axial_code": ["Excluding"],
        "componenet_code": ["excluding"]
      },
      {
        "solution_category": "Visualization",
        "solution_axial": "Repetition",
        "solution_compoent": "table+text",
        "axial_code": ["Repetition"],
        "componenet_code": ["text", "table"]
      },
      {
        "solution_category": "Interaction",
        "solution_axial": "Selecting",
        "solution_compoent": "",
        "axial_code": ["Selecting"],
        "componenet_code": ["selecting"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 169,
    "paper_title": "CcNav: Understanding Compiler Optimizations in Binary Code",
    "pub_year": 2021,
    "domain": "compilation",
    "requirement": {
      "requirement_text": "T1.4 Trace variable",
      "requirement_code": { "describe_observation_item": 1 }
    },
    "data": {
      "data_text": "The input data for CcNavis a compiled executable and its source code, the former of which can be disassembled into disassembly code. Both source and disassembly code are text data. There may be multiple source files associated with a single executable file.",
      "data_code": { "text": 1 }
    },
    "solution": [
      {
        "solution_category": "Visualization",
        "solution_axial": "Nesting",
        "solution_compoent": "network+text",
        "axial_code": ["Nesting"],
        "componenet_code": ["text", "network"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 170,
    "paper_title": "CcNav: Understanding Compiler Optimizations in Binary Code",
    "pub_year": 2021,
    "domain": "compilation",
    "requirement": {
      "requirement_text": "T2.1 Find areas of interest",
      "requirement_code": { "identify_main_cause_item": 1 }
    },
    "data": {
      "data_text": "The input data for CcNavis a compiled executable and its source code, the former of which can be disassembled into disassembly code. Both source and disassembly code are text data. There may be multiple source files associated with a single executable file.",
      "data_code": { "text": 1 }
    },
    "solution": [
      {
        "solution_category": "Interaction",
        "solution_axial": "Filtering,Participation/Collaboration",
        "solution_compoent": "",
        "axial_code": ["Participation/Collaboration", "Filtering"],
        "componenet_code": [
          "participation/collaboration",
          "filtering",
          "participation/collaboration",
          "filtering"
        ]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 171,
    "paper_title": "CcNav: Understanding Compiler Optimizations in Binary Code",
    "pub_year": 2021,
    "domain": "compilation",
    "requirement": {
      "requirement_text": "T2.1 Find areas of interest",
      "requirement_code": { "identify_main_cause_item": 1 }
    },
    "data": {
      "data_text": "The input data for CcNavis a compiled executable and its source code, the former of which can be disassembled into disassembly code. Both source and disassembly code are text data. There may be multiple source files associated with a single executable file.",
      "data_code": { "text": 1 }
    },
    "solution": [
      {
        "solution_category": "Visualization",
        "solution_axial": "Nesting",
        "solution_compoent": "tree+text",
        "axial_code": ["Nesting"],
        "componenet_code": ["text", "tree"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 172,
    "paper_title": "CcNav: Understanding Compiler Optimizations in Binary Code",
    "pub_year": 2021,
    "domain": "compilation",
    "requirement": {
      "requirement_text": "T2.1 Find areas of interest",
      "requirement_code": { "identify_main_cause_item": 1 }
    },
    "data": {
      "data_text": "The input data for CcNavis a compiled executable and its source code, the former of which can be disassembled into disassembly code. Both source and disassembly code are text data. There may be multiple source files associated with a single executable file.",
      "data_code": { "text": 1 }
    },
    "solution": [
      {
        "solution_category": "Visualization",
        "solution_axial": "Nesting",
        "solution_compoent": "tree+text",
        "axial_code": ["Nesting"],
        "componenet_code": ["text", "tree"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 173,
    "paper_title": "CcNav: Understanding Compiler Optimizations in Binary Code",
    "pub_year": 2021,
    "domain": "compilation",
    "requirement": {
      "requirement_text": "T2.1 Find areas of interest",
      "requirement_code": { "identify_main_cause_item": 1 }
    },
    "data": {
      "data_text": "The input data for CcNavis a compiled executable and its source code, the former of which can be disassembled into disassembly code. Both source and disassembly code are text data. There may be multiple source files associated with a single executable file.",
      "data_code": { "text": 1 }
    },
    "solution": [
      {
        "solution_category": "Interaction",
        "solution_axial": "Filtering",
        "solution_compoent": "",
        "axial_code": ["Filtering"],
        "componenet_code": ["filtering"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 174,
    "paper_title": "CcNav: Understanding Compiler Optimizations in Binary Code",
    "pub_year": 2021,
    "domain": "compilation",
    "requirement": {
      "requirement_text": "T2.2 Identify optimizations",
      "requirement_code": { "identify_main_cause_item": 1 }
    },
    "data": {
      "data_text": "The input data for CcNavis a compiled executable and its source code, the former of which can be disassembled into disassembly code. Both source and disassembly code are text data. There may be multiple source files associated with a single executable file.",
      "data_code": { "text": 1 }
    },
    "solution": [
      {
        "solution_category": "Interaction",
        "solution_axial": "Filtering",
        "solution_compoent": "",
        "axial_code": ["Filtering"],
        "componenet_code": ["filtering"]
      },
      {
        "solution_category": "Visualization",
        "solution_axial": "Repetition",
        "solution_compoent": "text",
        "axial_code": ["Repetition"],
        "componenet_code": ["text"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 175,
    "paper_title": "CcNav: Understanding Compiler Optimizations in Binary Code",
    "pub_year": 2021,
    "domain": "compilation",
    "requirement": {
      "requirement_text": "T2.2 Identify optimizations",
      "requirement_code": { "identify_main_cause_item": 1 }
    },
    "data": {
      "data_text": "The input data for CcNavis a compiled executable and its source code, the former of which can be disassembled into disassembly code. Both source and disassembly code are text data. There may be multiple source files associated with a single executable file.",
      "data_code": { "text": 1 }
    },
    "solution": [
      {
        "solution_category": "Visualization",
        "solution_axial": "Nesting",
        "solution_compoent": "tree+text",
        "axial_code": ["Nesting"],
        "componenet_code": ["text", "tree"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 176,
    "paper_title": "CcNav: Understanding Compiler Optimizations in Binary Code",
    "pub_year": 2021,
    "domain": "compilation",
    "requirement": {
      "requirement_text": "T2.2 Identify optimizations",
      "requirement_code": { "identify_main_cause_item": 1 }
    },
    "data": {
      "data_text": "The input data for CcNavis a compiled executable and its source code, the former of which can be disassembled into disassembly code. Both source and disassembly code are text data. There may be multiple source files associated with a single executable file.",
      "data_code": { "text": 1 }
    },
    "solution": [
      {
        "solution_category": "Visualization",
        "solution_axial": "Nesting",
        "solution_compoent": "network+text",
        "axial_code": ["Nesting"],
        "componenet_code": ["text", "network"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 177,
    "paper_title": "CcNav: Understanding Compiler Optimizations in Binary Code",
    "pub_year": 2021,
    "domain": "compilation",
    "requirement": {
      "requirement_text": "T2.3 Assess optimizations",
      "requirement_code": { "identify_main_cause_item": 1 }
    },
    "data": {
      "data_text": "The input data for CcNavis a compiled executable and its source code, the former of which can be disassembled into disassembly code. Both source and disassembly code are text data. There may be multiple source files associated with a single executable file.",
      "data_code": { "text": 1 }
    },
    "solution": [
      {
        "solution_category": "Interaction",
        "solution_axial": "Filtering",
        "solution_compoent": "",
        "axial_code": ["Filtering"],
        "componenet_code": ["filtering"]
      },
      {
        "solution_category": "Visualization",
        "solution_axial": "Repetition",
        "solution_compoent": "text",
        "axial_code": ["Repetition"],
        "componenet_code": ["text"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 179,
    "paper_title": "Selection-Bias-Corrected Visualization via Dynamic Reweighting",
    "pub_year": 2021,
    "domain": "bias ",
    "requirement": {
      "requirement_text": "R1. Identify relevant dimensions that exhibit high levels of bias.Users should be able to see which dimensions exhibit high lev-els of selection bias and understand which of those high-biasdimensions, and groups of dimensions, are most relevant for theiranalytical question.",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "The prototype implementation of the techniques described in this paper are applied to medical data which contain both non-temporal attributes (e.g., gender and race) and time-dependent events (e.g., diagnoses and procedures). Medical events are represented using widely-used coding systems such as ICD-10-CM [31] and SNOMED-CT [37] for diagnoses and procedures, respectively. These coding systems include over 300,000 distinct codes organized within hierarchical structures, and the electronic health record data can contain events coded at various levels of details. For instance, a single patient might be diagnosed with a generic ICD-10-CM code of I50: Heart Failure at one time and the more specific I50.32: Chronic diastolic (congestive) heart failure at another time. The hierarchical nature of the coding systems means that a patient with the specific I50.32 diagnosis would also be considered to have the more generic I50. This property highlights the importance of understanding selection bias and how DR corrects for it at different levels of specificity in the event type hierarchies.",
      "data_code": { "network_and_trees": 1, "quantitative": 1 }
    },
    "solution": [
      {
        "solution_category": "Visualization",
        "solution_axial": "Repetition",
        "solution_compoent": "icicle",
        "axial_code": ["Repetition"],
        "componenet_code": ["icicle"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 180,
    "paper_title": "Selection-Bias-Corrected Visualization via Dynamic Reweighting",
    "pub_year": 2021,
    "domain": "bias ",
    "requirement": {
      "requirement_text": "R1. Identify relevant dimensions that exhibit high levels of bias.Users should be able to see which dimensions exhibit high lev-els of selection bias and understand which of those high-biasdimensions, and groups of dimensions, are most relevant for theiranalytical question.",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "The prototype implementation of the techniques described in this paper are applied to medical data which contain both non-temporal attributes (e.g., gender and race) and time-dependent events (e.g., diagnoses and procedures). Medical events are represented using widely-used coding systems such as ICD-10-CM [31] and SNOMED-CT [37] for diagnoses and procedures, respectively. These coding systems include over 300,000 distinct codes organized within hierarchical structures, and the electronic health record data can contain events coded at various levels of details. For instance, a single patient might be diagnosed with a generic ICD-10-CM code of I50: Heart Failure at one time and the more specific I50.32: Chronic diastolic (congestive) heart failure at another time. The hierarchical nature of the coding systems means that a patient with the specific I50.32 diagnosis would also be considered to have the more generic I50. This property highlights the importance of understanding selection bias and how DR corrects for it at different levels of specificity in the event type hierarchies.",
      "data_code": { "network_and_trees": 1, "quantitative": 1 }
    },
    "solution": [
      {
        "solution_category": "Visualization",
        "solution_axial": "Repetition",
        "solution_compoent": "icicle",
        "axial_code": ["Repetition"],
        "componenet_code": ["icicle"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 181,
    "paper_title": "Selection-Bias-Corrected Visualization via Dynamic Reweighting",
    "pub_year": 2021,
    "domain": "bias ",
    "requirement": {
      "requirement_text": "R1. Identify relevant dimensions that exhibit high levels of bias.Users should be able to see which dimensions exhibit high lev-els of selection bias and understand which of those high-biasdimensions, and groups of dimensions, are most relevant for theiranalytical question.",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "The prototype implementation of the techniques described in this paper are applied to medical data which contain both non-temporal attributes (e.g., gender and race) and time-dependent events (e.g., diagnoses and procedures). Medical events are represented using widely-used coding systems such as ICD-10-CM [31] and SNOMED-CT [37] for diagnoses and procedures, respectively. These coding systems include over 300,000 distinct codes organized within hierarchical structures, and the electronic health record data can contain events coded at various levels of details. For instance, a single patient might be diagnosed with a generic ICD-10-CM code of I50: Heart Failure at one time and the more specific I50.32: Chronic diastolic (congestive) heart failure at another time. The hierarchical nature of the coding systems means that a patient with the specific I50.32 diagnosis would also be considered to have the more generic I50. This property highlights the importance of understanding selection bias and how DR corrects for it at different levels of specificity in the event type hierarchies.",
      "data_code": { "tables": 1, "quantitative": 1, "network_and_trees": 1 }
    },
    "solution": [
      {
        "solution_category": "Visualization",
        "solution_axial": "Stack",
        "solution_compoent": "icicle+table",
        "axial_code": ["Stack"],
        "componenet_code": ["table", "icicle"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 182,
    "paper_title": "Selection-Bias-Corrected Visualization via Dynamic Reweighting",
    "pub_year": 2021,
    "domain": "bias ",
    "requirement": {
      "requirement_text": "R1. Identify relevant dimensions that exhibit high levels of bias.Users should be able to see which dimensions exhibit high lev-els of selection bias and understand which of those high-biasdimensions, and groups of dimensions, are most relevant for theiranalytical question.",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "The prototype implementation of the techniques described in this paper are applied to medical data which contain both non-temporal attributes (e.g., gender and race) and time-dependent events (e.g., diagnoses and procedures). Medical events are represented using widely-used coding systems such as ICD-10-CM [31] and SNOMED-CT [37] for diagnoses and procedures, respectively. These coding systems include over 300,000 distinct codes organized within hierarchical structures, and the electronic health record data can contain events coded at various levels of details. For instance, a single patient might be diagnosed with a generic ICD-10-CM code of I50: Heart Failure at one time and the more specific I50.32: Chronic diastolic (congestive) heart failure at another time. The hierarchical nature of the coding systems means that a patient with the specific I50.32 diagnosis would also be considered to have the more generic I50. This property highlights the importance of understanding selection bias and how DR corrects for it at different levels of specificity in the event type hierarchies.",
      "data_code": { "tables": 1, "quantitative": 1, "network_and_trees": 1 }
    },
    "solution": [
      {
        "solution_category": "Visualization",
        "solution_axial": "Stack",
        "solution_compoent": "scatter+contour+vector",
        "axial_code": ["Stack"],
        "componenet_code": ["scatter", "contour", "vector"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 183,
    "paper_title": "Selection-Bias-Corrected Visualization via Dynamic Reweighting",
    "pub_year": 2021,
    "domain": "bias ",
    "requirement": {
      "requirement_text": "R2. Apply bias correction based on user-selected dimensions.Users should be able to specify one or more dimensions for biascorrection and have the system automatically determine the re-quired sample weighting to perform the correction.",
      "requirement_code": { "evaluate_hypothesis": 1, "collect_evidence": 1 }
    },
    "data": {
      "data_text": "The prototype implementation of the techniques described in this paper are applied to medical data which contain both non-temporal attributes (e.g., gender and race) and time-dependent events (e.g., diagnoses and procedures). Medical events are represented using widely-used coding systems such as ICD-10-CM [31] and SNOMED-CT [37] for diagnoses and procedures, respectively. These coding systems include over 300,000 distinct codes organized within hierarchical structures, and the electronic health record data can contain events coded at various levels of details. For instance, a single patient might be diagnosed with a generic ICD-10-CM code of I50: Heart Failure at one time and the more specific I50.32: Chronic diastolic (congestive) heart failure at another time. The hierarchical nature of the coding systems means that a patient with the specific I50.32 diagnosis would also be considered to have the more generic I50. This property highlights the importance of understanding selection bias and how DR corrects for it at different levels of specificity in the event type hierarchies.",
      "data_code": { "network_and_trees": 1, "quantitative": 1 }
    },
    "solution": [
      {
        "solution_category": "Visualization",
        "solution_axial": "Repetition",
        "solution_compoent": "icicle",
        "axial_code": ["Repetition"],
        "componenet_code": ["icicle"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 184,
    "paper_title": "Selection-Bias-Corrected Visualization via Dynamic Reweighting",
    "pub_year": 2021,
    "domain": "bias ",
    "requirement": {
      "requirement_text": "R2. Apply bias correction based on user-selected dimensions.Users should be able to specify one or more dimensions for biascorrection and have the system automatically determine the re-quired sample weighting to perform the correction.",
      "requirement_code": { "evaluate_hypothesis": 1, "collect_evidence": 1 }
    },
    "data": {
      "data_text": "The prototype implementation of the techniques described in this paper are applied to medical data which contain both non-temporal attributes (e.g., gender and race) and time-dependent events (e.g., diagnoses and procedures). Medical events are represented using widely-used coding systems such as ICD-10-CM [31] and SNOMED-CT [37] for diagnoses and procedures, respectively. These coding systems include over 300,000 distinct codes organized within hierarchical structures, and the electronic health record data can contain events coded at various levels of details. For instance, a single patient might be diagnosed with a generic ICD-10-CM code of I50: Heart Failure at one time and the more specific I50.32: Chronic diastolic (congestive) heart failure at another time. The hierarchical nature of the coding systems means that a patient with the specific I50.32 diagnosis would also be considered to have the more generic I50. This property highlights the importance of understanding selection bias and how DR corrects for it at different levels of specificity in the event type hierarchies.",
      "data_code": { "tables": 1, "quantitative": 1, "network_and_trees": 1 }
    },
    "solution": [
      {
        "solution_category": "Visualization",
        "solution_axial": "Stack",
        "solution_compoent": "icicle+table",
        "axial_code": ["Stack"],
        "componenet_code": ["table", "icicle"]
      },
      {
        "solution_category": "Interaction",
        "solution_axial": "OverviewandExplore",
        "solution_compoent": "",
        "axial_code": ["OverviewandExplore"],
        "componenet_code": ["overview_and_explore"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 185,
    "paper_title": "Selection-Bias-Corrected Visualization via Dynamic Reweighting",
    "pub_year": 2021,
    "domain": "bias ",
    "requirement": {
      "requirement_text": "R2. Apply bias correction based on user-selected dimensions.Users should be able to specify one or more dimensions for biascorrection and have the system automatically determine the re-quired sample weighting to perform the correction.",
      "requirement_code": { "evaluate_hypothesis": 1, "collect_evidence": 1 }
    },
    "data": {
      "data_text": "The prototype implementation of the techniques described in this paper are applied to medical data which contain both non-temporal attributes (e.g., gender and race) and time-dependent events (e.g., diagnoses and procedures). Medical events are represented using widely-used coding systems such as ICD-10-CM [31] and SNOMED-CT [37] for diagnoses and procedures, respectively. These coding systems include over 300,000 distinct codes organized within hierarchical structures, and the electronic health record data can contain events coded at various levels of details. For instance, a single patient might be diagnosed with a generic ICD-10-CM code of I50: Heart Failure at one time and the more specific I50.32: Chronic diastolic (congestive) heart failure at another time. The hierarchical nature of the coding systems means that a patient with the specific I50.32 diagnosis would also be considered to have the more generic I50. This property highlights the importance of understanding selection bias and how DR corrects for it at different levels of specificity in the event type hierarchies.",
      "data_code": { "tables": 1, "quantitative": 1, "network_and_trees": 1 }
    },
    "solution": [
      {
        "solution_category": "Interaction",
        "solution_axial": "Filtering",
        "solution_compoent": "",
        "axial_code": ["Filtering"],
        "componenet_code": ["filtering"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 186,
    "paper_title": "Selection-Bias-Corrected Visualization via Dynamic Reweighting",
    "pub_year": 2021,
    "domain": "bias ",
    "requirement": {
      "requirement_text": "R3. Understand the effect of bias correction. This includes two keyaspects. First (R3.1), as correcting for a small set of speci\ufb01eddimensions will affect a larger set of dimensions, the user shouldbe made aware of how widespread the effects of reweighting are,where bias was reduced, and where and how much bias remains.Second (R3.2), users must understand the effect of bias correctionon the visualizations driving their primary analysis.",
      "requirement_code": { "describe_observation_aggregate": 1 }
    },
    "data": {
      "data_text": "The prototype implementation of the techniques described in this paper are applied to medical data which contain both non-temporal attributes (e.g., gender and race) and time-dependent events (e.g., diagnoses and procedures). Medical events are represented using widely-used coding systems such as ICD-10-CM [31] and SNOMED-CT [37] for diagnoses and procedures, respectively. These coding systems include over 300,000 distinct codes organized within hierarchical structures, and the electronic health record data can contain events coded at various levels of details. For instance, a single patient might be diagnosed with a generic ICD-10-CM code of I50: Heart Failure at one time and the more specific I50.32: Chronic diastolic (congestive) heart failure at another time. The hierarchical nature of the coding systems means that a patient with the specific I50.32 diagnosis would also be considered to have the more generic I50. This property highlights the importance of understanding selection bias and how DR corrects for it at different levels of specificity in the event type hierarchies.",
      "data_code": { "tables": 1, "quantitative": 1, "network_and_trees": 1 }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "AlgorithmCalculation",
        "solution_compoent": "",
        "axial_code": ["AlgorithmCalculation"],
        "componenet_code": ["algorithmic_calculation"]
      },
      {
        "solution_category": "Visualization",
        "solution_axial": "Nesting",
        "solution_compoent": "tree+glyph",
        "axial_code": ["Nesting"],
        "componenet_code": ["glyph", "tree"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 187,
    "paper_title": "Selection-Bias-Corrected Visualization via Dynamic Reweighting",
    "pub_year": 2021,
    "domain": "bias ",
    "requirement": {
      "requirement_text": "R3. Understand the effect of bias correction. This includes two keyaspects. First (R3.1), as correcting for a small set of speci\ufb01eddimensions will affect a larger set of dimensions, the user shouldbe made aware of how widespread the effects of reweighting are,where bias was reduced, and where and how much bias remains.Second (R3.2), users must understand the effect of bias correctionon the visualizations driving their primary analysis.",
      "requirement_code": { "describe_observation_aggregate": 1 }
    },
    "data": {
      "data_text": "The prototype implementation of the techniques described in this paper are applied to medical data which contain both non-temporal attributes (e.g., gender and race) and time-dependent events (e.g., diagnoses and procedures). Medical events are represented using widely-used coding systems such as ICD-10-CM [31] and SNOMED-CT [37] for diagnoses and procedures, respectively. These coding systems include over 300,000 distinct codes organized within hierarchical structures, and the electronic health record data can contain events coded at various levels of details. For instance, a single patient might be diagnosed with a generic ICD-10-CM code of I50: Heart Failure at one time and the more specific I50.32: Chronic diastolic (congestive) heart failure at another time. The hierarchical nature of the coding systems means that a patient with the specific I50.32 diagnosis would also be considered to have the more generic I50. This property highlights the importance of understanding selection bias and how DR corrects for it at different levels of specificity in the event type hierarchies.",
      "data_code": { "network_and_trees": 1, "quantitative": 1 }
    },
    "solution": [
      {
        "solution_category": "Visualization",
        "solution_axial": "Repetition",
        "solution_compoent": "icicle",
        "axial_code": ["Repetition"],
        "componenet_code": ["icicle"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 188,
    "paper_title": "Selection-Bias-Corrected Visualization via Dynamic Reweighting",
    "pub_year": 2021,
    "domain": "bias ",
    "requirement": {
      "requirement_text": "R3. Understand the effect of bias correction. This includes two keyaspects. First (R3.1), as correcting for a small set of speci\ufb01eddimensions will affect a larger set of dimensions, the user shouldbe made aware of how widespread the effects of reweighting are,where bias was reduced, and where and how much bias remains.Second (R3.2), users must understand the effect of bias correctionon the visualizations driving their primary analysis.",
      "requirement_code": { "describe_observation_aggregate": 1 }
    },
    "data": {
      "data_text": "The prototype implementation of the techniques described in this paper are applied to medical data which contain both non-temporal attributes (e.g., gender and race) and time-dependent events (e.g., diagnoses and procedures). Medical events are represented using widely-used coding systems such as ICD-10-CM [31] and SNOMED-CT [37] for diagnoses and procedures, respectively. These coding systems include over 300,000 distinct codes organized within hierarchical structures, and the electronic health record data can contain events coded at various levels of details. For instance, a single patient might be diagnosed with a generic ICD-10-CM code of I50: Heart Failure at one time and the more specific I50.32: Chronic diastolic (congestive) heart failure at another time. The hierarchical nature of the coding systems means that a patient with the specific I50.32 diagnosis would also be considered to have the more generic I50. This property highlights the importance of understanding selection bias and how DR corrects for it at different levels of specificity in the event type hierarchies.",
      "data_code": { "tables": 1, "quantitative": 1, "network_and_trees": 1 }
    },
    "solution": [
      {
        "solution_category": "Visualization",
        "solution_axial": "Stack",
        "solution_compoent": "scatter+contour+vector",
        "axial_code": ["Stack"],
        "componenet_code": ["scatter", "contour", "vector"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 189,
    "paper_title": "Selection-Bias-Corrected Visualization via Dynamic Reweighting",
    "pub_year": 2021,
    "domain": "bias ",
    "requirement": {
      "requirement_text": "R3. Understand the effect of bias correction. This includes two keyaspects. First (R3.1), as correcting for a small set of speci\ufb01eddimensions will affect a larger set of dimensions, the user shouldbe made aware of how widespread the effects of reweighting are,where bias was reduced, and where and how much bias remains.Second (R3.2), users must understand the effect of bias correctionon the visualizations driving their primary analysis.",
      "requirement_code": { "describe_observation_aggregate": 1 }
    },
    "data": {
      "data_text": "The prototype implementation of the techniques described in this paper are applied to medical data which contain both non-temporal attributes (e.g., gender and race) and time-dependent events (e.g., diagnoses and procedures). Medical events are represented using widely-used coding systems such as ICD-10-CM [31] and SNOMED-CT [37] for diagnoses and procedures, respectively. These coding systems include over 300,000 distinct codes organized within hierarchical structures, and the electronic health record data can contain events coded at various levels of details. For instance, a single patient might be diagnosed with a generic ICD-10-CM code of I50: Heart Failure at one time and the more specific I50.32: Chronic diastolic (congestive) heart failure at another time. The hierarchical nature of the coding systems means that a patient with the specific I50.32 diagnosis would also be considered to have the more generic I50. This property highlights the importance of understanding selection bias and how DR corrects for it at different levels of specificity in the event type hierarchies.",
      "data_code": { "tables": 1, "quantitative": 1, "network_and_trees": 1 }
    },
    "solution": [
      {
        "solution_category": "Visualization",
        "solution_axial": "Repetition",
        "solution_compoent": "distancevs.correlationplots",
        "axial_code": ["Repetition"],
        "componenet_code": ["correlationplots", "distancevs"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 190,
    "paper_title": "Selection-Bias-Corrected Visualization via Dynamic Reweighting",
    "pub_year": 2021,
    "domain": "bias ",
    "requirement": {
      "requirement_text": "R4. Prevent over\ufb01tting for poorly represented subgroups. Insome cases the weighted samples used for bias correction canexcessively amplify poorly sampled subgroups, similar to theproblem of model over\ufb01tting. Users must be able to understandwhen a proposed bias correction poses a risk of over\ufb01tting dueto limitations in the underlying data, and be able to revise thereweighting con\ufb01guration appropriately.",
      "requirement_code": { "identify_main_cause_item": 1 }
    },
    "data": {
      "data_text": "The prototype implementation of the techniques described in this paper are applied to medical data which contain both non-temporal attributes (e.g., gender and race) and time-dependent events (e.g., diagnoses and procedures). Medical events are represented using widely-used coding systems such as ICD-10-CM [31] and SNOMED-CT [37] for diagnoses and procedures, respectively. These coding systems include over 300,000 distinct codes organized within hierarchical structures, and the electronic health record data can contain events coded at various levels of details. For instance, a single patient might be diagnosed with a generic ICD-10-CM code of I50: Heart Failure at one time and the more specific I50.32: Chronic diastolic (congestive) heart failure at another time. The hierarchical nature of the coding systems means that a patient with the specific I50.32 diagnosis would also be considered to have the more generic I50. This property highlights the importance of understanding selection bias and how DR corrects for it at different levels of specificity in the event type hierarchies.",
      "data_code": { "tables": 1, "quantitative": 1, "network_and_trees": 1 }
    },
    "solution": [
      {
        "solution_category": "Visualization",
        "solution_axial": "Repetition",
        "solution_compoent": "bar",
        "axial_code": ["Repetition"],
        "componenet_code": ["bar"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 191,
    "paper_title": "Selection-Bias-Corrected Visualization via Dynamic Reweighting",
    "pub_year": 2021,
    "domain": "bias ",
    "requirement": {
      "requirement_text": "R4. Prevent over\ufb01tting for poorly represented subgroups. Insome cases the weighted samples used for bias correction canexcessively amplify poorly sampled subgroups, similar to theproblem of model over\ufb01tting. Users must be able to understandwhen a proposed bias correction poses a risk of over\ufb01tting dueto limitations in the underlying data, and be able to revise thereweighting con\ufb01guration appropriately.",
      "requirement_code": { "identify_main_cause_item": 1 }
    },
    "data": {
      "data_text": "The prototype implementation of the techniques described in this paper are applied to medical data which contain both non-temporal attributes (e.g., gender and race) and time-dependent events (e.g., diagnoses and procedures). Medical events are represented using widely-used coding systems such as ICD-10-CM [31] and SNOMED-CT [37] for diagnoses and procedures, respectively. These coding systems include over 300,000 distinct codes organized within hierarchical structures, and the electronic health record data can contain events coded at various levels of details. For instance, a single patient might be diagnosed with a generic ICD-10-CM code of I50: Heart Failure at one time and the more specific I50.32: Chronic diastolic (congestive) heart failure at another time. The hierarchical nature of the coding systems means that a patient with the specific I50.32 diagnosis would also be considered to have the more generic I50. This property highlights the importance of understanding selection bias and how DR corrects for it at different levels of specificity in the event type hierarchies.",
      "data_code": { "tables": 1, "quantitative": 1, "network_and_trees": 1 }
    },
    "solution": [
      {
        "solution_category": "Visualization",
        "solution_axial": "Stack",
        "solution_compoent": "icicle+table",
        "axial_code": ["Stack"],
        "componenet_code": ["table", "icicle"]
      },
      {
        "solution_category": "Interaction",
        "solution_axial": "OverviewandExplore",
        "solution_compoent": "",
        "axial_code": ["OverviewandExplore"],
        "componenet_code": ["overview_and_explore"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 192,
    "paper_title": "Selection-Bias-Corrected Visualization via Dynamic Reweighting",
    "pub_year": 2021,
    "domain": "bias ",
    "requirement": {
      "requirement_text": "R4. Prevent over\ufb01tting for poorly represented subgroups. Insome cases the weighted samples used for bias correction canexcessively amplify poorly sampled subgroups, similar to theproblem of model over\ufb01tting. Users must be able to understandwhen a proposed bias correction poses a risk of over\ufb01tting dueto limitations in the underlying data, and be able to revise thereweighting con\ufb01guration appropriately.",
      "requirement_code": { "identify_main_cause_item": 1 }
    },
    "data": {
      "data_text": "The prototype implementation of the techniques described in this paper are applied to medical data which contain both non-temporal attributes (e.g., gender and race) and time-dependent events (e.g., diagnoses and procedures). Medical events are represented using widely-used coding systems such as ICD-10-CM [31] and SNOMED-CT [37] for diagnoses and procedures, respectively. These coding systems include over 300,000 distinct codes organized within hierarchical structures, and the electronic health record data can contain events coded at various levels of details. For instance, a single patient might be diagnosed with a generic ICD-10-CM code of I50: Heart Failure at one time and the more specific I50.32: Chronic diastolic (congestive) heart failure at another time. The hierarchical nature of the coding systems means that a patient with the specific I50.32 diagnosis would also be considered to have the more generic I50. This property highlights the importance of understanding selection bias and how DR corrects for it at different levels of specificity in the event type hierarchies.",
      "data_code": { "tables": 1, "quantitative": 1, "network_and_trees": 1 }
    },
    "solution": [
      {
        "solution_category": "Interaction",
        "solution_axial": "Filtering",
        "solution_compoent": "",
        "axial_code": ["Filtering"],
        "componenet_code": ["filtering"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 193,
    "paper_title": "Selection-Bias-Corrected Visualization via Dynamic Reweighting",
    "pub_year": 2021,
    "domain": "bias ",
    "requirement": {
      "requirement_text": "R4. Prevent over\ufb01tting for poorly represented subgroups. Insome cases the weighted samples used for bias correction canexcessively amplify poorly sampled subgroups, similar to theproblem of model over\ufb01tting. Users must be able to understandwhen a proposed bias correction poses a risk of over\ufb01tting dueto limitations in the underlying data, and be able to revise thereweighting con\ufb01guration appropriately.",
      "requirement_code": { "identify_main_cause_item": 1 }
    },
    "data": {
      "data_text": "The prototype implementation of the techniques described in this paper are applied to medical data which contain both non-temporal attributes (e.g., gender and race) and time-dependent events (e.g., diagnoses and procedures). Medical events are represented using widely-used coding systems such as ICD-10-CM [31] and SNOMED-CT [37] for diagnoses and procedures, respectively. These coding systems include over 300,000 distinct codes organized within hierarchical structures, and the electronic health record data can contain events coded at various levels of details. For instance, a single patient might be diagnosed with a generic ICD-10-CM code of I50: Heart Failure at one time and the more specific I50.32: Chronic diastolic (congestive) heart failure at another time. The hierarchical nature of the coding systems means that a patient with the specific I50.32 diagnosis would also be considered to have the more generic I50. This property highlights the importance of understanding selection bias and how DR corrects for it at different levels of specificity in the event type hierarchies.",
      "data_code": { "tables": 1, "quantitative": 1, "network_and_trees": 1 }
    },
    "solution": [
      {
        "solution_category": "Visualization",
        "solution_axial": "Stack",
        "solution_compoent": "matrix+bar",
        "axial_code": ["Stack"],
        "componenet_code": ["matrix", "bar"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 194,
    "paper_title": "VATLD: A Visual Analytics System to Assess, Understand and Improve Traffic Light Detection",
    "pub_year": 2021,
    "domain": "autonomous driving",
    "requirement": {
      "requirement_text": "x-ray image classi\ufb01cation",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "Bosch Small Traffic Lights Dataset: The dataset includes 5093 training images (10756 annotated traffic lights) and 8334 test images (13486 annotated traffic lights). The baseline traffic light detector was provided by domain experts for case study pur- pose.",
      "data_code": {
        "tables": 1,
        "media": 1,
        "clusters_and_sets_and_lists": 1,
        "text": 1
      }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "Modeling",
        "solution_compoent": "Disentangledrepresentationandsemanticadversariallearning.",
        "axial_code": ["Modeling"],
        "componenet_code": ["modeling"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 195,
    "paper_title": "VATLD: A Visual Analytics System to Assess, Understand and Improve Traffic Light Detection",
    "pub_year": 2021,
    "domain": "autonomous driving",
    "requirement": {
      "requirement_text": "RD1: Human-friendly data representation and summarization. This issue arises from the nature of high dimensionality and sheer volume of images. We need a representation to capture the intrinsic attributes of images in a lower dimension space and then summarize them in a human-friendly way [27,28].",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "Bosch Small Traffic Lights Dataset: The dataset includes 5093 training images (10756 annotated traffic lights) and 8334 test images (13486 annotated traffic lights). The baseline traffic light detector was provided by domain experts for case study pur- pose.",
      "data_code": {
        "tables": 1,
        "media": 1,
        "clusters_and_sets_and_lists": 1,
        "text": 1
      }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "Modeling",
        "solution_compoent": "Semanticlatentrepresentationextractionfortrafficlights.",
        "axial_code": ["Modeling"],
        "componenet_code": ["modeling"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 196,
    "paper_title": "VATLD: A Visual Analytics System to Assess, Understand and Improve Traffic Light Detection",
    "pub_year": 2021,
    "domain": "autonomous driving",
    "requirement": {
      "requirement_text": "RD2: Efficient generation of unseen test cases. We seek for a method generating edge cases to probe model robustness. These test cases should be different from the imperceivable noises that learned from traditional adversarial approaches, and have semantic meanings to guide human to improve the robustness [10,23].",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "Bosch Small Traffic Lights Dataset: The dataset includes 5093 training images (10756 annotated traffic lights) and 8334 test images (13486 annotated traffic lights). The baseline traffic light detector was provided by domain experts for case study pur- pose.",
      "data_code": {
        "tables": 1,
        "media": 1,
        "clusters_and_sets_and_lists": 1,
        "text": 1
      }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "Modeling",
        "solution_compoent": "Disentangledrepresentationandsemanticadversariallearning.",
        "axial_code": ["Modeling"],
        "componenet_code": ["modeling"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 197,
    "paper_title": "VATLD: A Visual Analytics System to Assess, Understand and Improve Traffic Light Detection",
    "pub_year": 2021,
    "domain": "autonomous driving",
    "requirement": {
      "requirement_text": "RD2: Efficient generation of unseen test cases. We seek for a method generating edge cases to probe model robustness. These test cases should be different from the imperceivable noises that learned from traditional adversarial approaches, and have semantic meanings to guide human to improve the robustness [10,23].",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "Bosch Small Traffic Lights Dataset: The dataset includes 5093 training images (10756 annotated traffic lights) and 8334 test images (13486 annotated traffic lights). The baseline traffic light detector was provided by domain experts for case study pur- pose.",
      "data_code": {
        "tables": 1,
        "media": 1,
        "clusters_and_sets_and_lists": 1,
        "text": 1
      }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "Modeling",
        "solution_compoent": "Semanticlatentrepresentationextractionfortrafficlights.",
        "axial_code": ["Modeling"],
        "componenet_code": ["modeling"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 198,
    "paper_title": "VATLD: A Visual Analytics System to Assess, Understand and Improve Traffic Light Detection",
    "pub_year": 2021,
    "domain": "autonomous driving",
    "requirement": {
      "requirement_text": "RP1: A contextualized understanding for model performance. In_x0002_stead of using an aggregated metric to evaluate models [18], we would like to put a single score into the contexts of various sizes, IoU thresholds and confident score ranges.",
      "requirement_code": { "describe_observation_item": 1 }
    },
    "data": {
      "data_text": "Bosch Small Traffic Lights Dataset: The dataset includes 5093 training images (10756 annotated traffic lights) and 8334 test images (13486 annotated traffic lights). The baseline traffic light detector was provided by domain experts for case study pur- pose.",
      "data_code": {
        "tables": 1,
        "media": 1,
        "clusters_and_sets_and_lists": 1,
        "text": 1
      }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "Modeling",
        "solution_compoent": "Disentangledrepresentationandsemanticadversariallearning.",
        "axial_code": ["Modeling"],
        "componenet_code": ["modeling"]
      },
      {
        "solution_category": "Visualization",
        "solution_axial": "Repetition",
        "solution_compoent": "table+bar",
        "axial_code": ["Repetition"],
        "componenet_code": ["table", "bar"]
      },
      {
        "solution_category": "Interaction",
        "solution_axial": "Filtering",
        "solution_compoent": "",
        "axial_code": ["Filtering"],
        "componenet_code": ["filtering"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 202,
    "paper_title": "Interactive Visual Study of Multiple Attributes Learning Model of X-Ray Scattering Images",
    "pub_year": 2021,
    "domain": "x-ray image classi\ufb01cation",
    "requirement": {
      "requirement_text": "T1. Analysis in Model Spaces: Investigate scienti\ufb01c images withinthe spaces of ACT, PRD, and FEA, for users to understand how theimages are modeled by the ResNet in the feature space and then classi-\ufb01ed by fully connected layers in the prediction space, with respect tothe real labels. Users can study ResNet model performance by com-paring the distributions of images after feature extraction (FEA), afterclassi\ufb01cation (PRD), and with actual labels (ACT). This study needs tobe performed in an exploratory process. Therefore, it is important tovisualize the images in the three spaces at the same time",
      "requirement_code": { "discover_observation": 1 }
    },
    "data": {
      "data_text": "We utilize an open x-ray scattering dataset [36], and an updated ResNet model [33] that was designed for multiple attributes classification of the dataset. About 1,000 x-ray scattering images were employed in our visualization system. They include different types of images including semiconductors, nano-particles, polymer, lithographic gratings, and so on. The attributes in these images are either labeled by domain experts or synthetically generated by a simulation algorithm [33]. Each image thus has an actual attribute vector (ACT vector) consisting of 17 Boolean (0 or 1) values to show if the image has a number of the 17 attributes.",
      "data_code": {
        "tables": 1,
        "media": 1,
        "clusters_and_sets_and_lists": 1,
        "categorical": 1
      }
    },
    "solution": [
      {
        "solution_category": "DataManipulation",
        "solution_axial": "DimensionalityReduction",
        "solution_compoent": "",
        "axial_code": ["DimensionalityReduction"],
        "componenet_code": ["dimensionality_reduction"]
      },
      {
        "solution_category": "Visualization",
        "solution_axial": "Repetition",
        "solution_compoent": "scatter",
        "axial_code": ["Repetition"],
        "componenet_code": ["scatter"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 203,
    "paper_title": "Interactive Visual Study of Multiple Attributes Learning Model of X-Ray Scattering Images",
    "pub_year": 2021,
    "domain": "x-ray image classi\ufb01cation",
    "requirement": {
      "requirement_text": "T2. Analysis with Group Behaviors: Select and examine speci\ufb01cgroups of images in the ACT, PRD, and FEA spaces, in order to \ufb01ndimportant clusters and outliers with respect to the learning model.",
      "requirement_code": { "collect_evidence": 1 }
    },
    "data": {
      "data_text": "We utilize an open x-ray scattering dataset [36], and an updated ResNet model [33] that was designed for multiple attributes classification of the dataset. About 1,000 x-ray scattering images were employed in our visualization system. They include different types of images including semiconductors, nano-particles, polymer, lithographic gratings, and so on. The attributes in these images are either labeled by domain experts or synthetically generated by a simulation algorithm [33]. Each image thus has an actual attribute vector (ACT vector) consisting of 17 Boolean (0 or 1) values to show if the image has a number of the 17 attributes.",
      "data_code": {
        "tables": 1,
        "clusters_and_sets_and_lists": 1,
        "categorical": 1
      }
    },
    "solution": [
      {
        "solution_category": "Visualization",
        "solution_axial": "Repetition",
        "solution_compoent": "radialbarchart",
        "axial_code": ["Repetition"],
        "componenet_code": ["radialbarchart"]
      },
      {
        "solution_category": "Interaction",
        "solution_axial": "Selecting,Participation/Collaboration",
        "solution_compoent": "",
        "axial_code": ["Participation/Collaboration", "Selecting"],
        "componenet_code": [
          "participation/collaboration",
          "selecting",
          "participation/collaboration",
          "selecting"
        ]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 204,
    "paper_title": "Interactive Visual Study of Multiple Attributes Learning Model of X-Ray Scattering Images",
    "pub_year": 2021,
    "domain": "x-ray image classi\ufb01cation",
    "requirement": {
      "requirement_text": "T3. Analysis with Image Attributes: Identify important image in-stances with the performance metrics of individual attributes and co-existent attributes to perform the \ufb01rst two tasks.",
      "requirement_code": { "describe_observation_item": 1 }
    },
    "data": {
      "data_text": "We utilize an open x-ray scattering dataset [36], and an updated ResNet model [33] that was designed for multiple attributes classification of the dataset. About 1,000 x-ray scattering images were employed in our visualization system. They include different types of images including semiconductors, nano-particles, polymer, lithographic gratings, and so on. The attributes in these images are either labeled by domain experts or synthetically generated by a simulation algorithm [33]. Each image thus has an actual attribute vector (ACT vector) consisting of 17 Boolean (0 or 1) values to show if the image has a number of the 17 attributes.",
      "data_code": {
        "tables": 1,
        "clusters_and_sets_and_lists": 1,
        "categorical": 1
      }
    },
    "solution": [
      {
        "solution_category": "Visualization",
        "solution_axial": "Repetition",
        "solution_compoent": "table",
        "axial_code": ["Repetition"],
        "componenet_code": ["table"]
      }
    ]
  },
  {
    "author": "zsz",
    "index_original": 205,
    "paper_title": "Interactive Visual Study of Multiple Attributes Learning Model of X-Ray Scattering Images",
    "pub_year": 2021,
    "domain": "x-ray image classi\ufb01cation",
    "requirement": {
      "requirement_text": "T4. Analysis with Comparisons: Compare individual images andimage clusters for the model prediction performance.",
      "requirement_code": { "compare_entities": 1 }
    },
    "data": {
      "data_text": "We utilize an open x-ray scattering dataset [36], and an updated ResNet model [33] that was designed for multiple attributes classification of the dataset. About 1,000 x-ray scattering images were employed in our visualization system. They include different types of images including semiconductors, nano-particles, polymer, lithographic gratings, and so on. The attributes in these images are either labeled by domain experts or synthetically generated by a simulation algorithm [33]. Each image thus has an actual attribute vector (ACT vector) consisting of 17 Boolean (0 or 1) values to show if the image has a number of the 17 attributes.",
      "data_code": {
        "tables": 1,
        "media": 1,
        "clusters_and_sets_and_lists": 1,
        "categorical": 1
      }
    },
    "solution": [
      {
        "solution_category": "Visualization",
        "solution_axial": "Repetition",
        "solution_compoent": "image+matrix",
        "axial_code": ["Repetition"],
        "componenet_code": ["image", "matrix"]
      },
      {
        "solution_category": "Interaction",
        "solution_axial": "Selecting",
        "solution_compoent": "",
        "axial_code": ["Selecting"],
        "componenet_code": ["selecting"]
      }
    ]
  }
]
